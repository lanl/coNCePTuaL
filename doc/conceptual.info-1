This is conceptual.info, produced by makeinfo version 6.5 from
conceptual.texi.

This document describes coNCePTuaL version 1.5.1b.


   Copyright (C) 2003, Triad National Security, LLC
INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* coNCePTuaL: (conceptual).   A domain-specific language for network benchmarks
END-INFO-DIR-ENTRY

   This document describes coNCePTuaL version 1.5.1b.


   Copyright (C) 2003, Triad National Security, LLC


File: conceptual.info,  Node: Top,  Next: Introduction,  Prev: (dir),  Up: (dir)

coNCePTuaL
**********

This document presents a simple, special-purpose language called
coNCePTuaL.  coNCePTuaL is intended for rapidly generating programs that
measure the performance and/or test the correctness of networks and
network protocol layers.  A few lines of coNCePTuaL code can produce
programs that would take significantly more effort to write in a
conventional programming language.

   This document describes coNCePTuaL version 1.5.1b.


   Copyright (C) 2003, Triad National Security, LLC

* Menu:

* Introduction::                Introduction to coNCePTuaL and this manual
* Installation::                Installing coNCePTuaL on your computer
* Usage::                       Running the compiler and related tools
* Grammar::                     Specification of the coNCePTuaL grammar
* Examples::                    Examples of complete coNCePTuaL programs
* Implementation::              How coNCePTuaL is implemented
* Tips and Tricks::             Helpful advice for using coNCePTuaL
* Troubleshooting::             Diagnosing coNCePTuaL errors
* Reserved Words::              Lists of token names not available as varaibles
* Backend Developer's Reference::  Lists of importance to backend developers
* Environment Variables::       List of environment variables honored
* Cache Variables::             List of variables used by the configure script
* Referenced Applications::     URLs for applications mentioned in this manual
* License::                     The coNCePTuaL copyright and license agreement
* Index::                       Index to terms used in this manual


File: conceptual.info,  Node: Introduction,  Next: Installation,  Prev: Top,  Up: Top

1 Introduction
**************

This document presents a simple, special-purpose language called
coNCePTuaL.  coNCePTuaL is intended for rapidly generating programs that
measure the performance and/or test the correctness of networks and
network protocol layers.  A few lines of coNCePTuaL code can produce
programs that would take significantly more effort to write in a
conventional programming language.

   coNCePTuaL is not merely a language specification.  The coNCePTuaL
toolset includes a compiler, run-time library, and associated utility
programs that enable users to analyze network behavior quickly,
conveniently, and accurately.

* Menu:

* Motivation::                  Why there's a need for coNCePTuaL
* Limitations::                 Things coNCePTuaL can't do
* Typesetting conventions::     How to read this manual


File: conceptual.info,  Node: Motivation,  Next: Limitations,  Prev: Introduction,  Up: Introduction

1.1 Motivation
==============

A frequently reinvented wheel among network researchers is a suite of
programs that test a network's performance.  A problem with having
umpteen versions of performance tests is that it leads to a variety in
the way results are reported; colloquially, apples are often compared to
oranges.  Consider a bandwidth test.  Does a bandwidth test run for a
fixed number of iterations or a fixed length of time?  Is bandwidth
measured as ping-pong bandwidth (i.e., 2 * message length / round-trip
time) or unidirectional throughput (N messages in one direction followed
by a single acknowledgement message)?  Is the acknowledgement message of
minimal length or as long as the entire message?  Does its length
contribute to the total bandwidth?  Is data sent unidirectionally or in
both directions at once?  How many warmup messages (if any) are sent
before the timing loop?  Is there a delay after the warmup messages (to
give the network a chance to reclaim any scarce resources)?  Are
receives nonblocking (possibly allowing overlap in the NIC) or blocking?

   The motivation behind creating coNCePTuaL, a simple specification
language designed for describing network benchmarks, is that it enables
a benchmark to be described sufficiently tersely as to fit easily in a
report or research paper, facilitating peer review of the experimental
setup and timing measurements.  Because coNCePTuaL code is simple to
write, network tests can be developed and deployed with low turnaround
times--useful when the results of one test suggest a following test that
should be written.  Because coNCePTuaL is special-purpose its run-time
system can perform the following functions, which benchmark writers
often neglect to implement:

   * logging information about the environment under which the benchmark
     ran: operating system, CPU architecture and clock speed, timer type
     and resolution, etc.

   * aborting a program if it takes longer than a predetermined length
     of time to complete

   * writing measurement data and descriptive statistics to a variety of
     output formats, including the input formats of various
     graph-plotting programs

coNCePTuaL is not limited to network peformance tests, however.  It can
also be used for network verification.  That is, coNCePTuaL programs can
be used to locate failed links or to determine the frequency of bit
errors--even those that may sneak past the network's CRC hardware.

   In addition, because coNCePTuaL is a very high-level language, the
coNCePTuaL compiler's backend has a great deal of potential.  It would
be possible for the backend to produce a variety of target formats such
as Fortran + MPI, Perl + sockets, C + a network vendor's low-level
messaging layer, and so forth.  It could directly manipulate a network
simulator.  It could feed into a graphics program to produce a
space-time diagram of a coNCePTuaL program.  The possibilities are
endless.


File: conceptual.info,  Node: Limitations,  Next: Typesetting conventions,  Prev: Motivation,  Up: Introduction

1.2 Limitations
===============

Although coNCePTuaL can express a wide variety of race-free
communication patterns it cannot currently express data-dependent
communication.  For example, coNCePTuaL canot express a master-worker
pattern in which a master task sends a message to a worker task as a
reaction to that particular worker's sending of a message to the master.
Such a communication pattern is not independent of the order in which
messages happen to arrive from the workers.  Similarly, coNCePTuaL
cannot use run-time performance data to guide its operations.  It is
therefore not currently possible to express a communication benchmark
that repeats until the standard error of some performance metric drops
below a given threshold.  These limitations may be lifted in a future
release of the system.


File: conceptual.info,  Node: Typesetting conventions,  Prev: Limitations,  Up: Introduction

1.3 Typesetting conventions
===========================

The following table showcases the typesetting conventions used in this
manual to attribute various meanings to text.  Note that not all of the
conventions are typographically distinct.

'-a'
'--abcdef'
     command-line options (e.g., '-C' or '--help')

'ABCDEF'
     environment variables (e.g., 'PATH')

<ABCDEF>
     nonterminals in the coNCePTuaL grammar (e.g., <IDENT>)

'abcdef'
     commands to enter on the keyboard (e.g., 'make install')

'abcdef'
     file and directory names (e.g., 'conceptual.pdf')

'ABCDEF'
     coNCePTuaL keywords (e.g., 'RECEIVE')

'abcdef'
     variables, constants, functions, and types in any language (e.g.,
     'bit_errors' or 'gettimeofday()')

ABCDEF
     metasyntactic variables and formal function parameters (e.g.,
     FAN-OUT)

'abcdef'
     snippets of code, command lines, files, etc. (e.g., '10 MOD 3')


File: conceptual.info,  Node: Installation,  Next: Usage,  Prev: Introduction,  Up: Top

2 Installation
**************

coNCePTuaL uses the GNU Autotools (Autoconf, Automake, and Libtool) to
increase portability, to automate compilation, and to facilitate
installation.  As of this writing, coNCePTuaL has passed 'make check'
(*note make::) on the following platforms:

Architecture    OS           Compiler
IA-32           Linux        'gcc' (GNU)
                             'icc' (Intel)
                             'opencc' (Open64)
                FreeBSD      'gcc' (GNU)
                OpenBSD      'gcc' (GNU)
                NetBSD       'gcc' (GNU)
                Solaris      'gcc' (GNU)
                             'cc' (Sun)
                Syllable     'gcc' (GNU)
                Windows      'gcc' (GNU)
                (via
                Cygwin)


x86-64          Linux        'gcc' (GNU)
                             'pgcc' (PGI)
                             'pathcc' (PathScale)
                             'llvm-gcc' (LLVM)
                             'clang' (LLVM)
                Catamount    'gcc' (GNU)
                             'pgcc' (PGI)


IA-64           Linux        'gcc' (GNU)
                             'ecc' (Intel)


PowerPC         Linux        'gcc' (GNU)
                             'xlc' (IBM)
                AIX          'gcc' (GNU)
                             'xlc' (IBM)
                MacOS X      'gcc' (GNU)
                BLRTS        'xlc' (IBM)


Cell (Power)    Linux        'gcc' (GNU)


Cray X1         UNICOS/mp    'cc' (Cray)


UltraSPARC      Solaris      'gcc' (GNU)
                             'cc' (Sun)


MIPS            IRIX         'gcc' (GNU)
                             'cc' (MIPSpro)


Alpha           Linux        'gcc' (GNU)
                             'ccc' (HP)
                Tru64        'gcc' (GNU)
                             'cc' (HP)


ARM             Linux        'gcc' (GNU)


   In its simplest form, coNCePTuaL installation works by executing the
following commands at the operating-system prompt:

     ./configure
     make
     make install

('configure' is normally run as './configure' to force it to run from
the current directory on the assumption that '.' is not in the
executable search path.)  We now describe those three installation steps
in detail, listing a variety of customization options for each step.

* Menu:

* configure::                   Create a customized Makefile for your system
* make::                        Compile the coNCePTuaL run-time library
* make install::                Install coNCePTuaL in your system


File: conceptual.info,  Node: configure,  Next: make,  Prev: Installation,  Up: Installation

2.1 'configure'
===============

'configure' is a Bourne-shell script that analyzes your system's
capabilities (compiler features, library and header-file availability,
function and datatype availability, linker flags for various options,
etc.)  and custom-generates a 'Makefile' and miscellaneous other files.
'configure' accepts a variety of command-line options.  './configure
--help' lists all of the options.  The following are some of the more
useful ones:

'--disable-shared'
     coNCePTuaL normally installs both static and dynamic libraries.
     While dynamic libraries have a number of advantages they do need to
     be installed on all nodes that run the compiled coNCePTuaL
     programs.  If global installation is not convenient/feasible,
     '--disable-shared' can be used to force static linking of
     executables.  Note, however, that 'libncptlmodule.so', the Python
     interface to the coNCePTuaL run-time library, needs to be built as
     a shared object so that it can be loaded dynamically into a running
     Python interpreter.  '--disable-shared' inhibits the compilation
     and installation of 'libncptlmodule.so'.

'--prefix=DIRECTORY'
     'make install' normally installs coNCePTuaL into the '/usr/local'
     directory.  The '--prefix' option instructs 'configure' to write a
     'Makefile' with a different installation directory.  For example,
     '--prefix=/local/encap/conceptual-1.5.1b' will cause coNCePTuaL's
     files to be installed in '/local/encap/conceptual-1.5.1b/bin',
     '/local/encap/conceptual-1.5.1b/include', etc.

'--with-ignored-libs=LIB1,LIB2,...'
     In some circumstances it may be necessary to prevent coNCePTuaL
     from using certain libraries even when './configure' detects them
     and believes them to be usable.  The '--with-ignored-libs'
     configuration option forces './configure' to ignore one or more
     specified libraries.  Only the base name of each library should be
     used; omit directory names, the 'lib' prefix (on Unix-like
     systems), and the file suffix.  For example, to disable the use of
     '/usr/local/lib/libpapi.a' you should specify
     '--with-ignored-libs=papi'.

'--without-fork'
     './configure' detects automatically if your system provides a
     working 'fork()' function.  However, it cannot detect if 'fork()'
     correctly spawns a child process but corrupts the parent's memory
     map while doing so, as is the case when using some InfiniBand
     software stacks.  The '--without-fork' option inhibits the use of
     'fork()' and well as functions that implicitly invoke 'fork()' such
     as 'system()' and 'popen()'.

'--with-gettimeofday'
     The coNCePTuaL run-time library is able to use any of a variety of
     platform-specific microsecond timers to take timing measurements.
     (*Note Time-related functions::, for a complete list.)  The
     '--with-gettimeofday' option forces the run-time library to utilize
     instead the generic C 'gettimeofday()' function.  This can be
     useful in the rare, but not impossible, case that a quirk in some
     particular platform misleads one of coNCePTuaL's other timers.  The
     'validatetimer' utility (*note Validating the coNCePTuaL timer::)
     can help determine whether '--with-gettimeofday' is necessary.

'--with-mpi-wtime'
     On some systems the most accurate timer available is provided by
     the 'MPI_Wtime()' function in the MPI library.  The
     '--with-mpi-wtime' option forces the run-time library to measure
     elapsed time using 'MPI_Wtime()' instead of any of the other
     available timers.  (*Note Time-related functions::, for a complete
     list).  The ramifications of '--with-mpi-wtime' are threefold:

       1. The option requires that you link all coNCePTuaL programs
          against an MPI library and run them like any other MPI
          program.  (You may need to set 'CPPFLAGS', 'LIBS', 'LDFLAGS',
          or some of the other command-line variables described below.)

       2. 'MPI_Wtime()' may be _less_ accurate than some of the other
          timers available to coNCePTuaL.  In many MPI implementations,
          'MPI_Wtime()' simply invokes 'gettimeofday()', for instance.

       3. Although this is a rare problem, it may not be safe to invoke
          'MPI_Wtime()' without first invoking 'MPI_Init()'.
          Fortunately, proper juxtaposition of the two functions is not
          a concern for the coNCePTuaL C+MPI backend (*note The c_mpi
          backend::), which ensures that 'MPI_Init()' is invoked before
          'MPI_Wtime()'.

     In short, you should specify '--with-mpi-wtime' only if you have
     good reason to believe that 'MPI_Wtime()' is likely to produce the
     most accurate timing measurements on your system.

'CC=C COMPILER'
     'configure' automatically searches for a C compiler to use.  To
     override its selection, assign a value to 'CC' on the command line.
     For example, './configure CC=ecc' will cause coNCePTuaL to be built
     with 'ecc'.

'CFLAGS=C COMPILER FLAGS'
'LDFLAGS=LINKER FLAGS'
'CPPFLAGS=C PREPROCESSOR FLAGS'
'LIBS=EXTRA LIBRARIES'
     Like 'CC', these variables override the values determined
     automatically by 'configure'.  As an illustration, './configure
     CPPFLAGS="-DSPECIAL -I/home/pakin/include/special -I." CFLAGS="-O3
     -g -Wall -W" LDFLAGS=--static LIBS="-lz /usr/lib/libstuff.a"'
     assigns values to all four variables.

'MPICC=C COMPILER'
'MPICPPFLAGS=C PREPROCESSOR FLAGS'
'MPILDFLAGS=EXTRA LINKER FLAGS'
'MPILIBS=EXTRA LIBRARIES'
     These variables are analagous to 'CC', 'CPPFLAGS', 'LDFLAGS', and
     'LIBS', respectively.  The difference is that they are not used to
     build the coNCePTuaL run-time library but rather to build user
     programs targeted to the C+MPI compiler backend.  For example, if
     your MPI installation lacks an 'mpicc' script, you may need to
     specify extra header files and libraries explicitly: './configure
     MPICPPFLAGS="-I/usr/lib/mpi/include" MPILIBS="-lmpich"'.

   As a rather complex illustration of how some of the preceding options
(as well as a few mentioned by './configure --help') might be combined,
the following is how coNCePTuaL was once configured to cross-compile
from a Linux/PowerPC build machine to a prototype of the BlueGene/L
supercomputer (containing, at the time, 2048 embedded PowerPC
processors, each executing a minimal run-time system, BLRTS). IBM's
'xlc' compiler was accessed via a wrapper script called 'mpcc'.

     './configure CFLAGS="-g -O -qmaxmem=64000" CC=/bgl/local/bin/mpcc
     CPP="gcc -E" --host=powerpc-ibm-linux-gnu
     --build=powerpc-unknown-linux-gnu --with-alignment=8
     --with-gettimeofday --prefix=/bgl/bgguest/LANL/ncptl
     MPICC=/bgl/local/bin/mpcc
     CPPFLAGS=-I/BlueLight/floor/bglsys/include'

   It's always best to specify environment variables as arguments to
'./configure' because the 'configure' script writes its entire command
line as a comment to 'config.log' and as a shell command to
'config.status' to enable re-running './configure' with exactly the same
parameters.


   When './configure' finishes running it outputs a list of the warning
messages that were issued during the run.  If no warnings were issued,
'./configure' will output 'Configuration completed without any errors or
warnings.'.  Warnings are also written to 'config.log' and can therefore
be redisplayed at any time by executing a shell command such as 'grep
WARNING config.log'.


File: conceptual.info,  Node: make,  Next: make install,  Prev: configure,  Up: Installation

2.2 'make'
==========

Running 'make' by itself will compile the coNCePTuaL run-time library.
However, the 'Makefile' generated by 'configure' can perform a variety
of other actions, as well:

'make check'
     Perform a series of regression tests on the coNCePTuaL run-time
     library.  This is a good thing to do after a 'make' to ensure that
     the run-time library built properly on your system.  When
     'make check' finishes it summarizes the test results.  The
     following output signifies a successful completion of 'make check':

          ===================
          All 21 tests passed
          ===================

     The total number of tests performed depends upon the way that
     coNCePTuaL was configured.  coNCePTuaL components that could not be
     built are not tested.

     If any tests behave unexpectedly it may be possible to gain more
     information about the source of the problem by examining the
     corresponding '.log' file left behind in the 'tests' directory.

     Tests can also be run individually:

          cd tests
          ./runtime_random

'make clean'
'make distclean'
'make maintainer-clean'
     'make clean' deletes all files generated by a preceding 'make'
     command.  'make distclean' deletes all files generated by a
     preceding './configure' command. 'make maintainer-clean' delete all
     generated files.  Run 'make maintainer-clean' only if you have
     not-too-ancient versions of the GNU Autotools (Autoconf 2.53,
     Automake 1.6, and Libtool 1.4) because those are needed to
     regenerate some of the generated files.  The sequence of operations
     to regenerate all of the configuration files needed by coNCePTuaL
     is shown below.

          libtoolize --force --copy
          aclocal
          autoheader
          automake --add-missing --copy
          autoconf

'make install'
     Install coNCePTuaL, including the compiler, run-time library,
     header files, and tools.  'make install' is described in detail in
     *note make install::.

'make uninstall'
     Remove all of the files that 'make install' installed.  Most of the
     top-level directories are retained, however, as 'make' cannot
     guarantee that these are not needed by other applications.

'make info'
'make pdf'
'make docbook'
     Produce the coNCePTuaL user's guide (this document) in,
     respectively, Emacs info format, PDF format, or DocBook format.
     The resulting documentation ('conceptual.info*', 'conceptual.pdf',
     or 'conceptual.xml') is created in the 'doc' subdirectory.

'make ncptl-logextract.html'
     coNCePTuaL comes with a postprocessor called 'ncptl-logextract'
     that facilitates extracting information from coNCePTuaL-produced
     log files.  The complete 'ncptl-logextract' documentation is
     presented in *note ncptl-logextract::.  As is readily apparent from
     that documentation, 'ncptl-logextract' supports an overwhelming
     number of command-line options.  To make the 'ncptl-logextract'
     documentation more approachable, the 'make ncptl-logextract.html'
     command creates a dynamic HTML version of it (and stores in the
     'doc' subdirectory).  The result, 'ncptl-logextract.html',
     initially presents only the top level of the 'ncptl-logextract'
     option hierarchy.  Users can then click on the name of a
     command-line option to expand or contract the list of subobtions.
     This interactive behavior makes it easy for a user to get more
     information on some options without being distracted by the
     documentation for the others.

'make empty.log'
     Create an empty log file called 'empty.log' that contains a
     complete prologue and epilogue but no data.  This is convenient for
     validating that the coNCePTuaL run-time library was built using
     your preferred build options.

'make stylesheets'
     coNCePTuaL can automatically produce stylesheets for a variety of
     programs.  These stylesheets make keywords, comments, strings, and
     other terms in the language visually distinct from each other for a
     more aesthetically appealing appearance.  Currently,
     'make stylesheets' produces a LaTeX2e package ('ncptl.sty'), an
     a2ps style sheet ('ncptl.ssh'), an Emacs major mode
     ('ncptl-mode.el' and 'ncptl-mode.elc'), a Vim syntax file
     ('ncptl.vim'), a Source-highlight language definition
     ('ncptl.lang'), and a GeSHi language file ('ncptl.php').  Each of
     these can be built individually if desired.  (For example,
     'make ncptl-mode.vim' will create only 'ncptl-mode.vim'.)  Note
     that the 'Makefile' currently lacks provisions for installing these
     files so whichever stylesheets are desired will need to be
     installed manually.  Stylesheet installation is detailed in *note
     Installing stylesheets::.

'make modulefile'
     The Environment Modules package facilitates configuring the
     operating-system shell for a given application.  The
     'make modulefile' command creates a 'conceptual_1.5.1b' modulefile
     that checks for conflicts with previously loaded coNCePTuaL
     modulefiles then sets the 'PATH', 'MANPATH', and 'LD_LIBRARY_PATH'
     environment variables to values appropriate values as determined by
     'configure' (*note configure::).

     Normally, 'conceptual_1.5.1b' should be installed in the system's
     module path (as described by the 'MODULEPATH' environment
     variable).  However, users without administrator access can still
     use the coNCePTuaL modulefile as a convenient mechanism for
     properly setting all of the environment variables needed by
     coNCePTuaL:

          make modulefile
          module load ./conceptual_1.5.1b

     See the 'module' man page for more information about modules.

'make dist'
     Package together all of the files needed to rebuild coNCePTuaL.
     The resulting file is called 'conceptual-1.5.1b.tar.gz' (for this
     version of coNCePTuaL).

'make all'
     Although 'all' is the default target it can also be specified
     explicitly.  Doing so is convenient when performing multiple
     actions at once, e.g., 'make clean all'.

'make tags'
     Produce/update a 'TAGS' file that the Emacs text editor can use to
     find function declarations, macro definitions, variable
     definitions, 'typedef's, etc. in the coNCePTuaL run-time library
     source code.  This is useful primarily for developers wishing to
     interface with the coNCePTuaL run-time library.  Read the Emacs
     documentation for 'M-x find-tag' for more information.

'make gui'
     Compile the coNCePTuaL GUI, producing 'ncptlGUI-1.5.1b.jar'.  Note
     that compilation requires both a Java compiler (e.g., 'javac') and
     the Jython Python-to-Java compiler ('jythonc').  Unfortunately, at
     the time of this writing (January 2009), 'jythonc''s future is
     uncertain (cf. <http://www.jython.org/Project/jythonc.html>).
     Hence, 'make gui' has been tested only with 'jythonc'
     version 2.2.X, not any later versions.

* Menu:

* Validating the coNCePTuaL timer::  Ensuring timing results are meaningful


File: conceptual.info,  Node: Validating the coNCePTuaL timer,  Prev: make,  Up: make

Validating the coNCePTuaL timer
-------------------------------

'make' automatically builds a program called 'validatetimer'.
'validatetimer' helps validate that the real-time clock used by the
coNCePTuaL run-time library accurately measures wall-clock time.  The
idea is to compare coNCePTuaL's timer to an external clock (i.e., one
not associated with the computer).  Simply follow the program's prompts:

     % validatetimer
     Press <Enter> to start the clock ...
     Press <Enter> again in exactly 60 seconds ...

     coNCePTuaL measured 60.005103 seconds.
     coNCePTuaL timer error = 0.008505%

   If the difference between coNCePTuaL's timer and an external clock is
significant, then performance results from coNCePTuaL--and possibly from
other programs, as well--should not be trusted.  Note that only extreme
differences in timings are significant; there will always be _some_
error caused by human response time and by system I/O speed.  In the
case that there _is_ an extreme performance difference,(1) the
'--with-gettimeofday' option to 'configure' (*note configure::) may be a
viable workaround.

   'validatetimer' takes an optional command-line argument, which is the
number of seconds of wall-clock time to expect.  The default is '60'.
Larger numbers help amortize error; smaller numbers enable the program
to finish sooner.

   ---------- Footnotes ----------

   (1) To date, extreme performance differences have been observed
primarily on PowerPC-based systems.  The PowerPC cycle counter is
clocked at a different rate from the CPU speed, which may confuse
coNCePTuaL.  The run-time library compensates for this behavior on all
tested platforms (*note Installation::), but the user should
nevertheless make sure to run 'validatetimer' to verify that
coNCePTuaL's timer is sufficiently accurate.


File: conceptual.info,  Node: make install,  Prev: make,  Up: Installation

2.3 'make install'
==================

The coNCePTuaL compiler and run-time library are installed with
'make install'.  Although 'configure' can specify the default
installation directory (*note configure::), this can be overridden at
'make install' time in one of two ways. 'make DESTDIR=PREFIX install'
prepends PREFIX to every directory when installing.  However, the files
are installed believing that 'DESTDIR' was not specified.  For example,
'make DESTDIR=/mnt install' would cause executables to be installed into
'/mnt/usr/local/bin', but if any of these are symbolic links, the link
will omit the '/mnt' prefix.

   The second technique for overriding installation directories is to
specify a new value for 'prefix' on the command line.  That is,
'make prefix=/opt/ncptl install' will install into '/opt/ncptl/bin',
'/opt/ncptl/include', '/opt/ncptl/man', etc., regardless of the
'--prefix' value given to 'configure'.  coNCePTuaL's 'Makefile' provides
even finer-grained control than that.  Instead of--or in addition
to--specifying a 'prefix' option on the command line, individual
installation directories can be named explicitly.  These include
'bindir', 'datadir', 'libdir', 'includedir', 'infodir', 'mandir',
'pkgdatadir', 'pythondir', and many others.  Scrutinize the 'Makefile'
to find a particular directory that should be overridden.

   The remainder of this section presents a number of optional
installation steps that add coNCePTuaL support to a variety of
third-party software packages.

* Menu:

* Installing stylesheets::      Where to put the various stylesheet files
* SLOCCount::                   Automatically counting lines of coNCePTuaL code
* pkg-config::                  Linking with the coNCePTuaL run-time library


File: conceptual.info,  Node: Installing stylesheets,  Next: SLOCCount,  Prev: make install,  Up: make install

Installing stylesheets
----------------------

The 'make stylesheets' command (*note make::) produces a variety of
stylesheets for presenting coNCePTuaL code in a more pleasant format
than ordinary, monochromatic text.  Stylesheets must currently be
installed manually as per the following instructions:

'ncptl.sty'

     'ncptl.sty' is typically installed in 'TEXMF/tex/latex/misc', where
     TEXMF is likely to be '/usr/local/share/texmf'.  On a Web2c version
     of TeX the command 'kpsewhich -expand-var='$TEXMFLOCAL'' should
     output the correct value of TEXMF.  In most TeX distributions the
     filename database needs to be refreshed after a new package is
     installed.  See
     <http://www.tex.ac.uk/cgi-bin/texfaq2html?label=instpackages> for
     more information.  'ncptl.sty' is merely a customization of the
     'listings' package that defines a new language called 'ncptl'.  See
     the 'listings' documentation for instructions on typesetting source
     code.

'ncptl.ssh'

     Running 'a2ps --list=defaults' outputs (among other things) the
     a2ps library path.  'ncptl.ssh' should be installed in one of the
     'sheets' directories listed there, typically
     '/usr/share/a2ps/sheets'.

'ncptl-mode.el'
'ncptl-mode.elc'

     'ncptl-mode.el' and 'ncptl-mode.elc' belong in a local Elisp
     directory that is part of the Emacs 'load-path', e.g.,
     '/usr/share/emacs/site-lisp'.  The following Elisp code, which
     belongs in '~/.emacs' for GNU Emacs or '~/.xemacs/init.el' for
     XEmacs, makes Emacs set 'ncptl-mode' whenever opening a file with
     extension '.ncptl':

          (autoload 'ncptl-mode "ncptl-mode"
            "Major mode for editing coNCePTuaL programs." t)
          (add-to-list 'auto-mode-alist '("\\.ncptl$" . ncptl-mode))

     Syntax highlighting should be enabled by default.  If it isn't, the
     Emacs command 'M-x font-lock-mode' should enable it for the current
     buffer.

'ncptl.vim'

     Vim's syntax-file directory may be named after the Vim version,
     e.g., '/usr/share/vim/vim61/syntax' for Vim 6.1.  Put 'ncptl.vim'
     there.  To associate '.ncptl' files with coNCePTuaL code, the
     following lines need to be added to Vim's 'filetype.vim' file
     somewhere between the 'augroup filetypedetect' line and the
     'augroup END' line:

          " coNCePTuaL
          au BufNewFile,BufRead *.ncptl           setf ncptl

'ncptl.lang'

     Source-highlight stores all of its helper files in a single
     directory, typically '/usr/share/source-highlight'.  Put
     'ncptl.lang' there.  To associate '.ncptl' files with coNCePTuaL
     code you will also need to add the following line to the 'lang.map'
     file in the same directory:

          ncptl = ncptl.lang

'ncptl.php'

     GeSHi stores all of its language files in a 'geshi' subdirectory.
     Simply put 'ncptl.php' there, and it should be ready for use.  A
     quick way to convert coNCePTuaL programs to color-coded HTML is to
     use the command-line version of the PHP interpreter with the
     following shell script.

          #!/usr/bin/env php

          <html>
          <head>
          <title><?php echo basename($argv[1]); ?></title>
          </head>
          <body>
          <?php
          include("GESHI_DIRECTORY/geshi.php");
          $ncptl_code = file_get_contents($argv[1]);
          geshi_highlight($ncptl_code, "ncptl");
          ?>
          </body>
          </html>

     Simply replace GESHI_DIRECTORY with the name of your top-level
     GeSHi directory and run the script with the name of a coNCePTuaL
     file as its sole argument.

     A GeSHi extension for Mediawiki introduces a '<syntaxhighlight>'
     tag for presenting color-coded program listings on a wiki.
     'ncptl.php' makes it easy to use coNCePTuaL code in this context.


File: conceptual.info,  Node: SLOCCount,  Next: pkg-config,  Prev: Installing stylesheets,  Up: make install

SLOCCount
---------

SLOCCount is a utility that counts the number of lines of code in a
file, excluding blank lines and comments.  SLOCCount supports a variety
of programming languages and it is straightforward to get it to support
coNCePTuaL, as well.  The procedure follows the "Adding support for new
languages" section of the SLOCCount manual:

  1. Create an 'ncptl_count' script with the following contents:

          #! /bin/sh

          generic_count "#" $@

  2. Mark the script executable and install it somewhere in your
     executable search path.

  3. Edit SLOCCount's 'break_filelist' Perl script to include the
     following association in the '%file_extensions' hash:

            "ncptl" => "ncptl",    # coNCePTuaL


File: conceptual.info,  Node: pkg-config,  Prev: SLOCCount,  Up: make install

pkg-config
----------

The pkg-config utility helps ensure that programs are given appropriate
compiler and linker flags to use a particular package's C header files
and libraries.  coNCePTuaL's 'configure' script (*note configure::)
automatically produces a pkg-config configuration file for the
coNCePTuaL header file ('ncptl.h') and run-time library ('libncptl').
This configuration file, 'ncptl.pc', should be installed in one of the
directories searched by pkg-config ('/usr/lib/pkgconfig' on some
systems).  Once 'ncptl.pc' is installed, pkg-config can be used to
compile C programs that require the coNCePTuaL header file and link
programs that require the coNCePTuaL run-time library, as is shown in
the following example:

     cc `pkg-config --cflags ncptl` -c myprog.c
     cc -o myprog myprog.o `pkg-config --libs ncptl`


File: conceptual.info,  Node: Usage,  Next: Grammar,  Prev: Installation,  Up: Top

3 Usage
*******

coNCePTuaL is more than just a language; it is a complete toolset that
consists of the following components:

   * the coNCePTuaL language (*note Grammar::)

   * a compiler and run-time library for coNCePTuaL programs (*note
     Compiling coNCePTuaL programs::)

   * a set of compiler backends that can generate code for a variety of
     languages and communication layers (*note Supplied backends::)

   * utilities to help analyze the results (*note ncptl-logextract::)

   This chapter explains how to compile and run coNCePTuaL programs and
how to interpret the log files they output.

* Menu:

* The coNCePTuaL GUI::          Drawing communication patterns
* Compiling coNCePTuaL programs::  Options accepted by the compiler
* Supplied backends::           Descriptions of the standard backends
* Running coNCePTuaL programs::  Options accepted by coNCePTuaL programs
* Interpreting coNCePTuaL log files::  Understanding program output


File: conceptual.info,  Node: The coNCePTuaL GUI,  Next: Compiling coNCePTuaL programs,  Prev: Usage,  Up: Usage

3.1 The coNCePTuaL GUI
======================

The coNCePTuaL graphical user interface (GUI) is the easiest way to get
started with coNCePTuaL. Instead of writing code in the coNCePTuaL
language (documented in detail in *note Grammar::), a user merely
_draws_ a communication pattern using the mouse, and the coNCePTuaL GUI
automatically produces a coNCePTuaL program from that illustration.  The
generated program can then be compiled just like a hand-coded coNCePTuaL
program as per the instructions in *note Compiling coNCePTuaL
programs::.

   The coNCePTuaL GUI is written in Java and therefore requires a Java
virtual machine (JVM) to run.  However, the coNCePTuaL GUI is quite
portable and should run identically on every platform for which a JVM
exists.  The following is a typical command for launching the coNCePTuaL
GUI from the command line:

     java -jar ncptlGUI-1.5.1b.jar

   The coNCePTuaL GUI is split into two main panels.  The _program
panel_ displays the components that make up the program and how they
interact with each other.  The _dialog panel_ displays fields for
setting the options of selected components.  Furthermore, a _menu bar_
provides access to various GUI-wide operations, and a _command bar_
includes buttons for creating new components in the program panel.

 [image src="gui.png" alt="Screenshot of the coNCePTuaL GUI" text="
+----------------------------------------------------------------+
| File  Edit  Options  Advanced                                  | Menu bar
+----------------------------------------------------------------+
| [Add Row] [Delete] [Loop] [Measure] [Compute] [Communicate]    | Command
| [Wait] [Extend] [Synchronize] [Reduce] [Multicast] [Normalize] | bar
+----------------------------------------------------------------+
|                                                                | Program
| (0) (1) (2) (3) (4) (5) (6) (7)                                | panel
|                                                                |
| ===============================                                |
|                                                                |
+----------------------------------------------------------------+
| To enable:                                                     | Dialog
|  -Delete: select one or more components.                       | panel
|  -Loop: select one or more task rows or blocks.                |
|  -Measure: select one or more task rows or blocks.             |
|  -Compute: select one or more tasks.                           |
|  -Communicate: select tasks in two task rows.                  |
+----------------------------------------------------------------+" ]

* Menu:

* Components::                  Graphical representations of coNCePTuaL objects
* Menu bar::                    Operations performed by each menu item
* Command bar::                 Operations performed by each button


File: conceptual.info,  Node: Components,  Next: Menu bar,  Prev: The coNCePTuaL GUI,  Up: The coNCePTuaL GUI

3.1.1 Components
----------------

Components are graphical representations of coNCePTuaL objects and
operations used by the coNCePTuaL GUI to specify programs.  Components
are added to the program panel by clicking on their corresponding
buttons in the command bar.  To select a component in the program panel,
simply left-click on it.  If the component has parameters that can be
edited, a dialog will appear in the dialog panel.  Multiple components
can be selected by dragging the mouse over target components or holding
down Ctrl as you left-click on several components.

   The coNCePTuaL GUI lets a user manipulate the following components:

task/task row
     Tasks represent operational units in coNCePTuaL programs and are
     analogous to a process or thread in a parallel program.  For
     example, a coNCePTuaL operation like point-to-point communication
     has a source task that specifies how the message is sent and a
     target task that specifies how the message is received.  Tasks are
     displayed graphically as numbered circles in the coNCePTuaL GUI.  A
     task row represents the total number of tasks available for
     operations at each step of a coNCePTuaL program.  *Note Task
     descriptions::, for information on how to specify subsets of a
     program's tasks.

communication message
     Messages between tasks are displayed as directed edges (arrows)
     from source task to target task in the coNCePTuaL GUI.  Messages
     are added to the program panel via the command bar or by dragging
     the mouse from a source task to a target task.  Communication
     messages in the coNCePTuaL GUI correspond to the 'SEND' and
     'RECEIVE' statements in the coNCePTuaL language (*note Sending::,
     and *note Receiving::).

awaiting completion
     Messages that are sent/received asynchronously must eventually be
     waited on.  Awaits message completion is displayed as a solid line
     under the associated tasks in the coNCePTuaL GUI.  Awaiting
     completion in the coNCePTuaL GUI correspond to the 'AWAIT
     COMPLETION' statement in the coNCePTuaL language (*note Awaiting
     completion::).

loop
     One can add a loop around selected components to repeat the
     corresponding coNCePTuaL operations.  Loops in the coNCePTuaL GUI
     correspond to the 'FOR' statement in the coNCePTuaL language (*note
     Iterating::).

measurement block
     One can log timing or other measurements of coNCePTuaL operations
     by placing them in a measurement block.  Measurement blocks in the
     coNCePTuaL GUI correspond to the 'LOGS' statement in the coNCePTuaL
     language (*note Writing to a log file::).

computation/sleeping
     Artificial computation (really a spin loop) and sleeping, both of
     which delay the program for a given length of time, can be
     performed on a set of tasks.  Computation is shown with 'cmp' under
     a task in the coNCePTuaL GUI, and sleeping is shown with 'slp'.
     Computation/sleeping in the coNCePTuaL GUI corresponds to the
     'COMPUTE' and 'SLEEP' statements in the coNCePTuaL language (*note
     Delaying execution::).

multicasting
     A multicast operation sends a message from a source task to
     multiple target tasks.  Multicasting in the coNCePTuaL GUI
     corresponds to the 'MULTICAST' statement in the coNCePTuaL language
     (*note Multicasting::).

reduction
     A reduction operation combines messages from multiple source tasks
     to a single target task.  Reduction in the coNCePTuaL GUI
     corresponds to the 'REDUCE' statement in the coNCePTuaL language
     (*note Reducing::).

synchronization
     Barrier synchronization forces a set of tasks to wait until each
     task in the set reaches the synchronization point before any task
     in the set proceeds past the synchronization point.
     Synchronization is displayed as a dotted line under the associated
     tasks in the coNCePTuaL GUI.  Synchronization in the coNCePTuaL GUI
     corresponds to the 'SYNCHRONIZE' statement in the coNCePTuaL
     language (*note Synchronizing::).


File: conceptual.info,  Node: Menu bar,  Next: Command bar,  Prev: Components,  Up: The coNCePTuaL GUI

3.1.2 Menu bar
--------------

The _File_ menu, which appears only when the coNCePTuaL GUI is granted
access to the filesystem, contains _New_, _Open_, _Save_, _Save As_,
_Print_, and _Quit_ commands that exhibit the expected behavior.
Programs are saved as coNCePTuaL source code that can then be compiled
with the coNCePTuaL compiler as per *note Compiling coNCePTuaL
programs::.  _Print_ prints a graphical view of the program as it
appears on screen.  (*Note The latex_vis backend::, for a more
sophisticated way to produce graphical views of coNCePTuaL programs.)

   The _Edit_ menu provides the usual _Cut_, _Copy_, _Paste_, and _Undo_
commands.

   _Options_->_Settings_ opens a dialog in the dialog panel for setting
the number of tasks in a task row.  The default number of tasks in a
task row is 16.

   _Advanced_->_Add conditional_ adds a conditional statement to a
program at the current cursor position in the program panel.  A dialog
in the dialog panel will open for entering the conditional expression.
A placeholder expression '1 = 1' is set by default.

   _Advanced_->_Command line options_ opens a dialog in the dialog panel
for adding command-line options to a program.  A placeholder 'reps'
('number of repetitions') option is set by default when this command is
selected.


File: conceptual.info,  Node: Command bar,  Prev: Menu bar,  Up: The coNCePTuaL GUI

3.1.3 Command bar
-----------------

The following buttons appear on the command bar:

_Add Row_
     Insert a new, empty task row at the cursor position.

_Delete_
     Delete the selected components.

_Loop_
     Add a loop around the selected components.

_Measure_
     Add a measurement block around the selected components.

_Compute_
     Make the selected tasks "compute" or sleep for a length of time.

_Communicate_
     Add point-to-point communication between selected tasks (different
     task rows).  This can also be achieved by dragging an arrow from a
     source task to a target task.

_Wait_
     Make the selected tasks (same task row) or all tasks in the row
     above the cursor wait for all outstanding messages sent or received
     asynchronously to complete.

_Extend_
     Extend a communication or computation pattern across an entire task
     row.

_Synchronize_
     Synchronize the selected tasks (same task row) or all tasks in the
     task row above the cursor.

_Reduce_
     Reduce data from the selected tasks in one task row to the selected
     tasks in the next task row.  With no selection, reduce data from
     all tasks above the cursor to task 0 below the cursor.

_Multicast_
     Multicast data from the selected tasks in one task row to the
     selected tasks in the next task row.  With no selection, multicast
     data from task 0 above the cursor to all tasks below the cursor.

_Normalize_
     Put the program into standard form as it will appear when
     translated into coNCePTuaL code.  After normalization, components
     are drawn as early in time as possible without changing the
     program's semantics.


File: conceptual.info,  Node: Compiling coNCePTuaL programs,  Next: Supplied backends,  Prev: The coNCePTuaL GUI,  Up: Usage

3.2 Compiling coNCePTuaL programs
=================================

The coNCePTuaL compiler is called 'ncptl' and is, by default, installed
into '/usr/local/bin'.  Executing 'ncptl --help' produces a brief usage
string:

     Usage: ncptl [--backend=<string>] [--quiet] [--no-link | --no-compile]
              [--keep-ints] [--lenient] [--filter=<sed expr>] [--output=<file>]
              <file.ncptl> | --program=<program>
              [<backend-specific options>]

            ncptl --help

            ncptl [--backend=<string>] --help-backend

The usage string is followed by a list of installed backends.

   The following list describes each compiler option in turn:

'--backend' (abbreviation: '-b')
     Specify the module that coNCePTuaL should use as the compiler
     backend. 'ncptl' must be told which backend to use with either
     '--backend=BACKEND' or by setting the environment variable
     'NCPTL_BACKEND' to the desired backend.  Running 'ncptl --help'
     lists the available backends.  Most coNCePTuaL backends are code
     generators.  For example, 'c_mpi' causes 'ncptl' to compile
     coNCePTuaL programs into C using MPI as the communication library.
     However, a backend need not generate code directly--or at all.  The
     'c_trace' backend (*note The c_trace backend::), for instance,
     supplements the code generated by another backend by adding tracing
     output to it.

     'ncptl' searches for backends first using 'NCPTL_PATH', an
     environment variable containing a colon-separated list of
     directories (default: empty); then, in the directory in which
     coNCePTuaL installed all of its Python files; and finally, in the
     default Python search path.  Non-directories (e.g., the '.zip'
     archives used in newer versions of Python) are not searched.

     If no backend is specified, 'ncptl' runs the given coNCePTuaL
     program through the lexer, parser, and semantic analyzer but does
     not generate an output file.

'--quiet' (abbreviation: '-q')
     The '--quiet' option tells 'ncptl' and the chosen backend to output
     minimal status information.

'--no-link' (abbreviation: '-c')
     By default, 'ncptl' instructs the backend to compile and link the
     user's coNCePTuaL program into an executable file.  '--no-link'
     tells the backend to skip the linking step and produce only an
     object file.

'--no-compile' (abbreviation: '-E')
     By default, 'ncptl' instructs the backend to compile and link the
     user's coNCePTuaL program into an executable file. '--no-compile'
     tells the backend to skip both the compilation and the linking step
     and to produce only a source file in the target language.

'--keep-ints' (abbreviation: '-K')
     coNCePTuaL backends normally delete any files created as part of
     the compiling or linking process.  '--keep-ints' tells 'ncptl' and
     the chosen backend to preserve their intermediate files.

'--lenient' (abbreviation: '-L')
     The '--lenient' option tells the compiler to permit certain
     constructs that would otherwise result in a compilation error.
     First, using the same command-line option (either the long or short
     variant) for two different variables normally generates an 'Option
     OPT is multiply defined' error.  (*Note Command-line arguments::,
     for a description of how to declare command-line options in
     coNCePTuaL.) '--lenient' tells the coNCePTuaL compiler to
     automatically rename duplicate options to avoid conflicts.  Only
     the option strings can be renamed; the programmer must still ensure
     that the option variables are unique.  Second, using a variable
     without declaring it normally produces an error message at compile
     time.  Passing '--lenient' to 'ncptl' tells the compiler to
     automatically generate a command-line option for each missing
     variable.  This is convenient when entering brief programs on the
     command line with '--program' (described below) as it can save a
     significant amount of typing.

'--filter' (abbreviation: '-f')
     The '--filter' option applies a 'sed'-style substitution expression
     to the backend-translated code (e.g., a '.c' file output by the
     'c_udgram' backend or a '.tex' file output by the 'latex_vis'
     backend) before the backend compiles it.  The '--filter' option can
     be used multiple times on the command line; filters are applied in
     the order specified.  Substitution expressions must be of the form
     's/PATTERN/REPLACEMENT/FLAGS', although the '/' characters can be
     replaced by any other character.  PATTERN is a regular expression;
     REPLACEMENT is an optional replacement string; and, FLAGS is a
     sequence of zero or more modifiers from the set {'i', 'l', 'm',
     's', 'u', 'x'}, as described in the Python Library Reference.  For
     example, 'i' means to perform a case-insensitive substitution.  In
     addition, the 'g' flag performs a global search-and-replace instead
     of replacing only the first occurrence of PATTERN.  An important
     difference between '--filter' and 'sed' is that omitting the 'g'
     flag instructs '--filter' to make at most one substitution _total_
     while it instructs 'sed' to make at most one substitution _per
     line_.

'--output' (abbreviation: '-o')
     'ncptl' normally writes its output to a file with the same base
     name as the input file (or 'a.out' if the program was specified on
     the command line using '--program').  '--output' lets the user
     specify a file to which to write the generated code.

'--program' (abbreviation: '-p')
     Because coNCePTuaL programs can be quite short '--program' enables
     a program to be specified in its entirety on the command line.  The
     alternative to using '--program' is to specify the name of a file
     containing a coNCePTuaL program.  By convention, coNCePTuaL
     programs have a '.ncptl' file extension.

'--help-backend' (abbreviation: '-H')
     Describe additional options that are meaningful only to the
     specified backend.  The '--backend' option must be used in
     conjunction with '--help-backend'.

   The following--to be entered without line breaks--is a sample command
line:

     ncptl --backend=c_mpi --output=sample.c --program='Task 0 sends a 0
       byte message to task 1 then task 1 sends a 0 byte message to task 0
       then task 0 logs elapsed_usecs/2 as "Startup latency (usecs)".'

   'ncptl' stops processing the command line at the first unrecognized
option it encounters.  That option and all subsequent options--including
those which 'ncptl' would otherwise process--are passed to the backend
without interpretation by 'ncptl'.  Furthermore, the '--' (i.e., empty)
option tells 'ncptl' explicitly to stop processing the command line at
that point.  For example, in the command 'ncptl --backend=some_backend
--lenient myprogram.ncptl -- --program', 'ncptl' will process the
'--backend' and '--lenient' options but will pass '--program' to the
'some_backend' backend even though 'ncptl' has its own '--program'
option.(1)

   ---------- Footnotes ----------

   (1) As an aside, '--help-backend' is essentially equivalent to '--
--help'; the '--help-backend' synonym is provided merely for
convenience.


File: conceptual.info,  Node: Supplied backends,  Next: Running coNCePTuaL programs,  Prev: Compiling coNCePTuaL programs,  Up: Usage

3.3 Supplied backends
=====================

The coNCePTuaL 1.5.1b distribution includes the following compiler
backends:

'c_seq'
     Generate ANSI C code with no communication support.

'c_mpi'
     Generate ANSI C code with calls to the MPI library for
     communication.

'c_udgram'
     Generate ANSI C code that communicates using Unix-domain (i.e.,
     local to a single machine) datagram sockets.

'c_trace'
     Instrument a C-based backend either to include a call to
     'fprintf()' before every program event or to utilize the 'curses'
     library to display graphically the execution of a selected task.

'c_profile'
     Instrument a C-based backend either to write event timings and
     tallies to each log file or to the standard error device if the
     coNCePTuaL program doesn't use a log file.

'interpret'
     Interpret a coNCePTuaL program, simulating any number of processors
     and checking for common problems such as deadlocks and mismatched
     sends and receives.

'stats'
     Output statistics of a program's execution--message tallies, byte
     counts, communication peers, network bisection crossings, event
     tallies, etc.

'picl'
     Output in the PICL trace format a logical-time trace of a
     coNCePTuaL program's communication pattern.

'paraver'
     Output in the Paraver trace format a logical-time trace of a
     coNCePTuaL program's communication pattern.

'latex_vis'
     Use LaTeX to produce an Encapsulated PostScript visualization of a
     program's communication pattern.

'dot_ast'
     Output a program's parse tree in the Graphviz dot format.

'libsea_ast'
     Output a program's parse tree in the LibSea graph file format.

   coNCePTuaL employs a highly modular software structure for its
backends.  Many of the backends listed above are built atop other
backends.  The following figure illustrates the current set of
dependencies:


 +--------------------------+
 |  c_trace and c_profile   |
 +-------+----------+-------+-------+------+-----------+
 | c_mpi | c_udgram | c_seq | stats | picl | latex_vis |
 +-------+----------+-------+-------+------+-----------+---------+------------+
 |        c_generic         |    interpret             | dot_ast | libsea_ast |
 +--------------------------+--------------------------+---------+------------+

   Some dependencies are defined as a static characteristic of a
backend.  For example, the 'c_mpi' backend is hardwired to derive some
of its functionality from 'c_generic'.  Other dependencies are
determined dynamically.  For example, the 'c_trace' backend must be
instructed to derive its functionality from one of 'c_profile', 'c_mpi',
'c_udgram', or 'c_seq'.  (*Note The c_trace backend::, for more
information on the 'c_trace' backend.)

   Except for 'c_generic', all of the compiler backends are described in
turn in the following sections.  The 'c_generic' backend is unique
because it is used exclusively to construct C-based backends; it does
nothing by itself.  *Note Backend creation::, for a detailed description
of 'c_generic'.

   Each backend accepts a '--help' option that explains the backend's
command-line options.  The easiest way to request help from a specific
backend is with 'ncptl --backend=BACKEND -- --help'.  The empty '--'
option, mentioned in *note Compiling coNCePTuaL programs::, prevents the
compiler from intercepting '--help' and providing the standard,
backend-independent information.

* Menu:

* The c_seq backend::           ANSI C, sequential code only
* The c_mpi backend::           ANSI C + MPI
* The c_udgram backend::        ANSI C + Unix-domain datagram sockets
* The c_trace backend::         Instrument any of the above with tracing output
* The c_profile backend::       Profile events in any of the above
* The interpret backend::       Interpret coNCePTuaL programs
* The stats backend::           Report statistics on a program's execution
* The picl backend::            Trace a coNCePTuaL program's logical execution
* The paraver backend::         Trace a coNCePTuaL program's logical execution
* The latex_vis backend::       Visualize a communication pattern
* The dot_ast backend::         Graphviz DOT format (show abstract-syntax tree)
* The libsea_ast backend::      CAIDA LibSea format (show abstract-syntax tree)


File: conceptual.info,  Node: The c_seq backend,  Next: The c_mpi backend,  Prev: Supplied backends,  Up: Supplied backends

3.3.1 The 'c_seq' backend
-------------------------

The 'c_seq' backend is intended primarily to provide backend developers
with a minimal C-based backend that can be used as a starting point for
creating new backends.  *Note Backend creation::, explains how to write
backends.


File: conceptual.info,  Node: The c_mpi backend,  Next: The c_udgram backend,  Prev: The c_seq backend,  Up: Supplied backends

3.3.2 The 'c_mpi' backend
-------------------------

The 'c_mpi' backend is coNCePTuaL's workhorse.  It generates parallel
programs written in ANSI C that communicate using the industry-standard
MPI messaging library.

   By default, 'c_mpi' produces an executable program that can be run
with 'mpirun', 'prun', 'pdsh', or whatever other job-launching program
is normally used to run MPI programs.  When 'ncptl' is run with the
'--no-link' option, 'c_mpi' produces an object file that needs to be
linked with the appropriate MPI library.  When 'ncptl' is run with the
'--no-compile' option, 'c_mpi' outputs ANSI C code that must be both
compiled and linked.

   'c_mpi' honors the following environment variables when compiling and
linking C+MPI programs: 'MPICC', 'MPICPPFLAGS', 'MPICFLAGS',
'MPILDFLAGS', 'MPILIBS'.  If any of these variables is not found in the
environment, 'c_mpi' will use the value specified/discovered at
configuration time (*note configure::).  'MPICC' defaults to the value
of 'CC'; 'MPICFLAGS' defaults to the value of 'CFLAGS'; the remaining
variables are appended respectively to 'CPPFLAGS', 'LDFLAGS', and
'LIBS'.

   The following is a complete list of MPI functions employed by the
'c_mpi' backend: 'MPI_Allreduce()', 'MPI_Alltoallv()', 'MPI_Barrier()',
'MPI_Bcast()', 'MPI_Comm_group()', 'MPI_Comm_rank()', 'MPI_Comm_size()',
'MPI_Comm_split()', 'MPI_Errhandler_create()', 'MPI_Errhandler_set()',
'MPI_Finalize()', 'MPI_Group_translate_ranks()', 'MPI_Init()',
'MPI_Irecv()', 'MPI_Isend()', 'MPI_Recv()', 'MPI_Reduce()',
'MPI_Send()', 'MPI_Ssend()', 'MPI_Waitall()'.  In addition, if
'./configure' is passed the '--with-mpi-wtime' option as described in
*note configure::, then _all_ backends that utilize the coNCePTuaL
run-time library, including 'c_mpi', will use 'MPI_Wtime()' for taking
performance measurements.

* Menu:

* Command-line options for c_mpi::  Control over the generated C+MPI code
* Implementation of reductions::  How c_mpi implements the REDUCE statement
* Implementation of multicasts::  How c_mpi implements the MULTICAST statement


File: conceptual.info,  Node: Command-line options for c_mpi,  Next: Implementation of reductions,  Prev: The c_mpi backend,  Up: The c_mpi backend

Command-line options for 'c_mpi'
................................

When 'ncptl' is passed '--backend=c_mpi' as a command-line option,
'c_mpi' processes the following backend-specific command-line options:

'--ssend'
     In the generated code, 'MPI_Isend()' and 'MPI_Irecv()' are used for
     asynchronous communication and 'MPI_Send()' and 'MPI_Recv()' are
     normally used for synchronous communication.  However, the
     'c_mpi'-specific compiler option '--ssend' instructs 'c_mpi' to
     replace all calls to 'MPI_Send()' in the generated code with calls
     to 'MPI_Ssend()', MPI's synchronizing send function.  A program's
     log files indicate whether the program was built to use
     'MPI_Send()' or 'MPI_Ssend()'.

'--reduce=MPI_OP'
     The default reduction operation is 'MPI_SUM' but a different
     operation can be specified using the 'c_mpi'-specific '--reduce'
     compiler option.  A program's log files indicate the reduction
     operation that was used.


File: conceptual.info,  Node: Implementation of reductions,  Next: Implementation of multicasts,  Prev: Command-line options for c_mpi,  Up: The c_mpi backend

Implementation of reductions
............................

The 'c_mpi' backend implements the coNCePTuaL 'REDUCE' statement (*note
Reducing::) as follows.  Many-to-one reductions are implemented with a
single call to 'MPI_Reduce()'.  Many-to-many reductions in which the
sources exactly match the targets are implemented with a single call to
'MPI_Allreduce()'.  All other reductions are implemented by calling
'MPI_Reduce()' to reduce the data to the first target task then
'MPI_Bcast()' to distribute the reduced data to the remaining targets.

   Because MPI requires that the source and target buffers in an
'MPI_Reduce()' or 'MPI_Allreduce()' be different, the 'c_mpi' backend
utilizes _two_ buffers when 'UNIQUE' (*note Unique messages::) is
specified.  It utilizes two _adjacent_ buffers when 'FROM BUFFER' or
'INTO BUFFER' (*note Buffer control::) is specified.


File: conceptual.info,  Node: Implementation of multicasts,  Prev: Implementation of reductions,  Up: The c_mpi backend

Implementation of multicasts
............................

The 'MULTICAST' statement (*note Multicasting::) enables any set of
tasks to transmit data to any other set of tasks.  The 'c_mpi' backend
implements 'MULTICAST' using the simpler 'MPI_Bcast()' when there is a
single initiator (determined dynamically at run time) and
'MPI_Alltoallv()' otherwise.  In all cases, 'c_mpi' creates an MPI
communicator that contains exactly the tasks involved in the multicast
(as senders and/or receivers).

   MPI requires that all tasks involved in an 'MPI_Bcast()' belong to
the same MPI communicator.  Hence, in the coNCePTuaL statement

     TASK 4 MULTICASTS A 64 KILOBYTE MESSAGE TO TASKS r SUCH THAT r
     IS IN {1, 3, 5, 7, 9}

the generated communicator contains tasks 1, 3, 4, 5, 7, and 9, even
though task 4 transmits but does not receive any data.

   Rather than repeatedly call 'MPI_Bcast()', many-to-one and
many-to-many multicasts such as

     TASKS from_tasks SUCH THAT from_tasks < 8 MULTICAST 3 2-KILOBYTE
     MESSAGES to TASKS to_tasks SUCH THAT 3 DIVIDES to_tasks

perform a single 'MPI_Alltoallv()'.  Two message buffers are used in
this case, one for all outgoing data and one for all incoming data.


File: conceptual.info,  Node: The c_udgram backend,  Next: The c_trace backend,  Prev: The c_mpi backend,  Up: Supplied backends

3.3.3 The 'c_udgram' backend
----------------------------

coNCePTuaL program development on a workstation is facilitated by the
'c_udgram' backend.  'c_udgram' runs on only a single machine but,
unlike 'c_seq', supports all of coNCePTuaL's communication statements.
Communication is performed over Unix-domain datagram sockets.
Unix-domain datagrams are reliable and guarantee order (unlike UDP/IP
datagrams) but have a maximum packet size.  'c_udgram' backend write
this maximum to every log file and automatically packetizes larger
messages.

   By default, 'c_udgram' produces an executable program that can be run
directly from the command line.  When 'ncptl' is run with the
'--no-link' option, 'c_udgram' produces an object file that needs to be
linked with the appropriate sockets library (on systems that require a
separate library for socket calls).  When 'ncptl' is run with the
'--no-compile' option, 'c_udgram' outputs ANSI C code that must be both
compiled and linked.  Like all C-based backends, 'c_udgram' honors the
'CC', 'CPPFLAGS', 'LDFLAGS', and 'LIBS' environment variables when
compiling and linking.  Values not found in the environment are taken
from those specified/discovered at configuration time (*note
configure::).

   In addition to supporting the default set of command-line options,
programs generated using the 'c_udgram' backend further support a
'--tasks' option that designates the number of tasks to use:

       -T, --tasks=<number>        Number of tasks to use [default: 1]

'c_udgram' programs spawn one OS-level process for each task in the
program.  They also create a number of sockets in the current directory
named 'c_udgram_<TAG>'.  These are automatically deleted if the program
exits cleanly but will need to be removed manually in the case that the
program is killed by an non-trappable signal.

* Menu:

* Implementation of collectives::  How c_udgram implements collective operations


File: conceptual.info,  Node: Implementation of collectives,  Prev: The c_udgram backend,  Up: The c_udgram backend

Implementation of collectives
.............................

The 'c_udgram' normally uses logarithmic-time algorithms for multicasts
(*note Multicasting::), reductions (*note Reducing::), and barriers
(*note Synchronizing::).  One-to-many multicasts disperse data in a
binary-tree pattern.  Reductions reduce data in a binary-tree pattern to
the root, which then disperses the data in a binary-tree pattern in the
many-to-many case.  Barriers synchronize in a butterfly pattern.  The
only non-logarithmic-time algorithm is for many-to-many multicasts,
which are implemented as one logarithmic-time, one-to-many multicast for
each sender.


File: conceptual.info,  Node: The c_trace backend,  Next: The c_profile backend,  Prev: The c_udgram backend,  Up: Supplied backends

3.3.4 The 'c_trace' backend
---------------------------

While most coNCePTuaL backends are code generators, the 'c_trace'
backend adds tracing code to the code produced by a code-generating
backend.  'c_trace' is useful as a debugging aid and as a means to help
understand the control flow of a coNCePTuaL program.

* Menu:

* Command-line options for c_trace::  Compiling with tracing enabled
* Default c_trace tracing::     Tracing to the standard error device
* c_trace tracing with curses::  Interactively tracing a live program
* Offline tracing with curses::  Playing back trace data interactively


File: conceptual.info,  Node: Command-line options for c_trace,  Next: Default c_trace tracing,  Prev: The c_trace backend,  Up: The c_trace backend

Command-line options for 'c_trace'
..................................

When 'ncptl' is passed '--backend=c_trace' as a command-line option,
'c_trace' processes the following backend-specific command-line options:

'--trace=BACKEND'
     Specify a backend that will produce C code for 'c_trace' to trace.
     The '--trace' option is required to use 'c_trace'; 'c_trace' will
     issue an error message if '--trace' is not specified.  The
     restrictions on BACKEND are that it must produce C code and must be
     derived from the 'c_generic' backend (*note Backend creation::).
     Improper backends cause 'c_trace' to abort abnormally.

'--curses'
     Instead of injecting 'fprintf()' statements into the generated
     C code, inject calls to the 'curses' (or 'ncurses') library to show
     graphically the line of code currently executing on a given
     processor.


File: conceptual.info,  Node: Default c_trace tracing,  Next: c_trace tracing with curses,  Prev: Command-line options for c_trace,  Up: The c_trace backend

Default 'c_trace' tracing
.........................

Without '--curses', 'c_trace' alters the generated C code to write data
like the following to the standard error device:

     [TRACE] phys: 1 | virt: 1 | action: RECV | event: 1 / 44001 | lines: 18 - 18
     [TRACE] phys: 0 | virt: 0 | action: RESET | event: 1 / 88023 | lines: 17 - 17
     [TRACE] phys: 0 | virt: 0 | action: SEND | event: 2 / 88023 | lines: 18 - 18
     [TRACE] phys: 0 | virt: 0 | action: RECV | event: 3 / 88023 | lines: 19 - 19
     [TRACE] phys: 1 | virt: 1 | action: SEND | event: 2 / 44001 | lines: 19 - 19
     [TRACE] phys: 1 | virt: 1 | action: RECV | event: 3 / 44001 | lines: 18 - 18
     [TRACE] phys: 0 | virt: 0 | action: CODE | event: 4 / 88023 | lines: 20 - 21
     [TRACE] phys: 0 | virt: 0 | action: RESET | event: 5 / 88023 | lines: 17 - 17
     [TRACE] phys: 0 | virt: 0 | action: SEND | event: 6 / 88023 | lines: 18 - 18
     [TRACE] phys: 0 | virt: 0 | action: RECV | event: 7 / 88023 | lines: 19 - 19
                                            .
                                            .
                                            .

The format is designed to be easy to read and easy for a program to
parse.  Each line of trace data begins with the string '[TRACE]' and
lists the (physical) processor number, the (virtual) task ID, the action
(a.k.a., event type) that is about to be performed, the current event
number and total number of events that will execute on the given
processor, and the range of lines of source code to which the current
event corresponds.  An "event" corresponds more-or-less to a statement
in the coNCePTuaL language.(1)  Loops are unrolled at initialization
time and therefore produce no events.  *note Event types::, lists and
briefly describes the various event types.

   ---------- Footnotes ----------

   (1) A more precise correspondence is to a <SIMPLE_STMT> in the formal
grammar presented in *note Grammar::.


File: conceptual.info,  Node: c_trace tracing with curses,  Next: Offline tracing with curses,  Prev: Default c_trace tracing,  Up: The c_trace backend

'c_trace' tracing with 'curses'
...............................

The '--curses' option enables a more interactive tracing environment.
Generated programs must be linked with the 'curses' (or compatible, such
as 'ncurses') library.  The resulting executable supports the following
additional command-line options:

     '-D', '--delay=NUMBER' delay in milliseconds after each screen
     update ('0'=no delay)

     '-M', '--monitor=NUMBER' processor number to monitor

     '-B', '--breakpoint=NUMBER' source line at which to enter
     single-stepping mode ('-1'=none; '0'=first event)

   When the program is run it brings up a screen like the following:

      1.  # Determine computational "noise"
      2.
      3.  Require language version "1.5".
      4.
      5.  accesses is "Number of data accesses to perform" and comes from
      6.    "--accesses" or "-a" with default 500000.
      7.
      8.  trials is "Number of timings to take" and comes from "--timings" or
      9.    "-t" with default 1000.
     10.
     11.  For trials repetitions {
     12.    all tasks reset their counters then
     13.    all tasks touch a 1 word memory region accesses times with stride 0 w
     14.    all tasks log a histogram of elapsed_usecs as "Actual time (usecs)"
     15.  }


     Phys: 0  Virt: 0  Action: RESET    Event:    1/3001

The program displays its source code (truncated vertically if too tall
and truncated horizontally if too wide) at the top of the screen and a
status bar at the bottom of the screen.  As the program executes, a
cursor indicates the line of source code that is currently executing.
Likewise, the status bar updates dynamically to indicate the processor's
current task ID, action, and event number.  In 'curses' mode, the
program's standard output (*note Writing to standard output::) is
suppressed so as not to disrupt the trace display.

   Programs traced with 'c_trace' and the '--curses' option are made
interactive and support the following (case-insensitive) keyboard
commands:

'S'
     Enable single-stepping mode.  While single-stepping mode is enabled
     the traced processor will execute only one event per keystroke from
     the user.

'SPACE'
     Disable single-stepping mode.  The program executes without further
     user intervention.

'D'
     Delete the breakpoint.

'Q'
     Quit the program.  The log file will indicate that the program did
     not run to completion.

All other keystrokes cause the program to advance to the next event
immediately.

   A single breakpoint can be set using the program's '-B' or
'--breakpoint' command-line option.  Whenever the monitored processor
reaches the source-code line at which a breakpoint has been set, it
enters single-stepping mode exactly as if 'S' were pressed.  Setting a
breakpoint at line 0 tells the program to begin single-stepping as soon
as the program begins.  Note that only lines corresponding to coNCePTuaL
events can support breakpoints.


File: conceptual.info,  Node: Offline tracing with curses,  Prev: c_trace tracing with curses,  Up: The c_trace backend

Offline tracing with 'curses'
.............................

The 'c_trace' backend can be told to trace by writing messages to the
standard error device (*note Default c_trace tracing::) or by employing
an interactive display (*note c_trace tracing with curses::).  These two
alternatives can be combined to support offline tracing of a coNCePTuaL
program.  The idea is to compile the program without the '--curses'
option.  When running the program, the standard-error output should be
redirected to a file.  The 'ncptl-replaytrace' utility, which comes with
coNCePTuaL, can then be used to play back the program's execution by
reading and displaying the file of redirected trace data.

   'ncptl-replaytrace' accepts the following command-line options, which
correspond closely to those accepted by a program compiled with the
'--curses' option to 'c_trace' (*note c_trace tracing with curses::):

'--trace'
     Specify a file containing redirected trace data.  FILE defaults to
     the standard input device.

'--delay'
     Specify the delay in milliseconds after each screen update ('0'=no
     delay).

'--monitor'
     Specify the processor number to monitor.  PROCESSOR defaults to
     '0'.

'--breakpoint'
     Specify a line of source code at which to enter single-stepping
     mode ('-1'=none; '0'=first event).

In addition, 'ncptl-replaytrace' requires that the coNCePTuaL
source-code file be specified on the command line, as the source code is
not included in the trace data.

   The interactive display presented by the offline 'ncptl-replaytrace'
tool is nearly identical to that presented by a program compiled with
the '--curses' option to 'c_trace'.  *Note c_trace tracing with
curses::, for a usage description.


File: conceptual.info,  Node: The c_profile backend,  Next: The interpret backend,  Prev: The c_trace backend,  Up: Supplied backends

3.3.5 The 'c_profile' backend
-----------------------------

Profiling communication events can help explain surprising performance
measurements.  A profiling tool that automatically instruments
coNCePTuaL programs is simpler than manually adding 'LOGS' or 'OUTPUTS'
statements to an existing program.

   Like the 'c_trace' backend (*note The c_trace backend::), the
'c_profile' backend adds code to that produced by other backends.  The
'c_profile' backend accepts a single--mandatory--command-line argument,
'--profile=BACKEND', which designates a target backend to use.  The
restrictions on BACKEND are that it must produce C code and must be
derived from the 'c_generic' backend (*note Backend creation::).
Improper backends cause 'c_profile' to abort abnormally.

   If the profiled coNCePTuaL program produces log files, the log files
will include profiling information in the epilogue, one line for each
event type that was used at least once by the corresponding process.
(*note Event types::, lists and briefly describes the various event
types.)  Each line names an event and presents the total number of
microseconds spent processing that event, a tally of the number of times
that event type was executed, and the quotient of those two numbers.  In
addition, the amount of memory used to store the event list is also
logged.

   For example, the following extract from a log file indicates that the
process that wrote it spent a total of 6.7s processing 22,000 'RECV'
events (which includes waiting time) for an average of 303.5us per
'RECV' event:

     # Profile of SEND (microseconds, count, average): 5267469 22001 239.4
     # Profile of RECV (microseconds, count, average): 6676521 22000 303.5
     # Profile of REPEAT (microseconds, count, average): 11985167 1 11985167.0
     # Profile of NEWSTMT (microseconds, count, average): 43 1 43.0
     # Profile of CODE (microseconds, count, average): 5516 1 5516.0
     # Profile of event memory: 528 bytes (6 events * 88 bytes/event)

   Each 'REPEAT' event includes the time for all of the events that it
repeats.

   Although the preceding log-file excerpt indicates that a total of
22001+22000+1+1+1 = 44004 events were executed, the 'event memory' line
clarifies that the event list contained only 6 unique events and
therefore required only 528 bytes of memory.

   Profiled programs that do not produce log files write profiling
information to the standard error device.  Because all processes may
share a single standard error device, each line of output is preceded by
a processor ID as in the following example:

     1 SEND 5527125 22000 251.2
     1 RECV 6322699 22001 287.4
     1 REPEAT 11894523 1 11894523.0
     1 event-memory 352 4 88
     0 SEND 5267469 22001 239.4
     0 RECV 6676521 22000 303.5
     0 REPEAT 11985167 1 11985167.0
     0 event-memory 352 4 88

The columns are PROCESSOR ID, EVENT, TOTAL MICROSECONDS, TALLY, and
AVERAGE MICROSECONDS except when EVENT is 'event-memory' in which case
the columns are PROCESSOR ID, 'event-memory', TOTAL BYTES, NUMBER OF
EVENTS, and BYTES PER EVENT.  The intention is for the output to be
easily parseable using tools such as 'awk'.


File: conceptual.info,  Node: The interpret backend,  Next: The stats backend,  Prev: The c_profile backend,  Up: Supplied backends

3.3.6 The 'interpret' backend
-----------------------------

Like the 'c_udgram' backend (*note The c_udgram backend::), the
'interpret' backend is designed to help programmers ensure the
correctness of coNCePTuaL code.  The 'interpret' backend does not output
code.  As its name implies, 'interpret' is an _interpreter_ of
coNCePTuaL programs rather than a compiler.  'interpret' exhibits the
following salient features:

  1. Some programs run faster than with a compiler because the
     interpreter does not actually send messages.  'interpret' merely
     simulates communication.  It also skips over statements such as
     'COMPUTES'/'SLEEPS' (*note Delaying execution::) and 'TOUCHES'
     (*note Touching memory::).

  2. 'interpret' can simulate massively parallel computer systems from a
     single process.

  3. As 'interpret' runs it checks for common communication errors such
     as deadlocks, asynchronous sends and receives that are never
     completed, and blocking operations left over at the end of the
     program (which would likely cause hung tasks under a real messaging
     layer).

The drawbacks are that 'interpret' is slow when interpreting
control-intensive programs and that timing measurements are not
indicative of any real network.  (The 'interpret' backend utilizes
logical time rather than physical time.)  'interpret' is intended
primarily as a development tool for helping ensure the correctness of
coNCePTuaL programs.

   The 'interpret' backend accepts all of the command-line options
described in *note Running coNCePTuaL programs::, plus the following
four options:

       -H, --hierarchy=<string>     Latency hierarchy as a comma-separated list
                                    of task_factor:latency_delta pairs [default:
                                    "tasks:1"]
       -K, --kill-reps=<number>     If nonzero, perform FOR...REPETITIONS loop
                                    bodies exactly once [default: 0]
       -M, --mcastsync=<number>     Perform an implicit synchronization after a
                                    multicast (0=no; 1=yes) [default: 0]
       -T, --tasks=<number>         Number of tasks to use [default: 1]

   Normally, the 'interpret' backend assigns unit latency to every
communication operation.  The '--hierarchy' option can make
communication with distant tasks observe more latency than communication
with nearby tasks.  An explanation of the argument to '--hierarchy' is
presented in *note Task latency hierarchies::.

   To save execution time, the '--kill-reps' option alters the behavior
of all 'FOR'...'REPETITIONS' statements in the program, treating them as
if they read, 'FOR 1 REPETITION'.  That is, it ignores warmup
repetitions, synchronizations, and the specified number of repetitions,
always using '1' instead.

   A multicast operation (*note Multicasting::) is normally treated as
multiple point-to-point operations with the same send time.  The
'--mcastsync' option instructs the 'interpret' backend to perform an
implicit barrier synchronization at the end of the multicast.

   The '--tasks' option specifies the number of tasks to simulate.
Because this number can be quite large the 'NCPTL_LOG_ONLY' environment
variable (*note Environment Variables::) may be used to limit the set of
processors that are allowed to create log files.  That way, if task 0 is
the only task out of thousands that logs any data, 'NCPTL_LOG_ONLY' can
specify that only one log file will be produced, not thousands.  By
default, all processors create a log file.

   All other command-line arguments are passed to the program being
interpreted.

   The '--output' option described in *note Compiling coNCePTuaL
programs::, has special meaning to the 'interpret' backend.  When
'--output' is used, 'interpret' dumps a list of events to the specified
file after a successful run.  For example, the coNCePTuaL program 'ALL
TASKS t ASYNCHRONOUSLY SEND A 384 BYTE MESSAGE TO TASK t XOR 2 THEN ALL
TASKS AWAIT COMPLETION' results in the following event dump:

     Task 0 posted a NEWSTMT at time 0 and completed it at time 0
     Task 0 posted a RECEIVE at time 0 and completed it at time 0
     Task 0 posted a SEND at time 1 and completed it at time 1
     Task 0 posted a WAIT_ALL at time 2 and completed it at time 2
     Task 1 posted a NEWSTMT at time 0 and completed it at time 0
     Task 1 posted a RECEIVE at time 0 and completed it at time 0
     Task 1 posted a SEND at time 1 and completed it at time 1
     Task 1 posted a WAIT_ALL at time 2 and completed it at time 2
     Task 2 posted a NEWSTMT at time 0 and completed it at time 0
     Task 2 posted a RECEIVE at time 0 and completed it at time 0
     Task 2 posted a SEND at time 1 and completed it at time 1
     Task 2 posted a WAIT_ALL at time 2 and completed it at time 2
     Task 3 posted a NEWSTMT at time 0 and completed it at time 0
     Task 3 posted a RECEIVE at time 0 and completed it at time 0
     Task 3 posted a SEND at time 1 and completed it at time 1
     Task 3 posted a WAIT_ALL at time 2 and completed it at time 2

   As an example of the 'interpret' backend's usage, here's how to
simulate 100,000 processors communicating in a simple ring pattern:

     % ncptl --backend=interpret --lenient --program='All tasks t send
         nummsgs 1024 gigabyte messages to task t+1 then task num_tasks-1
         sends nummsgs 1024 gigabyte messages to task 0.' --tasks=100000
         --nummsgs=5

The preceding command ran to completion in under 5 minutes on a 1.5GHz
Xeon uniprocessor workstation--not too bad considering that
488 petabytes of data are transmitted on the program's critical path.

   The 'interpret' backend is especially useful for finding
communication-related program errors:

     % ncptl --backend=interpret --quiet --program='All tasks t send
         a 10 doubleword message to task (t+1) mod num_tasks.' --tasks=3
     <command line>: The following tasks have deadlocked: 0 --> 2 --> 1
         --> 0

Deadlocked tasks are shown with '-->' signifying "is blocked waiting
for".  In the preceding example, all receives are posted before all
sends.  Hence, task 0 is blocked waiting for task 2 to send it a
message.  Task 2, in turn, is blocked waiting for task 1 to sent it a
message.  Finally, task 1 is blocked waiting for task 0 to send it a
message, which creates a cycle of dependencies.

   The 'interpret' backend can find other errors, as well:

     % ncptl --backend=interpret --quiet --program='All tasks t
         asynchronously send a 10 doubleword message to task (t+1) mod
         num_tasks.' --tasks=4
     <command line>: The program ended with the following leftover-event
         errors:
        * Task 0 posted an asynchronous RECEIVE that was never waited for
        * Task 0 posted an asynchronous SEND that was never waited for
        * Task 0 sent a message to task 1 that was never received
        * Task 1 posted an asynchronous RECEIVE that was never waited for
        * Task 1 posted an asynchronous SEND that was never waited for
        * Task 1 sent a message to task 2 that was never received
        * Task 2 posted an asynchronous RECEIVE that was never waited for
        * Task 2 posted an asynchronous SEND that was never waited for
        * Task 2 sent a message to task 3 that was never received
        * Task 3 posted an asynchronous RECEIVE that was never waited for
        * Task 3 posted an asynchronous SEND that was never waited for
        * Task 3 sent a message to task 0 that was never received

(A message received 'ASYNCHRONOUSLY' is not considered received until
after the corresponding 'AWAITS COMPLETION'; hence, all of the 'was
never received' messages listed above.)

     % ncptl --backend=interpret --quiet --program='Task 0 sends a 40
         kilobyte message to unsuspecting task 1 then task 0 receives a 40
         kilobyte message from task 1.' --tasks=2
     <command line>: The program ended with the following leftover-event
         errors:
        * Task 0 sent a message to task 1 that was never received
        * Task 1 terminated before satisfying task 0's RECEIVE operation

   In short, it is well worth testing the correctness of new coNCePTuaL
programs with 'interpret' before performing timing runs with one of the
message-passing backends.

* Menu:

* Task latency hierarchies::    Specifying latency as a function of distance


File: conceptual.info,  Node: Task latency hierarchies,  Prev: The interpret backend,  Up: The interpret backend

Task latency hierarchies
........................

The 'interpret' backend normally simulates a flat network in which
communication between any two tasks takes unit latency.  However, the
'--hierarchy' option lets one specify a hierarchy of latencies: latency
l1 within a set of t1 tasks, latency l1+l2 within a set of t1*t2 tasks,
latency l1+l2+l3 within a set of t1*t2*t3 tasks, and so forth.

   The argument to '--hierarchy' is a comma-separated list of <TASK
FACTOR:LATENCY DELTA> pairs.  The LATENCY DELTA component is optional
and defaults to '1'.  If the list ends with '...', the final <TASK
FACTOR:LATENCY DELTA> pair is repeatedly indefinitely.  All TASK FACTOR
values must be positive integers, and all LATENCY DELTA values must be
nonnegative integers.

   As an example, '--hierarchy=4' (or '--hierarchy=4:1') partitions the
program's tasks into sets of four with one unit of additional latency to
communicate with another set.  Hence, tasks 0, 1, 2, and 3 can
communicate with each other in unit time, as can tasks 4, 5, 6, and 7.
However, communication between any task in the first set and any task in
the second set (e.g., between tasks 3 and 4) takes an additional unit of
time for a total latency of two units.

   As a more complex example, consider a cluster of symmetric
multiprocessors (SMPs) in which each SMP comprises two processor sockets
with each socket containing a quad-core processor (four CPUs).  Further
assume that the SMPs are networked together via a fat-tree network
consisting of 12-port switches.  In this example, let's say that it
takes unit latency to communicate within a socket, two units of latency
to communicate with another socket in the same SMP, and an additional
three units of latency to traverse each switch.  This configuration can
be specified to the 'interpret' backend as
'--hierarchy="4:1, 2:1, 12:3, 12:6, ..."' (or simply
'--hierarchy=4,2,12:3,12:6, ...').  With this setting, task 0, for
instance, communicates with tasks 1-3 in 1 time unit, with tasks 4-7 in
2 time units, with tasks 8-95 in 5 time units (one switch crossing),
with tasks 96-1151 in 11 time units (three switch crossings--a level 0
switch, a level 1 switch, and another level 0 switch), with
tasks 1152-13,823 in 17 time units (five switch crossings--of switch
levels 0, 1, 2, 1, and 0), and so forth.


File: conceptual.info,  Node: The stats backend,  Next: The picl backend,  Prev: The interpret backend,  Up: Supplied backends

3.3.7 The 'stats' backend
-------------------------

The 'stats' backend outputs various statistics about a coNCePTuaL
program.  It can be used to help verify a program's correctness or
merely to search for interesting patterns within a complex communication
pattern.  The following is some sample output from a program compiled
with 'stats':

     Execution parameters
     --------------------
       Number of processors:          16
       Random-number seed:   -1727114895
       Command line:         ncptl --backend=stats hycom.ncptl --xdim=4 --ydim=4 --tasks=16 --iter=10
       Timestamp:            Wed Jan  4 17:32:04 2006

     Message traffic
     ---------------
       Total messages sent:           710
       Total bytes sent:          1454080
       Unique message sizes sent: 2048

     Per-processor message traffic
     -----------------------------
       Processors sending a total of 61440 bytes:    0
       Processors sending a total of 81920 bytes:    1-3, 12-15
       Processors sending a total of 102400 bytes:   4-11
       Processors receiving a total of 61440 bytes:  1-3, 13-15
       Processors receiving a total of 81920 bytes:  5-7, 9-11
       Processors receiving a total of 122880 bytes: 12
       Processors receiving a total of 143360 bytes: 4, 8
       Processors receiving a total of 184320 bytes: 0
       Processors sending a total of 30 messages:    0
       Processors sending a total of 40 messages:    1-3, 12-15
       Processors sending a total of 50 messages:    4-11
       Processors receiving a total of 30 messages:  1-3, 13-15
       Processors receiving a total of 40 messages:  5-7, 9-11
       Processors receiving a total of 60 messages:  12
       Processors receiving a total of 70 messages:  4, 8
       Processors receiving a total of 90 messages:  0

     Processor SEND-event peers
     --------------------------
       Processors posting SEND events to offsets {-12, -4, +1, +3}:    12
       Processors posting SEND events to offsets {-8, -4, +1, +3, +4}: 8
       Processors posting SEND events to offsets {-4, -3, -1}:         15
       Processors posting SEND events to offsets {-4, -3, -1, +4}:     7, 11
       Processors posting SEND events to offsets {-4, -2, -1, +1}:     14
       Processors posting SEND events to offsets {-4, -2, -1, +1, +4}: 6, 10
       Processors posting SEND events to offsets {-4, -1, +1}:         13
       Processors posting SEND events to offsets {-4, -1, +1, +4}:     5, 9
       Processors posting SEND events to offsets {-4, +1, +3, +4}:     4
       Processors posting SEND events to offsets {-3, -1, +4}:         3
       Processors posting SEND events to offsets {-2, -1, +1, +4}:     2
       Processors posting SEND events to offsets {-1, +1, +4}:         1
       Processors posting SEND events to offsets {+1, +3, +4}:         0

     Network bisection crossings
     ---------------------------
       Bisection messages:    100
       Bisection bytes:    204800

     Event tallies
     -------------
       Total number of LOG events:       10
       Total number of NEWSTMT events:   48
       Total number of RECEIVE events:  710
       Total number of RESET events:     10
       Total number of SEND events:     710
       Total number of WAIT_ALL events: 480

     Per-processor event sets
     ------------------------
       Processors executing only {LOG, NEWSTMT, RECEIVE, RESET, SEND, WAIT_ALL}: 0
       Processors executing only {NEWSTMT, RECEIVE, SEND, WAIT_ALL}:             1-15

     Per-processor event tallies
     ---------------------------
       Processors executing 10 LOG events:      0
       Processors executing 3 NEWSTMT events:   0-15
       Processors executing 30 RECEIVE events:  1-3, 13-15
       Processors executing 40 RECEIVE events:  5-7, 9-11
       Processors executing 60 RECEIVE events:  12
       Processors executing 70 RECEIVE events:  4, 8
       Processors executing 90 RECEIVE events:  0
       Processors executing 10 RESET events:    0
       Processors executing 30 SEND events:     0
       Processors executing 40 SEND events:     1-3, 12-15
       Processors executing 50 SEND events:     4-11
       Processors executing 30 WAIT_ALL events: 0-15

   'stats' is derived from 'interpret' (*note The interpret backend::)
and therefore supports the 'interpret' backend's options as well as the
standard options described in *note Running coNCePTuaL programs::.
However, because 'stats' does not produce log files, the '--logfile'
option is absent.  'stats' additionally supports the following three
command-line options:

       -E, --expand-lists=<number>     0=collapse lists of numbers into ranges;
                                       1=show all numbers [default: 0]
       -F, --format=<string>           Output format, either "text", "excelcsv",
                                       or "sep:<string>" [default: "text"]
       -X, --exclude=<string>          Name of a category or individual field to
                                       exclude from output [default: ""]

   The '--expand-lists' option tells the 'stats' backend whether it
should output sets of numbers as comma-separated ranges
(e.g., '1-3, 12-15') or as individual numbers (e.g., '1, 2, 3, 12, 13,
14, 15').  The '--format' option specifies the output format.  By
default, it outputs human-readable text, as shown in the above example.
However, '--format=excelcsv' outputs the data in comma-separated value
format suitable for loading directly into Microsoft Excel.  A more
general form of computer-parseable output is specified with the 'sep'
sub-option, which takes a separator string as a sub-option.  For
example, '--format=sep:"#"' produces output like the following:

     "Event tallies"#"Total number of LOG events"#10
     #"Total number of NEWSTMT events"#48
     #"Total number of RECEIVE events"#710
     #"Total number of RESET events"#10
     #"Total number of SEND events"#710
     #"Total number of WAIT_ALL events"#480

The difference between '--format=excelcsv' and '--format=sep:","' is
that the former employs a number of bizarre special cases when quoting
strings so as to coerce Excel into properly processing the file.  The
latter simply inserts a comma between columns with no special string
processing other than preceding the characters '"' and '\' with '\'.

   The 'stats' backend issues a 'Column separator SEP appears within a
field' warning if the separator string appears in any of the output
fields.  (Note that it will always appear in the 'Command line' line
because the '--format' line is specified on the command line.)  The idea
is to warn the user that automatic parsing of the output (e.g., using
'awk') may need to be careful when processing lines containing such
fields.

   As can be seen from the sample output, 'stats' outputs a lot of
information.  The '--exclude' option--which can be specified repeatedly
on the command line--provides the user with fine-grained control over
which output to suppress.  For example,
'--exclude="Total number of NEWSTMT events"' tells 'stats' not to output
the line with that key.  Similarly,
'--exclude="Processor SEND-event peers"' eliminates an entire category
of information.


File: conceptual.info,  Node: The picl backend,  Next: The paraver backend,  Prev: The stats backend,  Up: Supplied backends

3.3.8 The 'picl' backend
------------------------

PICL, the Portable Instrumented Communication Library, defines a trace
file format that records an execution trace of a message-passing
application.  In particular, MPICL is an MPI-specific implementation of
PICL that facilitates instrumenting MPI programs.  Normally, one passes
a PICL file to a performance-visualization tool such as ParaGraph, which
renders the trace data using any of a number of graphical views.

   Although MPICL is compatible with the 'c_mpi' backend (*note The
c_mpi backend::), coNCePTuaL provides a 'picl' backend that produces
PICL files directly.  The intention is to use the PICL format to
represent an idealized view of a communication pattern rather than to
store a time-sensitive execution trace.  For example, timing events
recorded by 'picl' occur at logical times instead of physical times and
statements such as 'COMPUTES'/'SLEEPS' (*note Delaying execution::) and
'TOUCHES' (*note Touching memory::) take either zero time or unit time,
depending upon a command-line option.  By providing an idealized view of
a communication pattern, 'picl' abstracts away timing artifacts so
events that one would expect to occur simultaneously are written to the
trace file as being exactly simultaneous.

   As an example, the following is the PICL output produced by passing
'picl' the coNCePTuaL program 'TASK 0 SENDS A 32 KILOBYTE MESSAGE TO
TASK 1 THEN TASK 1 SENDS A 256 BYTE MESSAGE TO TASK 0.':

     -3 -901 0.00000 0 0 0
     -3 -901 0.00000 1 1 0
     -3 -21 0.00001 0 0 4 2 32768 1 1 1
     -4 -21 0.00001 0 0 0
     -3 -52 0.00001 1 1 3 2 1 0 0
     -3 -52 0.00002 0 0 3 2 1 1 1
     -4 -52 0.00002 1 1 4 2 32768 1 0 0
     -3 -21 0.00002 1 1 4 2 256 1 0 0
     -4 -21 0.00002 1 1 0
     -4 -52 0.00003 0 0 4 2 256 1 1 1
     -4 -901 0.00003 1 1 0
     -4 -901 0.00004 0 0 0

See the PICL manual, 'A new PICL trace file format' (ORNL/TM-12125), for
a detailed description of the various fields used in the preceding trace
file.

   ParaGraph is a visualization tool that reads PICL trace files and
graphically displays/animates the corresponding execution in a variety
of formats.  Running ParaGraph on output from 'picl' makes it easy for a
coNCePTuaL programmer to explain complex communication patterns to other
people.

   'picl' is derived from 'interpret' (*note The interpret backend::)
and therefore supports the 'interpret' backend's '--tasks' and
'--mcastsync' options as well as the standard options described in *note
Running coNCePTuaL programs::.  However, because 'picl' does not produce
log files, the '--logfile' option is absent.  'picl' additionally
supports the following two command-line options:

       -A, --all-events=<number>     0=include only communication events;
                                     1=include all events  [default: 0]
       -F, --frequency=<number>      PICL event frequency (Hz) [default: 100000]

   By default, only communication events are written to the trace file.
If '--all-events' is set to '1' then all events are written to the trace
file.  Events not related to communication are defined to take unit
time.  Regardless of the setting of '--all-events', the 'OUTPUTS'
statement (*note Writing to standard output::) writes a PICL 'tracemsg'
event to the trace file.  A user can tell ParaGraph to pause
visualization at 'tracemsg' events, making it possible to isolate key
components of a coNCePTuaL program's execution.

   Because PICL events are marked with physical time (a floating-point
number of seconds) but 'picl' uses exclusively logical time, 'picl'
needs to associate a (fabricated) physical time with each logical time.
The '--frequency' option specifies that mapping.  By default, 'picl'
pretends that each unit of logical time corresponds to 1/100000 of a
second (i.e, 10 microseconds) of physical time.  As an example, the
default time step in ParaGraph is 1 microsecond; this can be specified
to 'picl' with '--frequency=1E6'.

   One of the goals of coNCePTuaL is to facilitate the explanation of
network performance tests.  The 'picl' backend aids in the explanation
by making it easy to show graphically how tasks communicate with each
other in an arbitrary coNCePTuaL program.


File: conceptual.info,  Node: The paraver backend,  Next: The latex_vis backend,  Prev: The picl backend,  Up: Supplied backends

3.3.9 The 'paraver' backend
---------------------------

The Paraver trace visualizer accepts a trace file format that records an
execution trace of a message-passing (or other) application and uses
that to display application timelines and statistical data.  Normally,
one uses an application-instrumentation tool such as Extrae to generate
Paraver traces, and Extrae is, in fact, compatible with programs
generated using the coNCePTuaL 'c_mpi' backend (*note The c_mpi
backend::).  However, the 'paraver' backend produces Paraver files
directly.  The intention is to use the Paraver format to represent an
idealized view of a communication pattern rather than to store a
time-sensitive execution trace.  For example, timing events recorded by
'paraver' occur at logical times instead of physical times and
statements such as 'COMPUTES'/'SLEEPS' (*note Delaying execution::) and
'TOUCHES' (*note Touching memory::) take either zero time or unit time,
depending upon a command-line option.  By providing an idealized view of
a communication pattern, 'paraver' abstracts away timing artifacts so
events that one would expect to occur simultaneously are written to the
trace file as being exactly simultaneous.

   As an example, the following is the Paraver output produced by
passing the 'paraver' backend the coNCePTuaL program, 'TASK 0 SENDS A 32
KILOBYTE MESSAGE TO TASK 1 THEN TASK 1 SENDS A 256 BYTE MESSAGE TO TASK
0.':

     #Paraver (06/01/2011 at 11:22):2001_ns:2(1,1):1:2(1:1,1:2),0
     3:1:1:1:1:0:0:2:1:2:1:1000:1000:32768:0
     2:1:1:1:1:0:1000000:6
     2:1:1:1:1:0:1000000:13
     2:2:1:2:1:0:1000000:6
     2:2:1:2:1:0:1000000:9
     1:1:1:1:1:0:1000:4
     1:2:1:2:1:0:1000:3
     3:2:1:2:1:1000:1000:1:1:1:1:2000:2000:256:0
     2:1:1:1:1:1000:1000000:9
     2:2:1:2:1:1000:1000000:13
     1:1:1:1:1:1000:2000:3
     1:2:1:2:1:1000:2000:4

The 'paraver' backend also generates an associated configuration file
that maps program state and event numbers to names and colors.  For
example, state 4 represents "blocking send" and is colored a neon
fuchsia in Paraver's graphical interface; event 1000000 represents
"coNCePTuaL," and event 1000000, value 13 represents a coNCePTuaL 'SEND'
event.  See the manual, 'Paraver Parallel Program Visualization and
Analysis Tool: Tracefile Description', for a detailed description of the
various fields used in the preceding trace file.

   'paraver' is derived from 'interpret' (*note The interpret backend::)
and therefore supports the 'interpret' backend's '--tasks' and
'--mcastsync' options as well as the standard options described in *note
Running coNCePTuaL programs::.  However, because 'paraver' does not
produce log files, the '--logfile' option is absent.  'paraver'
additionally supports the following two command-line options:

       -D, --dimemas-events=<number> 0=no Dimemas events; 1=extra events for
                                     Dimemas simulator [default: 0]
       -E, --conc-events=<number>    0=exclude names of coNCePTuaL event types;
                                     1=include them [default: 0]
       -O, --comp-time=<number>      Time spent in each non-communication event
                                     (ns) [default: 0]
       -P, --event-time=<number>     Paraver event time (ns) [default: 1000]
       -R, --conc-source=<number>    0=exclude references to coNCePTuaL source
                                     lines; 1=include them [default: 1]

   By default, only coNCePTuaL communication events are written to the
trace file.  If '--comp-time' is set to a positive integer then all
events are written to the trace file, and all non-communication events
take the specified amount of time.  Because Paraver events are marked
with physical time (a integral number of nanoseconds) but 'paraver' uses
exclusively logical time, 'paraver' needs to associate a (fabricated)
physical time with each logical time.  The '--event-time' option
specifies that mapping.  By default, 'paraver' pretends that each unit
of logical time corresponds to 1 microsecond (i.e, 1000 nanoseconds) of
physical time.  In addition to coNCePTuaL, Paraver also has a notion of
an "event."  The '--conc-source' and '--conc-events' options tell the
'paraver' backend which Paraver events to include in the trace file.  If
'--conc-source' is '1' (the default), Paraver will display text like the
following in its Info panel:

     User Event at 529,000 ns  myfile.ncptl source line Unknown value 203

which indicates that the most recently clicked time in the Paraver
timeline represents logical time 529 and corresponds to line 203 of
'myfile.ncptl'.  If '--conc-events' is '1', Paraver will display text
like the following in its Info panel:

     User Event at 529,000 ns  coNCePTuaL event RECEIVE

which indicates that the most recently clicked time in the Paraver
timeline represents logical time 529 and represents a coNCePTuaL
interpreter 'RECEIVE' event (*note The interpret backend::).  The
Dimemas network simulator accepts the same traces as the Paraver
visualizer but expects to see a number of additional events in the trace
file.  If '--dimemas-events' is '1', the 'paraver' backend will generate
those extra events.

   One of the goals of coNCePTuaL is to facilitate the explanation of
network performance tests.  The 'paraver' backend aids in the
explanation by making it easy to show graphically how tasks communicate
with each other in an arbitrary coNCePTuaL program.


File: conceptual.info,  Node: The latex_vis backend,  Next: The dot_ast backend,  Prev: The paraver backend,  Up: Supplied backends

3.3.10 The 'latex_vis' backend
------------------------------

The 'latex_vis' backend visualizes a program's communication pattern as
an Encapsulated PostScript time-space diagram.  The backend thereby
provides a static counterpart to the animated visualizations made
possible by the 'picl' and 'paraver' backends and the ParaGraph and
Paraver trace visualizers (*note The picl backend::, and *note The
paraver backend::).  'latex_vis' outputs LaTeX code with calls to the
PSTricks package (available from
<http://www.tug.org/applications/PSTricks/> but shipped with most LaTeX
distributions) to draw the figure, then runs 'latex' (or whatever the
'LATEX' environment variable is set to) to convert the '.tex' file to
DVI format and 'dvips' (or whatever the 'DVIPS' environment variable is
set to) to convert the '.dvi' file into EPS format.  Finally,
'latex_vis' runs the graphic through Ghostscript ('gs' or whatever the
'GS' environment variable is set to) to tighten the graphic's bounding
box.(1)  'latex_vis' requires that LaTeX and PSTricks be installed in
order to produce its visualizations.  However, it can still run with
'--no-compile' (*note Compiling coNCePTuaL programs::) to produce a
'.tex' file that can later be run manually through 'latex'.

   As an example, the following is the default 'latex_vis' output from
the coNCePTuaL program 'TASK 0 SENDS A 1 MEGABYTE MESSAGE TO TASK 1 THEN
ALL TASKS SYNCHRONIZE THEN TASK 1 SENDS A 3 KILOBYTE MESSAGE TO TASK 0'
when run with three tasks:


                                    |     (0)   (1)   (2)
                                    |        \
                                    |         \
                                               *
                                    T     (0)   (1)   (2)
                                    i
                                    m     ===============
                                    e
                                          (0)   (1)   (2)
                                    |          /
                                    |         /
                                    |        *
                                    V     (0)   (1)   (2)

Currently, the output diagram does not indicate message size but this
may change in a future release of 'latex_vis'.

   The 'latex_vis' backend has a number of uses.  First, it can be used
to illustrate a nontraditional communication pattern for a presentation,
research paper, or technical report.  Second, it can be used as a
teaching aid to demonstrate common communication patterns (e.g., a
butterfly pattern) to students.  Third, it can be used as a debugging
aid to ensure that a coNCePTuaL program is, in fact, performing the
expected communication operations.

   'latex_vis' is derived from 'interpret' (*note The interpret
backend::) and therefore supports the 'interpret' backend's '--tasks'
and '--mcastsync' options as well as the standard options described in
*note Running coNCePTuaL programs::.  (The 'interpret' backend's
'--kill-reps' option can be handy for reducing the picture's size by
showing only a single iteration of each loop.)  Because 'latex_vis' does
not produce log files, the '--logfile' option is absent.  'latex_vis'
additionally supports the following command-line options:

       -A, --annotate=<string>         Annotation level (0=no annotations;
                                       1=annotate communication events;
                                       2=annotate all events;
                                       "<event>..."=annotate only the
                                       specified events) [default: "0"]
       -B, --binary-tasks=<number>     Display task numbers in binary rather
                                       than decimal (0=decimal; 1=binary)
                                       [default: 0]
       -E, --every-event=<number>      Events requiring nonzero time to complete
                                       (0=only communication events;
                                       1=every event) [default: 0]
       -G, --stagger=<number>          Number of points by which to stagger
                                       overlapping arrows [default: 2]
       -L, --source-lines=<number>     Associate source-code line numbers with
                                       each event annotation (0=no; 1=yes)
                                       [default: 0]
       -R, --arrow-width=<string>      Python expression to map m, representing
                                       a message size in bytes, to an arrow
                                       width in points [default: "1"]
       -Z, --zero-latency=<number>     Depict communication as having zero
                                       latency (0=unit latency; 1=zero
                                       latency) [default: 0]

   In the preceding list a "point" refers to a PostScript point.  TeX
calls these "big points" and defines 1bp = 1/72")

   The '--annotate' option places adjacent to appropriate nodes in the
output diagram a list of textual annotations that indicate the
communication operations that were posted or completed and the
non-communication operations that were executed by the corresponding
task at the corresponding time.  Some sample annotations are 'Post
SEND', 'Complete SEND', and 'Execute OUTPUT'.  With '--annotate=1', only
communication events are annotated; with '--annotate=2', all events are
annotated;(2); otherwise, a list of specific events can be annotated.
For example, '--annotate=SYNC,MCAST' causes only the 'SYNC' and 'MCAST'
events to be annotated.  Compiling a coNCePTuaL program with the
'latex_vis' backend and the '--keep-ints' options (*note Compiling
coNCePTuaL programs::) produces a '.tex' file that contains in the
prologue comments a list of all events used by a program that were and
were not annotated.

   Task numbers are normally shown in base ten.  The '--binary-tasks'
option causes task numbers to be output in base two and using the same
number of bits for each task.  For example, a 3-task visualization with
'--binary-tasks' would number the tasks '00', '01', and '11'.

   Because 'latex_vis' is intended primarily for visualizing
communication patterns, by default only communication operations take
nonzero time to complete.  The '--every-event' option indicates that all
events--including local events such as 'SLEEP', 'COMPUTE', 'LOG', and
'OUTPUT'--should be deemed to complete in unit time.

   'latex_vis' output distinguishes coincident arrows (consider the
phrase 'TASK 0 ASYNCHRONOUSLY SENDS 5 MESSAGES TO TASK 1') by staggering
them slightly.  The '--stagger' option specifies the number of
PostScript points by which to stagger each overlapping arrow with a
default of 2 points.  Large stagger values are more visually distinctive
while small stagger values allow arrows to drift less from their
associated nodes.

   The '--source-lines' option, when used with '--annotate', augments
each event annotation with the corresponding line(s) of source code that
produced that event.  This feature improves the utility of 'latex_vis'
as a debugging aid for coNCePTuaL programs.

   By default, all arrows that indicate message transmissions are drawn
with equally thick line widths.  The '--arrow-width' option lets you
specify a Python function to map a message size in bytes, m, to a line
width in PostScript points, with the default being 1 point.  As a simple
example, '--arrow-width=2' doubles the arrow width for all message
(i.e., it represents the constant function f: m --> 2).  A more typical
example would be '--arrow-width="log10(m)"' (representing f: m -->
log10(m)), which causes a tenfold increase in message size to yield a
unit increase in line width.  The argument to '--arrow-width' can be any
Python expression using either built-in functions or functions from the
Python 'math' module.  See the Python library reference
(http://docs.python.org/lib/lib.html) for details.

   Normally, messages are considered to require one time unit to travel
from source to destination.  The '--zero-latency' option shows messages
as being received in the same timestep as they were sent.  Some
communication patterns are more aesthetically pleasing when drawn this
way.

* Menu:

* Further customizations::      Exploting ncptl's -filter option

   ---------- Footnotes ----------

   (1) If Ghostscript is not installed or fails to run, 'latex_vis'
issues a warning message, not an error message.  The figure is still
usable without a tight bounding box and a loose bounding box can be
corrected manually by editing the '%%BoundingBox:' line in the generated
EPS file.

   (2) To avoid the confusion of annotating what is essentially a "do
nothing" event, 'latex_vis' does not annotate the 'NEWSTMT' event, which
is injected at the beginning of each top-level statement.


File: conceptual.info,  Node: Further customizations,  Prev: The latex_vis backend,  Up: The latex_vis backend

Further customizations
......................

In addition to the options described above, the front end's '--filter'
option (*note Compiling coNCePTuaL programs::) is a useful mechanism for
customizing the formatting of the communication diagram.  For example,
specifying '--filter="s/rowsep=30bp/rowsep=1.5in/g"' increases the
separation between rows from 30bp (where 1bp = 1/72") to 1.5".  See the
PSTricks documentation (http://www.tug.org/applications/PSTricks/) for
more information about the PSTricks commands used in the generated
'.tex' files.

   To facilitate the use of '--filter', the 'latex_vis' backend uses a
helper macro ('\viscolor') to define colors.  '\viscolor' takes an
argument of the form 'NAME=COLOR' and defines a macro '\'NAME'color'
that expands to COLOR.  To further facilitate the use of '--filter', the
LaTeX code generated by the 'latex_vis' backend contains a number of
strategically placed placeholder comments of the form '% PLACEHOLDER:
TAG'.  A '--filter' command can thereby insert code into the document by
replacing an appropriate 'PLACEHOLDER' line.  In alphabetical order, the
currently defined placeholder tags are 'ANNOTATIONS', 'COLORS',
'COMMUNICATION', 'DEADLOCK', 'DOCUMENT', 'END', 'NODESHAPE', 'PACKAGES',
'PSMATRIX', 'TEXTOEPS', and 'TIMELINE'.  Look through any
'latex_vis'-generated '.tex' file to see where these are situated.  As
an example, the following command-line options define a "chartreuse"
color then change the color used to indicate point-to-point messages
from blue to chartreuse:

     --filter="s/% PLACEHOLDER: COLORS/\\newrgbcolor{chartreuse}{0.5 1 0}/"
     --filter="s/sendrecv=blue/sendrecv=chartreuse/"

(According to the PSTricks documentation
(http://www.tug.org/applications/PSTricks/), the predefined colors are
'red', 'green', 'blue', 'cyan', 'magenta', and 'yellow', and the
predefined grayscales are 'black', 'darkgray', 'gray', 'lightgray', and
'white'.)

   Tasks that are active at a given time are drawn using the '\task'
macro, which takes the task number as an argument.  Tasks that are idle
at a given time are drawn using the '\idle' macro, which is initially
defined to be the same as '\task'.  The following "cookbook" examples
showcase some of the ways that the power of LaTeX and PSTricks can be
exploited to display idle tasks in a variety of different styles (best
used with '--annotate=2'):

omitting idle tasks
     '--filter="s/\\let\\idle=\\task/\\newcommand*{\\idle}[1]{[mnode=R]}/"'

showing each idle task as a gray dot
     '--filter="s/\\let\\idle=\\task/\\newcommand*{\\idle}[1]{[mnode=dot,
     linecolor=gray]}/"'

drawing idle tasks with a dotted circle instead of a solid circle
     '--filter="s/\\let\\idle=\\task/\\newcommand*{\\idle}[1]
     {[linestyle=dotted]\\task{#1}}/"'

As an alternative to replacing the '\let\idle=\task' binding, the
preceding substitutions can be expressed as the insertion of a LaTeX
'\renewcommand'.  That is, idle tasks can also be omitted by specifying
'--filter="s/% PLACEHOLDER:
NODESHAPE/\\renewcommand*{\\idle}[1]{[mnode=R]}/"'.

   In short, the 'latex_vis' backend produces highly customizable
illustrations of communication patterns.  Because 'latex_vis' produces
commented LaTeX code, any customization not provided through the use of
'--filter' or one of the backend-specific command-line options is easily
performed by compiling with '--keep-ints' (*note Compiling coNCePTuaL
programs::) and editing the generated LaTeX code.


File: conceptual.info,  Node: The dot_ast backend,  Next: The libsea_ast backend,  Prev: The latex_vis backend,  Up: Supplied backends

3.3.11 The 'dot_ast' backend
----------------------------

dot is a format for describing graphs in terms of their edges and
vertices.  The tools in the Graphviz suite typeset dot files in a
variety of output formats and using a variety of graph-layout
algorithms.  coNCePTuaL's 'dot_ast' backend outputs in dot format the
abstract-syntax tree corresponding to a given coNCePTuaL program.  As an
example, 'dot_ast' renders the one-line coNCePTuaL program 'TASK 0
SLEEPS FOR 10 SECONDS' as follows:


                             +---------+       
                             | program |
                             +---------+     1)  TASK 0 SLEEPS FOR 10 SECONDS
                             | line 1  |
                             +---------+
                                  |
                                  V
                     +---------------------+----+
                     | top_level_stmt_list | 1L |
                     +---------------------+----+
                     |          line 1          |
                     +--------------------------+
                                  |
                                  V
                          +----------------+
                          | top_level_stmt |
                          +----------------+
                          |     line 1     |
                          +----------------+
                                  |
                                  V
                      +------------------+----+
                      | simple_stmt_list | 1L |
                      +------------------+----+
                      |        line 1         |
                      +-----------------------+
                                  |
                                  V
                           +-------------+
                           | simple_stmt |
                           +-------------+
                           |   line 1    |
                           +-------------+
                                  |
                                  V
                            +------------+
                            | sleeps_for |
                            +------------+
                            |   line 1   |
                            +------------+
                           /      |       \
                          /       V        \
          +--------------+    +--------+    +-----------+-----------+
          | source_task  |    |  expr  |    | time_unit | 'seconds' |
          +--------------+    +--------+    +-----------+-----------+
          |   line 1     |    | line 1 |    |        line 1         |
          +--------------+    +--------+    +-----------------------+
                  |               |
                  V               V
    +-----------+--------+    +-------------+
    | task_expr | 'expr' |    | ifelse_expr |
    +-----------+--------+    +-------------+
    |       line 1       |    |   line 1    |
    +--------------------+    +-------------+
              |                       |
              V                       V
          +--------+             +----------+
          |  expr  |             | add_expr |
          +--------+             +----------+
          | line 1 |             |  line 1  |
          +--------+             +----------+
              |                       |
              V                       V
       +-------------+          +-----------+
       | ifelse_expr |          | mult_expr |
       +-------------+          +-----------+
       |   line 1    |          |  line 1   |
       +-------------+          +-----------+
              |                       |
              V                       V
         +----------+           +------------+
         | add_expr |           | unary_expr |
         +----------+           +------------+
         |  line 1  |           |   line 1   |
         +----------+           +------------+
              |                       |
              V                       V
        +-----------+           +------------+
        | mult_expr |           | power_expr |
        +-----------+           +------------+
        |  line 1   |           |   line 1   |
        +-----------+           +------------+
              |                       |
              V                       V
        +------------+        +--------------+
        | unary_expr |        | primary_expr |
        +------------+        +--------------+
        |   line 1   |        |    line 1    |
        +------------+        +--------------+
              |                       |
              V                       V
        +------------+        +---------+-----+
        | power_expr |        | integer | 10L |
        +------------+        +---------+-----+
        |   line 1   |        |     line 1    |
        +------------+        +---------------+
              |
              V
       +--------------+
       | primary_expr |
       +--------------+
       |    line 1    |
       +--------------+
              |
              V
       +---------+----+
       | integer | 0L |
       +---------+----+
       |    line 1    |
       +--------------+

   'dot_ast' is expected to be of particular use to backend developers,
who can use it to help prioritize the methods that need to be
implemented (i.e., implementing first the AST node types needed by in a
trivial program, then those needed by successively more complex
programs).

   The 'dot_ast' backend accepts the following options from the 'ncptl'
command line:

'--format=DOT_FORMAT'
     The programs in the Graphviz suite can output graphs in a variety
     of formats such as PostScript, SVG, and PNG. By default, the
     'dot_ast' backend outputs PostScript.  The '--format' option
     specifies an alternate format to use.  At the time of this writing,
     the Graphviz programs support the following formats: 'canon',
     'cmap', 'dot', 'fig', 'gd', 'gd2', 'gif', 'hpgl', 'imap', 'ismap',
     'jpeg', 'jpg', 'mif', 'mp', 'pcl', 'pic', 'plain', 'plain-ext',
     'png', 'ps', 'ps2', 'svg', 'svgz', 'vrml', 'vtx', 'wbmp', and
     'xdot'.  See the Graphviz documentation for more information about
     these formats.

'--node-code=CHARACTERS'
     To facilitate associating nodes in the AST with fragments of the
     coNCePTuaL program being graphed, the 'dot_ast' backend provides a
     '--node-code' option that labels each node with the fragment of
     code to which it corresponds.  The argument to '--node-code' is a
     number of characters at which to truncate the code fragment or '-1'
     to inhibit truncation.  The purpose of truncation is to prevent
     excessively large nodes from disturbing the graph layout.  The
     <PROGRAM> node (*note Complete programs::), for example, includes
     the complete program source code if not truncated.

'--extra-dot=DOT_CODE'
     The 'dot_ast' backend's '--extra-dot' option enables the user to
     inject arbitrary dot code into the generated file.  For example,
     specifying '--extra-dot="node [shape=Mrecord]"'(1) tells dot to use
     draw nodes as rounded rectangles and specifying '--extra-dot='edge
     [color="green"]'' colors all edges green.  '--extra-dot' can be
     specified repeatedly on the command line; 'dot_ast' concatenates
     all of the extra dot code with intervening semicolons.

'--compress'
     Normally, every node of the AST is drawn.  The '--compress' option
     makes the resulting dot graph more readable by eliding chains of
     single-child nodes.  For example, '--compress' reduces the previous
     graph of 'TASK 0 SLEEPS FOR 10 SECONDS' to the following:


                             +---------+
                             | program |
                             +---------+     1)  TASK 0 SLEEPS FOR 10 SECONDS
                             | line 1  |
                             +---------+
                                  |
                                  V
                              (4 nodes)
                                  |
                                  V
                            +------------+
                            | sleeps_for |
                            +------------+
                            |   line 1   |
                            +------------+
                           /      |       \
                          /       V        \
          +--------------+    +--------+    +-----------+-----------+
          | source_task  |    |  expr  |    | time_unit | 'seconds' |
          +--------------+    +--------+    +-----------+-----------+
          |   line 1     |    | line 1 |    |        line 1         |
          +--------------+    +--------+    +-----------------------+
                  |               |
                  V               V
    +-----------+--------+    +-------------+
    | task_expr | 'expr' |    | ifelse_expr |
    +-----------+--------+    +-------------+
    |       line 1       |    |   line 1    |
    +--------------------+    +-------------+
              |                       |
              V                       V
          (8 nodes)               (6 nodes)
              |                       |
              V                       V
       +---------+----+       +---------+-----+
       | integer | 0L |       | integer | 10L |
       +---------+----+       +---------+-----+
       |   line 1     |       |     line 1    |
       +--------------+       +---------------+

'--no-lines'
     By default, each AST node indicates the lines in the program's
     source code to which it corresponds.  The '--no-lines' option
     suppresses the outputting of source-code line numbers.

'--no-attrs'
     Every node in the AST has a type.  Some nodes additionally have an
     attribute.  'dot_ast' normally outputs attributes but '--no-attrs'
     prevents 'dot_ast' from doing so.

'--no-source'
     The complete source code corresponding to the AST is included in
     the generated dot graph unless '--no-source' is specified on the
     command line.

   The 'DOT' environment variable names the Graphviz program that
'dot_ast' should run on the generated code.  If 'DOT' is not set,
'dot_ast' uses whatever value was specified/discovered at configuration
time (*note configure::), with the default being 'dot'.  By default,
'dot_ast' produces dot code and runs this through the designated
Graphviz program to produce a PostScript file (or whatever format is
named by the '--format' option).  If 'ncptl' is run with either the
'--no-link' or '--no-compile' options, it produces a dot file that
should be run manually through 'dot' or another Graphviz tool.

   ---------- Footnotes ----------

   (1) 'dot_ast' automatically places a semicolon after the extra dot
code.


File: conceptual.info,  Node: The libsea_ast backend,  Prev: The dot_ast backend,  Up: Supplied backends

3.3.12 The 'libsea_ast' backend
-------------------------------

Like the 'dot_ast' backend (*note The dot_ast backend::), the
'libsea_ast' backend visualizes a coNCePTuaL parse tree.  This
capability is primarily useful to backend developers to help prioritize
the methods that need to be implemented (i.e., implementing first the
AST node types needed by in a trivial program, then those needed by
successively more complex programs).

   The 'libsea_ast' backend specifies a coNCePTuaL program's parse tree
in the LibSea graph file format, which can then be visualized and
manipulated interactively using the Walrus visualization tool.  The
primary advantage of 'libsea_ast' over 'dot_ast' is that 'libsea_ast'
can handle much larger parse trees than 'dot_ast'.  For example, the
following image illustrates the Walrus GUI displaying a 702,985-node
coNCePTuaL parse tree:(1)

 [image src="walrus.png" alt="Image of the Walrus GUI displaying a large coNCePTuaL parse tree" text="+--------------------------------------------------------------------+
|                      Walrus 0.6.3 -- mg.graph                      |
+--------------------------------------------------------------------+
| File  Rendering   Display  Spanning Tree  Color Scheme  Node Label |
+--------------------------------------------------------------------+
|                                                                    |
|                    o\" \" o\" M M ooo o  o                            |
|                 o\" o\"o\"o\"o\"o M ooo\"o o o                           |
|                 o\" o\" o\"o \"o\" o  o \"o o                            |
|                 o\" M \"o \"o\" o\"  o o\" o\"o\" o  o                     |
|              \" \"o\" o\" o\"o M M \"o o o\"  o\" o                        |
|             \"\" \"o \"o \"o M \"o\"o\"o\" \" \"\" \"o\" o <-- Tasks t5527 such t|
|            \" \"o\"  o  \" o M o\" M \"o\" \" \" \" M                        |
|             \" o o o \" o o M \"o M o\"o\"\"\"o\"\"o\" \"                     |
|              \" o\"  \" \" \" \"o\"\"o\" M oo\"o\"o M o                       |
|                \" o o  \"  o \" M \"o\" o <-- All tasks await completion|
|                \"  o o  o   \"  M o\" M M \"o\"\"o \"                     |
|                  \" o  o  \"  \"o M M o\"o\"o M o                       |
|                     \" o o \"  o o\" \" o\"o\" o                         |
|                        o M \" o \"o\" M M \"o  o                       |
|                            \" o o M \"o                              |
|                             o   \" <-- Tasks t8171 such that t8171 =|
|                                                                    |
+--------------------------------------------------------------------+" ]

A secondary advantage of 'libsea_ast' is that Walrus lets a user
selectively view information.  For example, in the preceding image, only
<SIMPLE_STMT> nodes (*note Complex statements::) are highlighted; the
source code for only certain nodes is displayed; and all node type and
node attribute information is hidden.

   The 'libsea_ast' backend accepts the following option from the
'ncptl' command line:

'--node-code=CHARACTERS'
     Every node in the generated LibSea graph lists the fragment of
     coNCePTuaL code to which it corresponds.  For large coNCePTuaL
     programs, these strings can get large.  The <PROGRAM> node (*note
     Complete programs::), for example, includes the complete program
     source code.  Because the Walrus visualizer does not currently wrap
     long lines, most of a long string is never even presented to the
     user and therefore serves no practical purpose.  The argument to
     '--node-code' is a number of characters at which to truncate the
     code fragment or '-1' to inhibit truncation.

   ---------- Footnotes ----------

   (1) The original source program contained over 6000 lines of
coNCePTuaL code.


File: conceptual.info,  Node: Running coNCePTuaL programs,  Next: Interpreting coNCePTuaL log files,  Prev: Supplied backends,  Up: Usage

3.4 Running coNCePTuaL programs
===============================

coNCePTuaL programs can be run like any other program built with the
same compiler and communication library.  For example if a program
'myprog' was built with coNCePTuaL's C+MPI backend, the program might be
run with a command like 'mpirun -np NODES myprog' or 'prun -NNODES
myprog' or 'pdsh -w NODE_LIST myprog'.  The important point is that job
launching is external to coNCePTuaL.  A coNCePTuaL program is oblivious
to whether it is being run with a single thread on each multiprocessor
node or with one thread on each CPU, for example.  However, coNCePTuaL
log files do include the host name in the prologue comments (*note
Log-file format::) so job-launching parameters can potentially be
inferred from those.

   coNCePTuaL programs automatically support a "help" option.  This is
usually specified as '--help' or '-?', depending on which option-parsing
library 'configure' configured in.  (*Note configure::.)  The output of
running 'myprog --help' most likely looks something like this:

     Usage: myprog [OPTION...]
       -C, --comment=<string>      Additional commentary to write to the log
                                   file, @FILE to import commentary from FILE,
                                   or !COMMAND to import commentary from COMMAND
                                   (may be specified repeatedly)
       -L, --logfile=<string>      Log-file template [default: "a.out-%p.log"]
       -N, --no-trap=<string>      List of signals that should not be trapped
                                   [default: ""]
       -S, --seed=<number>         Seed for the random-number generator
                                   [default: 0]

     Help options:
       -?, --help                  Show this help message
       --usage                     Display brief usage message

   Although a coNCePTuaL program can specify its own command-line
options (*note Command-line arguments::), a few are provided by default.
In addition to '--help' these include '--comment', '--logfile',
'--no-trap', and '--seed'.

'--comment'
     '--comment' makes it possible to add arbitrary commentary to a log
     file.  This is useful for incorporating information that coNCePTuaL
     would be unable to (or simply does not currently) determine on its
     own, for example, '--comment="Last experiment before upgrading the
     network device driver"'.  Two special cases are supported:

       1. If the comment string begins with '@' then the remainder of
          the string is treated as a filename.  Each line of the
          corresponding file is treated as a separate comment string.
          Hence, if the file 'sysdesc.txt' contains the lines 'Using
          FooBarNet' and 'Quux is enabled', then specifying
          '--comment=sysdesc.txt' is similar to specifying both
          '--comment="Using FooBarNet"' and '--comment="Quux is
          enabled"'.

       2. If the comment string begins with '!' then the remainder of
          the string is treated as a shell command.  The command is
          executed and each line of its output is treated as a separate
          comment string.  For example, '--comment='!lspci | grep -i
          net'' executes 'lspci', extracts only those lines containing
          the string 'net', and makes log-file comments out of the
          result.  Note that '--comment='!COMMAND'' differs from
          '--comment="`COMMAND`"' in that the former causes COMMAND to
          be executed individually by each process in the program while
          the latter executes COMMAND only once and only before
          launching the program.  Also note that '!' must be escaped in
          'csh' and derivitive shells (i.e., '--comment='\!COMMAND'').

     As an example, the command line arguments '--comment="This is a
     simple comment." --comment=!lspci --comment=@/proc/version
     --comment="This is another simple comment."' produce log-file lines
     like the following:

          # User comment 1: This is a simple comment.
          # Output of 'lspci', line 1: 00:00.0 Host bridge: Intel Corp. 82860 860 (Wombat) Chipset Host Bridge (MCH) (rev 04)
          # Output of 'lspci', line 2: 00:01.0 PCI bridge: Intel Corp. 82850 850 (Tehama) Chipset AGP Bridge (rev 04)
          # Output of 'lspci', line 3: 00:02.0 PCI bridge: Intel Corp. 82860 860 (Wombat) Chipset AGP Bridge (rev 04)
          # Output of 'lspci', line 4: 00:1e.0 PCI bridge: Intel Corp. 82801BA/CA/DB PCI Bridge (rev 04)
          # Output of 'lspci', line 5: 00:1f.0 ISA bridge: Intel Corp. 82801BA ISA Bridge (LPC) (rev 04)
          # Output of 'lspci', line 6: 00:1f.1 IDE interface: Intel Corp. 82801BA IDE U100 (rev 04)
          # Output of 'lspci', line 7: 00:1f.2 USB Controller: Intel Corp. 82801BA/BAM USB (Hub  (rev 04)
          # Output of 'lspci', line 8: 00:1f.3 SMBus: Intel Corp. 82801BA/BAM SMBus (rev 04)
          # Output of 'lspci', line 9: 00:1f.4 USB Controller: Intel Corp. 82801BA/BAM USB (Hub  (rev 04)
          # Output of 'lspci', line 10: 00:1f.5 Multimedia audio controller: Intel Corp. 82801BA/BAM AC'97 Audio (rev 04)
          # Output of 'lspci', line 11: 01:00.0 VGA compatible controller: nVidia Corporation NV11 [GeForce2 MXR] (rev b2)
          # Output of 'lspci', line 12: 02:1f.0 PCI bridge: Intel Corp. 82806AA PCI64 Hub PCI Bridge (rev 03)
          # Output of 'lspci', line 13: 03:00.0 PIC: Intel Corp. 82806AA PCI64 Hub Advanced Programmable Interrupt Controller (rev 01)
          # Output of 'lspci', line 14: 04:0b.0 Ethernet controller: 3Com Corporation 3c905C-TX/TX-M [Tornado] (rev 78)
          # Output of 'lspci', line 15: 04:0d.0 Multimedia audio controller: Creative Labs SB Live! EMU10k1 (rev 08)
          # Output of 'lspci', line 16: 04:0d.1 Input device controller: Creative Labs SB Live! MIDI/Game Port (rev 08)
          # Contents of /proc/version, line 1: Linux version 2.4.20-28.7 (bhcompile@porky.devel.redhat.com) (gcc version 2.96 20000731 (Red Hat Linux 7.3 2.96-126)) #1 Thu Dec 18 11:31:59 EST 2003
          # User comment 2: This is another simple comment.

     To facilitate log-file parsing, all colons in the name of an
     '@'-file or '!'-command are written as periods.  This affects only
     the display, not the file to read or command to execute.

     Be careful when using shell backquotes with '--comment' (e.g., as
     in '--comment="`who`"').  Different shells have different ways of
     handling newlines output by a backquoted command.  In some shells
     (e.g., 'bash'), the coNCePTuaL program sees the entire output with
     embedded newlines as a single argument; in others (e.g., 'tcsh'),
     each line of output constitutes a separate command-line argument.
     Because coNCePTuaL programs currently ignore arguments that do not
     begin with '--', the comment written to the log file in the latter
     case terminates at the first newline.  In virtually all shells, the
     double quotes around the backquoted command are needed to prevent
     the shell from splitting arguments at word boundaries.  As a
     consequence, '--comment=`who`' logs only the first word output by
     the 'who' command.

'--logfile'
     '--logfile' specifies a template for naming log files.  Each task
     maintains a log file based on the template name but with '%p'
     replaced with the processor number, '%r' replaced with the run
     number (the smallest nonnegative integer that produces a filename
     that does not already exist), and '%%' replaced with a literal "%"
     character.  The program outputs an error message and aborts if the
     log-file template does not contain at least one '%p'.  The only
     exception is that an empty template (i.e., '--logfile=""') inhibits
     the production of log files entirely.

     Like C's 'printf()' function, a numeric field width can occur
     between the '%' and the conversion specifier (the 'p' or 'r' in the
     case of '--logfile').  The field is padded on the left with spaces
     to the given width.  More practically, if the field width begins
     with the number '0' the field is padded on the left with zeroes to
     the given width.  For example, specifying
     '--logfile="mydata-%03p.log"' on the command line produces log
     files named 'mydata-000.log', 'mydata-001.log', 'mydata-002.log',
     'mydata-003.log', and so forth.

'--no-trap'
     '--no-trap' specifies a list of signals or ranges of signals that
     should not be trapped.  For example, '--no-trap=10-12,17' prevents
     signals 10, 11, 12, and 17 from being trapped.(1)  Signals can also
     be referred to by name, with or without a 'SIG' prefix.  Also,
     names and numbers can be freely mixed.  Hence,
     '--no-trap=10-12,INT,17,SIGSTOP,SIGCONT' is a valid argument to a
     coNCePTuaL program.  Because signal reception can adversely affect
     performance, coNCePTuaL's default behavior is to terminate the
     program on receipt of a signal.  However, some signals may be
     necessary for the underlying communication layer's proper
     operation.  '--no-trap' enables such signals to pass through
     coNCePTuaL untouched.  (Some signals, however, are needed by
     coNCePTuaL or by a particular backend and are always trapped.)

'--seed'
     '--seed' (which selects a different default value on each run) is
     used in any program that utilizes the 'RANDOM TASK' construct
     (*note Binding variables::) or that sends message 'WITH
     VERIFICATION' (*note Message specifications::).

   If the 'LOGS' statement (*note Writing to a log file::) is used
anywhere in a coNCePTuaL program, then _all_ processes write a log file.
This is done because coNCePTuaL log files--even those that contain no
measurement data--include a wealth of important information in prologue
comments, as described *note Interpreting coNCePTuaL log files::.  As a
consequence, a program run with thousands of processes produces
thousands of log files.  If process 0 is the only process that logs
actual data, the 'ncptl-logmerge' script (*note ncptl-logmerge::) can
merge these log files into a single, more manageable, file.  For
situations in which it is unreasonable for every process to write a log
file (e.g., if the filesystem is unable to handle large numbers of
simultaneous file creations, the 'NCPTL_LOG_ONLY' environment variable
lets the user limit the set of processes that produce log files.
'NCPTL_LOG_ONLY' accepts a comma-separated list of dash-separated
process ranges such as '0-3,12-16,24,25,32-48'.  Only processes included
in the list produce log files.

   ---------- Footnotes ----------

   (1) On some platforms, these signals correspond to 'SIGUSR1',
'SIGSEGV', 'SIGUSR2', and 'SIGCHLD', respectively.


File: conceptual.info,  Node: Interpreting coNCePTuaL log files,  Prev: Running coNCePTuaL programs,  Up: Usage

3.5 Interpreting coNCePTuaL log files
=====================================

Any coNCePTuaL program that uses the 'LOGS' keyword (*note Writing to a
log file::) will produce a log file as it runs.  The coNCePTuaL run-time
library writes log files in a simple, plain-text format.  In addition to
measurement data, a wealth of information is stored within log-file
comments.  coNCePTuaL comes with a tool, 'ncptl-logextract', which can
extract data and other information from a log file and convert it into
any of a variety of other formats.

* Menu:

* Log-file format::             Syntax and semantics of program log files
* ncptl-logextract::            A tool for extracting log-file information
* ncptl-logmerge::              A tool for merging and comparing log files
* ncptl-logunmerge::            A tool for undoing the effects of ncptl-logmerge


File: conceptual.info,  Node: Log-file format,  Next: ncptl-logextract,  Prev: Interpreting coNCePTuaL log files,  Up: Interpreting coNCePTuaL log files

3.5.1 Log-file format
---------------------

The coNCePTuaL run-time library writes log files in the following
(textual) format:

   * Lines beginning with '#' are comments.

   * Columns are separated by commas.

   * Strings are output between double quotes.  Literal double-quotes
     are output as '\"' and literal backslashes are output as '\\'.

A sample log file is listed below.  The log file is presented in its
entirety.

     ###########################################################################
     # ===================
     # coNCePTuaL log file
     # ===================
     # coNCePTuaL version: 0.6.4a
     # coNCePTuaL backend: c_mpi (C + MPI)
     # Executable name: /home/pakin/src/coNCePTuaL/example
     # Working directory: /home/pakin/src/coNCePTuaL
     # Command line: ./example
     # Number of tasks: 2
     # Processor (0<=P<tasks): 0
     # Host name: a1
     # Operating system: Linux version 2.4.21-3.5qsnet (root@a31) (gcc version 2.96 20000731 (Red Hat Linux 7.2 2.96-108.1)) #2 SMP Thu Aug 7 10:51:04 MDT 2003
     # CPU vendor: GenuineIntel
     # CPU architecture: ia64
     # CPU count: 2
     # CPU frequency: 1300000000 Hz (1.3 GHz)
     # Cycle-counter frequency: 1300000000 Hz (1.3 GHz)
     # OS page size: 16384 bytes
     # Physical memory: 2047901696 bytes (1.9 GB)
     # Elan capability: [1965771c.6213bf5d.3a26411c.5b4c5d58] Version 10002 Type a001 Context 640.640.640 Node 1.2
     # coNCePTuaL configuration: ./configure '--prefix=/tmp/ncptl' 'MPICPPFLAGS=-I/usr/local/include' 'CFLAGS=-g -O3 -ansi_alias -ansi' 'MPICC=/usr/lib/mpi/mpi_intel/bin/mpicc' '--enable-maintainer-mode' 'CC=ecc' '--disable-shared'
     # Library compiler+linker: /opt/intel-7.1.033/compiler70/ia64/bin/ecc
     # Library compiler version: Intel(R) C++ gcc 3.0 mode [7.1]
     # Library compiler options: -g -O3 -ansi_alias -ansi
     # Library linker options: -lrmscall -lelan -lpopt
     # Library compiler mode: LP64
     # Dynamic libraries used: /usr/lib/qsnet/elan3/lib/librmscall.so.1 /usr/lib/qsnet/elan3/lib/libelan.so.1 /usr/lib/libpopt.so.0.0.0 /usr/lib/mpi/mpi_intel/lib/libmpi.so.1.0 /lib/libm-2.2.4.so /opt/intel-7.1.033/compiler70/ia64/lib/libcxa.so.4 /lib/libc-2.2.4.so /usr/lib/qsnet/elan3/lib/libelan3.so.1 /usr/lib/qsnet/elan/lib/libelanctrl.so.2 /lib/ld-2.2.4.so
     # Microsecond timer type: gettimeofday()
     # Average microsecond timer overhead: <1 microsecond
     # Microsecond timer increment: 1.00466 +/- 0.123576 microseconds (ideal: 1 +/- 0)
     # Minimum sleep time: 1946.6 +/- 31.5872 microseconds (ideal: 1 +/- 0)
     # WARNING: Sleeping exhibits poor granularity (not a serious problem).
     # WARNING: Sleeping has a large error component (not a serious problem).
     # Process CPU timer: getrusage()
     # Process CPU-time increment: 976.59 +/- 0.494311 microseconds (ideal: 1 +/- 0)
     # WARNING: Process timer exhibits poor granularity (not a serious problem).
     # Log-file template: example-%p.log
     # Number of minutes after which to kill the job (-1=never): -1
     # List of signals which should not be trapped: 14
     # Log-file checkpointing interval: 60 seconds (i.e., 1 minute)
     # MPI send routine: MPI_Send()
     # MPI error checking: off
     # Front-end compilation command line: ncptl --backend=c_mpi example.ncptl
     # Back-end compilation command line: /usr/lib/mpi/mpi_intel/bin/mpicc -I/tmp/ncptl/include  -I/usr/local/include -g -O3 -ansi_alias -ansi tmppG76Fv.c  -L/tmp/ncptl/lib   -lncptl -lrmscall -lelan -lpopt -o example
     # Log creator: Scott Pakin
     # Log creation time: Mon Dec 19 12:02:18 2005
     #
     # Environment variables
     # ---------------------
     # CVS_RSH: /usr/bin/ssh
     # DISPLAY: localhost:19.0
     # DYNINSTAPI_RT_LIB: /home/pakin/dyninstAPI-3.0/lib/i386-unknown-linux2.2/libdyninstAPI_RT.so.1
     # DYNINST_ROOT: /home/pakin/dyninstAPI-3.0
     # EDITOR: /usr/bin/emacs
     # GROUP: CCS3
     # HOME: /home/pakin
     # HOST: a0
     # HOSTNAME: a0
     # HOSTTYPE: unknown
     # KDEDIR: /usr
     # LANG: en_US
     # LD_LIBRARY_PATH: /opt/intel-7.1.033/compiler70/ia64/lib:/users/pakin/lib:/usr/lib:/usr/ccs/lib:/opt/SUNWspro/lib:/usr/dt/lib:/usr/openwin/lib:/usr/X11R6/lib:/usr/local/gnu/lib:/usr/local/lib:/usr/ucblib:/users/pakin/dyninstAPI-3.0/lib/i386-unknown-linux2.2
     # LESSOPEN: |/usr/bin/lesspipe.sh %s
     # LOGNAME: pakin
     # LPDEST: lwy
     # LS_COLORS: no=00:fi=00:di=01;34:ln=01;36:pi=40;33:so=01;35:bd=40;33;01:cd=40;33;01:or=01;05;37;41:mi=01;05;37;41:ex=01;32:*.cmd=01;32:*.exe=01;32:*.com=01;32:*.btm=01;32:*.bat=01;32:*.sh=01;32:*.csh=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.gz=01;31:*.bz2=01;31:*.bz=01;31:*.tz=01;31:*.rpm=01;31:*.cpio=01;31:*.jpg=01;35:*.gif=01;35:*.bmp=01;35:*.xbm=01;35:*.xpm=01;35:*.png=01;35:*.tif=01;35:
     # MACHTYPE: unknown
     # MAIL: /var/mail/pakin
     # MANPATH: /opt/intel-7.1.033/compiler70/man:/home/pakin/man:/usr/man:/opt/SUNWspro/man:/usr/dt/man:/usr/openwin/man:/usr/X11R6/man:/usr/local/gnu/man:/usr/local/man:/usr/share/man:/usr/lanl/man
     # MOZILLA_HOME: /usr/local/netscape/java
     # NAME: Scott Pakin
     # ORGANIZATION: Los Alamos National Lab
     # OSTYPE: linux
     # PATH: /opt/intel-7.1.033/compiler70/ia64/bin:.:/home/pakin/bin:/usr/local/bin:/usr/dt/bin:/usr/openwin/bin:/usr/X11R6/bin:/usr/local/gnu/bin:/usr/local/bin:/sbin:/bin:/opt/SUNWspro/bin:/usr/sbin:/usr/bin:/usr/ccs/bin:/usr/ucb:/usr/local/teTeX/bin:.:/usr/lanl/bin
     # PRINTER: lwy
     # PVM_ROOT: /usr/share/pvm3
     # PVM_RSH: /usr/bin/rsh
     # PWD: /home/pakin/src/coNCePTuaL
     # QTDIR: /usr/lib/qt-2.3.1
     # REMOTEHOST: antero.c3.lanl.gov
     # RMS_JOBID: 308
     # RMS_MACHINE: a
     # RMS_NNODES: 2
     # RMS_NODEID: 0
     # RMS_NPROCS: 2
     # RMS_PROCID: 0
     # RMS_RANK: 0
     # RMS_RESOURCEID: parallel.318
     # RMS_STOPONELANINIT: 0
     # SHELL: /bin/tcsh
     # SHLVL: 2
     # SSH_AGENT_PID: 8586
     # SSH_ASKPASS: /usr/libexec/openssh/gnome-ssh-askpass
     # SSH_AUTH_SOCK: /tmp/ssh-XXfG457q/agent.8562
     # SSH_CLIENT: 128.165.20.177 47456 22
     # SSH_TTY: /dev/pts/10
     # SUPPORTED: en_US:en
     # TERM: xterm
     # TZ: MST7MDT
     # USER: pakin
     # VENDOR: unknown
     #
     # coNCePTuaL source code
     # ----------------------
     #     FOR 10 REPETITIONS {
     #       TASK 0 RESETS ITS COUNTERS THEN
     #       TASK 0 SENDS A 0 BYTE MESSAGE TO TASK 1 THEN
     #       TASK 1 SENDS A 0 BYTE MESSAGE TO TASK 0 THEN
     #       TASK 0 LOGS EACH elapsed_usecs/2 AS "Latency (usecs)"
     #     }
     #
     ###########################################################################
     "Latency (usecs)"
     "(all data)"
     192.5
     7
     5.5
     5.5
     5
     5
     5
     5.5
     5
     5.5
     ###########################################################################
     # Program exited normally.
     # Log completion time: Mon Dec 19 12:02:18 2005
     # Elapsed time: 0 seconds
     # Process CPU usage (user+system): 0 seconds
     # Number of interrupts received (all CPUs): 22
     # Peak memory allocation: 1072987 bytes (1.0 MB)
     ###########################################################################


   As the preceding example indicates, a log file's comment block can be
divided into multiple stanzas:

   * a list of <KEY:VALUE> pairs that describe various characteristics
     of the run-time environment, including hardware and software
     identification, timer quality, values of command-line arguments,
     and a timestamp

   * a dump of the environment variables active when the program ran

   * the complete coNCePTuaL source program

Two rows of column headers and the measurement data follow the prologue
comment block.  A set of epilogue comments completes the log file.

   The motivation for writing so much information to the log file is to
facilitate reproduction of the experiment.  The ideal situation is for a
third party to be able to look at a coNCePTuaL log file and from that,
recreate the original experiment and get identical results.


   Some of the comments that may benefit from additional explanation
include the following:

'Library compiler mode'
     'LP64' means "*L*ong integers and *P*ointers contain exactly *64*
     bits while ordinary integers contain exactly 32 bits".  'ILP32'
     means "ordinary *I*ntegers, *L*ong integers, and *P*ointers all
     contain exactly *32* bits".  The library compiler mode will be
     'nonstandard' for any other combination of datatype sizes.

'Average timer overhead'
     During initialization, the coNCePTuaL run-time library performs
     some calibration routines.  Among these routines is a measurement
     of the quality of whatever mechanisms the library is using to
     measure elapsed time.  In the sample log file presented above, the
     mechanism used was 'inline assembly code', meaning the run-time
     library reads the hardware cycle counter without going through a
     standard library or system call.  The complete set of timer
     mechanisms and selection criteria is presented in *note
     Time-related functions::, in the documentation for the
     'ncptl_time()' function.

     The log file then reports "average timer overhead" as the mean time
     between back-to-back invocations of whichever timer routine is
     being used.  Ideally, the mean should be '<1 microsecond' but this
     is not the case on all systems.  Large values indicate that a
     performance penalty is charged every time a coNCePTuaL program
     reads the timer.

'Timer increment'
     In addition to measuring the overhead of reading the timer, the
     coNCePTuaL run-time library also measures timer accuracy.  The
     library expects to be able to read the timer with microsecond
     accuracy.  That is, the time reported should not increase by more
     than a microsecond between successive readings of the timer.  To
     gauge timer accuracy, the library's initialization routine performs
     a number of back-to-back invocations of the timer routine and
     reports the mean and standard deviation of the number of
     microseconds that elapsed between readings, discarding any deltas
     of zero microseconds.  Ideally, the microsecond timer, when read
     multiple times in rapid succession, should report nonzero
     increments of exactly one microsecond with no variation.  The log
     file will contain warning messages if the increment or standard
     deviation are excessively large, as this may indicate a large
     margin of error in the measurement data.

'Process CPU-time increment'
'Process CPU usage (user+system)'
     Log files end with an epilogue section that includes 'Process CPU
     usage (user+system)', which indicates the subset of total
     wall-clock time for which the program was running ('user') or for
     which the operating system was running on the program's behalf
     ('system').  The log-file prologue reports as 'Process CPU-time
     increment' the resolution of the timer user to report process CPU
     time.  Note that process CPU time is not exported to coNCePTuaL
     programs; it is therefore much less critical than the wall-clock
     timer and is reported primarily for informational purposes.

'Number of interrupts received (all CPUs)'
     On certain platforms, coNCePTuaL can tally the number of CPU
     interrupts that were processed during the run of the program.
     Because a multiprocessor may migrate tasks among CPUs during their
     execution, a per-CPU interrupt count may have little merit.
     Consequently, the number reported represents the sum across all
     CPUs in the same node (but not across nodes).  coNCePTuaL attempts
     to read interrupt information from the '/proc/interrupts' file if
     no alternative mechanism is available.  In case having a large
     number of processes accessing '/proc/interrupts' poses a problem
     the '--disable-proc-interrupts' configuration option prevents
     programs from accessing that file.

'Peak memory allocation'
     coNCePTuaL programs heap-allocate memory for a variety of purposes:
     message buffers, event lists (*note Generated code::), unaggregated
     performance data (*note Computing aggregates::), etc.  Allocated
     memory that is no longer needed is returned to the heap.  The total
     amount of allocated memory the program is holding therefore
     increases and decreases over time.  The 'Peak memory allocation'
     comment reports the maximum amount of memory the program held at
     any given time.  If this value nears or exceeds the value reported
     for 'Physical memory', it is possible that paging overheads may be
     negatively impacting some of the program's timing measurements.  On
     systems without demand paging, exceeding 'Physical memory' is
     likely to crash the program; a large 'Peak memory allocation' on a
     smaller run can therefore help explain why a larger run is
     crashing.  'Peak memory allocation' includes only memory allocated
     using the memory-allocation functions described in *note
     Memory-allocation functions::.


File: conceptual.info,  Node: ncptl-logextract,  Next: ncptl-logmerge,  Prev: Log-file format,  Up: Interpreting coNCePTuaL log files

3.5.2 'ncptl-logextract'
------------------------

To facilitate converting coNCePTuaL log files into input data for other
applications, coNCePTuaL provides a Perl script called
'ncptl-logextract'.  'ncptl-logextract' can extract the data from a log
file--as well as various information that appears in the log file's
comments--into a variety of formats suitable for graphing or
typesetting.

   Running 'ncptl-logextract --usage' causes 'ncptl-logextract' to list
a synopsis of its core command-line options to the standard output
device; running 'ncptl-logextract --help' produces basic usage
information; and, running 'ncptl-logextract --man' outputs a complete
manual page.  *Note ncptl-logextract manual page::, shows the
'ncptl-logextract' documentation as produced by
'ncptl-logextract --man'.

* Menu:

* ncptl-logextract manual page::   The result of running "ncptl-logextract -man"


File: conceptual.info,  Node: ncptl-logextract manual page,  Prev: ncptl-logextract,  Up: ncptl-logextract

NAME
....

ncptl-logextract - Extract various bits of information from a coNCePTuaL
log file

SYNOPSIS
........

ncptl-logextract '--usage' | '--help' | '--man'


ncptl-logextract ['--extract'=[data|params|env|source|warnings]]
['--format=FORMAT'] [FORMAT-SPECIFIC OPTIONS...]  ['--before=STRING']
['--after=STRING'] ['--force-merge'[=NUMBER]] ['--procs=STRING']
['--quiet'] ['--verbose'] ['--output=FILENAME'] [FILENAME...]

DESCRIPTION
...........

*Background*    coNCePTuaL is a domain-specific programming language
designed to facilitate writing networking benchmarks and validation
suites.  coNCePTuaL programs can log data to a file but in only a single
file format.  'ncptl-logextract' extracts this log data and outputs it
in a variety of formats for use with other applications.

   The coNCePTuaL-generated log files that serve as input to
'ncptl-logextract' are plain ASCII files.  Syntactically, they contain a
number of newline-separated tables.  Each table contains a number of
newline-separated rows of comma-separated columns.  This is known
generically as COMMA-SEPARATED VALUE or CSV format.  Each table begins
with two rows of header text followed by one or more rows of numbers.
Text is written within double quotes.  Double-quote characters and
backslashes within text are escaped with a backslash.  No other escaped
characters are recognized.  Lines that begin with '#' are considered
comments.

   Semantically, there are four types of data present in every
coNCePTuaL-generated log file:

  1. The complete source code of the coNCePTuaL program that produced
     the log file

  2. Characteristics of the run-time environment and the values of all
     command-line parameters

  3. A list of warning messages that coNCePTuaL issued while analyzing
     the run-time environment

  4. One or more tables of measurement data produced by the coNCePTuaL
     program

   The first three items appear within comment lines.  The measurement
data is written in CSV format.

*Extracting information from coNCePTuaL log files*    It is common to
want to extract information (especially measurement data) from log
files.  For simple formatting operations, a one-line awk or Perl script
suffices.  However, as the complexity of the formatting increases, the
complexity of these scripts increases even more.  That's where
'ncptl-logextract' fits in.  'ncptl-logextract' makes it easy to extract
any of the four types of log data described above and format it in
variety of ways.  Although the number of options that 'ncptl-logextract'
supports may be somewhat daunting, it is well worth learning how to use
'ncptl-logextract' to avoid reinventing the wheel every time a
coNCePTuaL log file needs to be processed.  'ncptl-logextract' takes
care of all sorts of special cases that crop up when manipulating
coNCePTuaL log files.

OPTIONS
.......

'ncptl-logextract' accepts the following command-line options regardless
of what data is extracted from the log file and what formatting occurs:

'-h'
     Output the Synopsis section and the Options section then exit the
     program.

'-m'
     Output a complete Unix man ("manual") page for 'ncptl-logextract'
     then exit the program.

'-e'
     Specify what sort of data should be extracted from the log file.
     Acceptable values for INFO are listed and described in the
     Additional Options section and include 'data', 'params', 'env', and
     'source'.

'-f'
     Specify how the extracted data should be formatted.  Valid
     arguments depend upon the value passed to '--extract' and include
     such formats as 'csv', 'html', 'latex', 'text', and 'bash'.  See
     the Additional Options section for details, explanations, and
     descriptions of applicability.

'-b'
     Output an arbitrary string of text before any other output.  STRING
     can contain escape characters such as '\n' for newline, '\t' for
     tab, and '\\' for backslash.

'-a'
     Output an arbitrary string of text after all other output.  STRING
     can contain escape characters such as '\n' for newline, '\t' for
     tab, and '\\' for backslash.

'-F'
     Try extra hard to merge multiple log files, even if they seem to
     have been produced by different programs or in different execution
     environments.  This generally implies padding empty rows and
     columns with blanks.  However, if '--force-merge' is given a
     numeric argument, the value of that argument is used instead of
     blanks to pad empty locations.  Note that '--force-merge' is
     different from '--force-merge=0' because data-merging functions
     ('mean', 'max', etc.)  ignore blanks but consider zeroes.

'-p'
     When given a "merged" log file, unmerge only the data corresponding
     to the comma-separated processor ranges in STRING.  For example,
     '--procs=0,16-20,25' unmerges the data for processors 0, 16, 17,
     18, 19, 20, and 25.  By default, 'ncptl-logextract' uses all of the
     data from a merged log file.

'-q'
     Suppress progress output.  Normally, 'ncptl-logextract' outputs
     status information regarding its operation.  The '--quiet' option
     instruct 'ncptl-logextract' to output only warning and error
     messages.

'-v'
     Increase progress output.  Normally, 'ncptl-logextract' outputs
     basic status information regarding its operation.  The '--verbose'
     option instruct 'ncptl-logextract' to output more detailed
     information.  Each time '--verbose' is specified, the program's
     verbosity increases (up to a maximum).

'-o'
     Redirect the output from 'ncptl-logextract' to a file.  By default,
     'ncptl-logextract' writes to the standard output device.

   The above is merely a terse summary of the 'ncptl-logextract'
command-line options.  The reader is directed to the Additional Options
section for descriptions of the numerous ways that 'ncptl-logextract'
can format information.  Note that '--extract' and '--format' are the
two most common options as they specify what to extract and how to
format it; most of the remaining options in the Additional Options
section exist to provide precise control over formatting details.

ADDITIONAL OPTIONS
..................

The 'ncptl-logextract' command-line options follow a hierarchy.  At the
top level is '--extract', which specifies which of the four types of
data 'ncptl-logextract' should extract.  Next, '--format' specifies how
the extracted data should be formatted.  Valid values for '--format'
differ based on the argument to '--extract'.  Finally, there are various
format-specific options that fine-tune the formatted output.  Each
output format accepts a different set of options.  Many of the options
appear at multiple places within the hierarchy, although usually with
different default values.

   The following hierarchical list describes all of the valid
combinations of '--extract', '--format', and the various format-specific
options:

'--extract=data [default]'
     Extract measurement data

     '--format=csv [default]'
          Output each table in comma-separated-value format

          '--noheaders'
               Do not output column headers

          '--colbegin=STRING'
               Specify the text placed at the beginning of each data
               column [default: "''"]

          '--colsep=STRING'
               Specify the text used to separate data columns [default:
               "','"]

          '--colend=STRING'
               Specify the text placed at the end of each data column
               [default: "''"]

          '--rowbegin=STRING'
               Specify the text placed at the beginning of each data row
               [default: "''"]

          '--rowsep=STRING'
               Specify the text used to separate data rows [default:
               "''"]

          '--rowend=STRING'
               Specify the text placed at the end of each data row
               [default: "'\\n'"]

          '--hcolbegin=STRING'
               Specify the text placed at the beginning of each header
               column [default: same as 'colbegin']

          '--hcolsep=STRING'
               Specify the text used to separate header columns
               [default: same as 'colsep']

          '--hcolend=STRING'
               Specify the text placed at the end of each header column
               [default: same as 'colend']

          '--hrowbegin=STRING'
               Specify the text placed at the beginning of each header
               row [default: same as 'rowbegin']

          '--hrowsep=STRING'
               Specify the text used to separate header rows [default:
               same as 'rowsep']

          '--hrowend=STRING'
               Specify the text placed at the end of each header row
               [default: same as 'rowend']

          '--tablebegin=STRING'
               Specify the text placed at the beginning of each table
               [default: "''"]

          '--tablesep=STRING'
               Specify the text used to separate tables [default:
               "'\\n'"]

          '--tableend=STRING'
               Specify the text placed at the end of each table
               [default: "''"]

          '--quote=STRING'
               Specify the text used to begin quoted text [default:
               "'"'"]

          '--unquote=STRING'
               Specify the text used to end quoted text [default: same
               as 'quote']

          '--excel'
               Output strings in a format readable by Microsoft Excel

          '--keep-columns=STRING'
               Enumerate the columns that should be included in the
               output [default: all columns]

          '--merge=FUNCTION'
               Specify how to merge data from multiple files [default:
               "'mean'"]

          '--showfnames=OPTION'
               Add an extra header row showing the filename the data
               came from [default: "'none'"]

     '--format=tsv'
          Output each table in tab-separated-value format

          '--noheaders'
               Do not output column headers

          '--colbegin=STRING'
               Specify the text placed at the beginning of each data
               column [default: "''"]

          '--colsep=STRING'
               Specify the text used to separate data columns [default:
               "'\\t'"]

          '--colend=STRING'
               Specify the text placed at the end of each data column
               [default: "''"]

          '--rowbegin=STRING'
               Specify the text placed at the beginning of each data row
               [default: "''"]

          '--rowsep=STRING'
               Specify the text used to separate data rows [default:
               "''"]

          '--rowend=STRING'
               Specify the text placed at the end of each data row
               [default: "'\\n'"]

          '--hcolbegin=STRING'
               Specify the text placed at the beginning of each header
               column [default: same as 'colbegin']

          '--hcolsep=STRING'
               Specify the text used to separate header columns
               [default: same as 'colsep']

          '--hcolend=STRING'
               Specify the text placed at the end of each header column
               [default: same as 'colend']

          '--hrowbegin=STRING'
               Specify the text placed at the beginning of each header
               row [default: same as 'rowbegin']

          '--hrowsep=STRING'
               Specify the text used to separate header rows [default:
               same as 'rowsep']

          '--hrowend=STRING'
               Specify the text placed at the end of each header row
               [default: same as 'rowend']

          '--tablebegin=STRING'
               Specify the text placed at the beginning of each table
               [default: "''"]

          '--tablesep=STRING'
               Specify the text used to separate tables [default:
               "'\\n'"]

          '--tableend=STRING'
               Specify the text placed at the end of each table
               [default: "''"]

          '--quote=STRING'
               Specify the text used to begin quoted text [default:
               "'"'"]

          '--unquote=STRING'
               Specify the text used to end quoted text [default: same
               as 'quote']

          '--excel'
               Output strings in a format readable by Microsoft Excel

          '--keep-columns=STRING'
               Enumerate the columns that should be included in the
               output [default: all columns]

          '--merge=FUNCTION'
               Specify how to merge data from multiple files [default:
               "'mean'"]

          '--showfnames=OPTION'
               Add an extra header row showing the filename the data
               came from [default: "'none'"]

     '--format=html'
          Output each table in HTML table format

          '--noheaders'
               Do not output column headers

          '--colbegin=STRING'
               Specify the text placed at the beginning of each data
               column [default: "'<td>'"]

          '--colsep=STRING'
               Specify the text used to separate data columns [default:
               "' '"]

          '--colend=STRING'
               Specify the text placed at the end of each data column
               [default: "'</td>'"]

          '--rowbegin=STRING'
               Specify the text placed at the beginning of each data row
               [default: "'<tr>'"]

          '--rowsep=STRING'
               Specify the text used to separate data rows [default:
               "''"]

          '--rowend=STRING'
               Specify the text placed at the end of each data row
               [default: "'</tr>\\n'"]

          '--hcolbegin=STRING'
               Specify the text placed at the beginning of each header
               column [default: "'<th>'"]

          '--hcolsep=STRING'
               Specify the text used to separate header columns
               [default: same as 'colsep']

          '--hcolend=STRING'
               Specify the text placed at the end of each header column
               [default: "'</th>'"]

          '--hrowbegin=STRING'
               Specify the text placed at the beginning of each header
               row [default: same as 'rowbegin']

          '--hrowsep=STRING'
               Specify the text used to separate header rows [default:
               same as 'rowsep']

          '--hrowend=STRING'
               Specify the text placed at the end of each header row
               [default: same as 'rowend']

          '--tablebegin=STRING'
               Specify the text placed at the beginning of each table
               [default: "'<table>\\n'"]

          '--tablesep=STRING'
               Specify the text used to separate tables [default: "''"]

          '--tableend=STRING'
               Specify the text placed at the end of each table
               [default: "'</table>\\n'"]

          '--quote=STRING'
               Specify the text used to begin quoted text [default:
               "''"]

          '--unquote=STRING'
               Specify the text used to end quoted text [default: same
               as 'quote']

          '--keep-columns=STRING'
               Enumerate the columns that should be included in the
               output [default: all columns]

          '--merge=FUNCTION'
               Specify how to merge data from multiple files [default:
               "'mean'"]

          '--showfnames=OPTION'
               Add an extra header row showing the filename the data
               came from [default: "'none'"]

     '--format=gnuplot'
          Output each table as a gnuplot data file

          '--noheaders'
               Do not output column headers

          '--colbegin=STRING'
               Specify the text placed at the beginning of each data
               column [default: "''"]

          '--colsep=STRING'
               Specify the text used to separate data columns [default:
               "' '"]

          '--colend=STRING'
               Specify the text placed at the end of each data column
               [default: "''"]

          '--rowbegin=STRING'
               Specify the text placed at the beginning of each data row
               [default: "''"]

          '--rowsep=STRING'
               Specify the text used to separate data rows [default:
               "''"]

          '--rowend=STRING'
               Specify the text placed at the end of each data row
               [default: "'\\n'"]

          '--hcolbegin=STRING'
               Specify the text placed at the beginning of each header
               column [default: same as 'colbegin']

          '--hcolsep=STRING'
               Specify the text used to separate header columns
               [default: same as 'colsep']

          '--hcolend=STRING'
               Specify the text placed at the end of each header column
               [default: same as 'colend']

          '--hrowbegin=STRING'
               Specify the text placed at the beginning of each header
               row [default: "'# '"

          '--hrowsep=STRING'
               Specify the text used to separate header rows [default:
               same as 'rowsep']

          '--hrowend=STRING'
               Specify the text placed at the end of each header row
               [default: same as 'rowend']

          '--tablebegin=STRING'
               Specify the text placed at the beginning of each table
               [default: "''"]

          '--tablesep=STRING'
               Specify the text used to separate tables [default:
               "'\\n\\n'"]

          '--tableend=STRING'
               Specify the text placed at the end of each table
               [default: "''"]

          '--quote=STRING'
               Specify the text used to begin quoted text [default:
               "'"'"]

          '--unquote=STRING'
               Specify the text used to end quoted text [default: same
               as 'quote']

          '--keep-columns=STRING'
               Enumerate the columns that should be included in the
               output [default: all columns]

          '--merge=FUNCTION'
               Specify how to merge data from multiple files [default:
               "'mean'"]

          '--showfnames=OPTION'
               Add an extra header row showing the filename the data
               came from [default: "'none'"]

     '--format=octave'
          Output each table as an Octave text-format data file

          '--noheaders'
               Do not output column headers

          '--colbegin=STRING'
               Specify the text placed at the beginning of each data
               column [default: "''"]

          '--colsep=STRING'
               Specify the text used to separate data columns [default:
               "''"]

          '--colend=STRING'
               Specify the text placed at the end of each data column
               [default: "'\\n'"]

          '--rowbegin=STRING'
               Specify the text placed at the beginning of each data row
               [default: "''"]

          '--rowend=STRING'
               Specify the text placed at the end of each data row
               [default: "''"]

          '--hcolbegin=STRING'
               Specify the text placed at the beginning of each header
               column [default: "''"]

          '--hcolsep=STRING'
               Specify the text used to separate header columns
               [default: "'_'"]

          '--hcolend=STRING'
               Specify the text placed at the end of each header column
               [default: "''"]

          '--hrowbegin=STRING'
               Specify the text placed at the beginning of each header
               row [default: "'# '"]

          '--hrowsep=STRING'
               Specify the text used to separate header rows [default:
               "''"]

          '--hrowend=STRING'
               Specify the text placed at the end of each header row
               [default: "'\\n'"]

          '--tablebegin=STRING'
               Specify the text placed at the beginning of each table
               [default: "''"]

          '--tablesep=STRING'
               Specify the text used to separate tables [default:
               "'\\n'"]

          '--tableend=STRING'
               Specify the text placed at the end of each table
               [default: "''"]

          '--quote=STRING'
               Specify the text used to begin quoted text [default:
               "''"]

          '--unquote=STRING'
               Specify the text used to end quoted text [default: same
               as 'quote']

          '--keep-columns=STRING'
               Enumerate the columns that should be included in the
               output [default: all columns]

          '--merge=FUNCTION'
               Specify how to merge data from multiple files [default:
               "'mean'"]

          '--showfnames=OPTION'
               Add an extra header row showing the filename the data
               came from [default: "'none'"]

     '--format=custom'
          Output each table in a completely user-specified format

          '--noheaders'
               Do not output column headers

          '--colbegin=STRING'
               Specify the text placed at the beginning of each data
               column [default: "''"]

          '--colsep=STRING'
               Specify the text used to separate data columns [default:
               "''"]

          '--colend=STRING'
               Specify the text placed at the end of each data column
               [default: "''"]

          '--rowbegin=STRING'
               Specify the text placed at the beginning of each data row
               [default: "''"]

          '--rowsep=STRING'
               Specify the text used to separate data rows [default:
               "''"]

          '--rowend=STRING'
               Specify the text placed at the end of each data row
               [default: "''"]

          '--hcolbegin=STRING'
               Specify the text placed at the beginning of each header
               column [default: same as 'colbegin']

          '--hcolsep=STRING'
               Specify the text used to separate header columns
               [default: same as 'colsep']

          '--hcolend=STRING'
               Specify the text placed at the end of each header column
               [default: same as 'colend']

          '--hrowbegin=STRING'
               Specify the text placed at the beginning of each header
               row [default: same as 'rowbegin']

          '--hrowsep=STRING'
               Specify the text used to separate header rows [default:
               same as 'rowsep']

          '--hrowend=STRING'
               Specify the text placed at the end of each header row
               [default: same as 'rowend']

          '--tablebegin=STRING'
               Specify the text placed at the beginning of each table
               [default: "''"]

          '--tablesep=STRING'
               Specify the text used to separate tables [default: "''"]

          '--tableend=STRING'
               Specify the text placed at the end of each table
               [default: "''"]

          '--quote=STRING'
               Specify the text used to begin quoted text [default:
               "''"]

          '--unquote=STRING'
               Specify the text used to end quoted text [default: same
               as 'quote']

          '--excel'
               Output strings in a format readable by Microsoft Excel

          '--keep-columns=STRING'
               Enumerate the columns that should be included in the
               output [default: all columns]

          '--merge=FUNCTION'
               Specify how to merge data from multiple files [default:
               "'mean'"]

          '--showfnames=OPTION'
               Add an extra header row showing the filename the data
               came from [default: "'none'"]

     '--format=latex'
          Output each table as a LaTeX tabular environment

          '--dcolumn'
               Use the dcolumn package to align numbers on the decimal
               point

          '--booktabs'
               Use the booktabs package for a more professionally
               typeset look

          '--longtable'
               Use the longtable package to enable multi-page tables

          '--keep-columns=STRING'
               Enumerate the columns that should be included in the
               output [default: all columns]

          '--merge=FUNCTION'
               Specify how to merge data from multiple files [default:
               "'mean'"]

          '--showfnames=OPTION'
               Add an extra header row showing the filename the data
               came from [default: "'none'"]

'--extract=params'
     Extract the program's run-time parameters and environment variables

     '--format=text [default]'
          Output the parameters in plain-text format

          '--include=FILENAME'
               Read from a file the list of keys to output

          '--exclude=REGEXP'
               Ignore any keys whose name matches a regular expression

          '--sort'
               Sort the list of parameters alphabetically by key

          '--noenv'
               Exclude environment variables

          '--noparams'
               Exclude run-time parameters

          '--envformat=TEMPLATE'
               Format environment variable names using the given
               template [default: "'%s (environment variable)'"]

          '--columns=NUMBER'
               Output the parameters as a 1-, 2-, or 3-column table
               [default: 1]

          '--colsep=STRING'
               Specify the text used to separate data columns [default:
               "': '"]

          '--rowbegin=STRING'
               Specify the text that's output at the start of each data
               row [default: "''"]

          '--rowend=STRING'
               Specify the text that's output at the end of each data
               row [default: "'\\n'"]

     '--format=dumpkeys'
          Output a list of the keys only (i.e., no values)

          '--include=FILENAME'
               Read the list of parameters to output from a given file

          '--exclude=REGEXP'
               Ignore any keys whose name matches a regular expression

          '--envformat=TEMPLATE'
               Format environment variable names using the given
               template [default: "'%s (environment variable)'"]

          '--sort'
               Sort the list of parameters alphabetically by key

          '--noenv'
               Exclude environment variables

          '--noparams'
               Exclude run-time parameters

     '--format=latex'
          Output the parameters as a LaTeX tabular environment

          '--include=FILENAME'
               Read from a file the list of keys to output

          '--exclude=REGEXP'
               Ignore any keys whose name matches a regular expression

          '--envformat=TEMPLATE'
               Format environment variable names using the given
               template [default: "'%s (environment variable)'"]

          '--sort'
               Sort the list of parameters alphabetically by key

          '--booktabs'
               Use the booktabs package for a more professionally
               typeset look

          '--tabularx'
               Use the tabularx package to enable line wraps within the
               value column

          '--longtable'
               Use the longtable package to enable multi-page tables

          '--noenv'
               Exclude environment variables

          '--noparams'
               Exclude run-time parameters

'--extract=env'
     Extract the environment in which the program was run

     '--format=sh [default]'
          Use Bourne shell syntax for setting environment variables

          '--newlines'
               Separate commands with newlines instead of semicolons

          '--unset'
               Unset all other environment variables

          '--chdir'
               Switch to the program's original working directory

     '--format=bash'
          Use Bourne Again shell syntax for setting environment
          variables

          '--newlines'
               Separate commands with newlines instead of semicolons

          '--unset'
               Unset all other environment variables

          '--chdir'
               Switch to the program's original working directory

     '--format=ksh'
          Use Korn shell syntax for setting environment variables

          '--newlines'
               Separate commands with newlines instead of semicolons

          '--unset'
               Unset all other environment variables

          '--chdir'
               Switch to the program's original working directory

     '--format=csh'
          Use C shell syntax for setting environment variables

          '--newlines'
               Separate commands with newlines instead of semicolons

          '--unset'
               Unset all other environment variables

          '--chdir'
               Switch to the program's original working directory

     '--format=zsh'
          Use Z shell syntax for setting environment variables

          '--newlines'
               Separate commands with newlines instead of semicolons

          '--unset'
               Unset all other environment variables

          '--chdir'
               Switch to the program's original working directory

     '--format=tcsh'
          Use tcsh syntax for setting environment variables

          '--newlines'
               Separate commands with newlines instead of semicolons

          '--unset'
               Unset all other environment variables

          '--chdir'
               Switch to the program's original working directory

     '--format=ash'
          Use ash syntax for setting environment variables

          '--newlines'
               Separate commands with newlines instead of semicolons

          '--unset'
               Unset all other environment variables

          '--chdir'
               Switch to the program's original working directory

'--extract=source'
     Extract coNCePTuaL source code

     '--format=text [default]'
          Output the source code in plain-text format

          '--linebegin=STRING'
               Specify the text placed at the beginning of each line
               [default: "''"]

          '--lineend=STRING'
               Specify the text placed at the end of each line [default:
               "'\\n'"]

          '--kwbegin=STRING'
               Specify the text placed before each keyword [default:
               "''"]

          '--kwend=STRING'
               Specify the text placed after each keyword [default:
               "''"]

          '--strbegin=STRING'
               Specify the text placed before each string [default:
               "''"]

          '--strend=STRING'
               Specify the text placed after each string [default: "''"]

          '--combegin=STRING'
               Specify the text placed before each comment [default:
               "''"]

          '--comend=STRING'
               Specify the text placed after each comment [default:
               "''"]

          '--indent=NUMBER'
               Indent each line by a given number of spaces

          '--wrap=NUMBER'
               Wrap the source code into a paragraph with a given
               character width

'--extract=warnings'
     Extract a list of warnings the program issued during initialization

     '--format=text [default]'
          Output warnings in plain-text format

          '--listbegin=STRING'
               Specify text to appear at the beginning of the list
               [default: "''"]

          '--listend=STRING'
               Specify text to appear at the end of the list [default:
               "''"]

          '--itembegin=STRING'
               Specify text to appear before each warning [default:
               "'* '"]

          '--itemend=STRING'
               Specify text to appear after each warning [default:
               "'\\n'"]

     '--format=html'
          Output warnings as an HTML list

          '--listbegin=STRING'
               Specify text to appear at the beginning of the list
               [default: "'<ul>\\n'"]

          '--listend=STRING'
               Specify text to appear at the end of the list [default:
               "'</ul>\\n'"]

          '--itembegin=STRING'
               Specify text to appear before each warning [default:
               "'  <li>'"]

          '--itemend=STRING'
               Specify text to appear after each warning [default:
               "'</li>\\n'"]

     '--format=latex'
          Output warnings as a LaTeX list

          '--listbegin=STRING'
               Specify text to appear at the beginning of the list
               [default: "'\begin@{itemize@}\\n'"]

          '--listend=STRING'
               Specify text to appear at the end of the list [default:
               "'\end@{itemize@}\\n'"]

          '--itembegin=STRING'
               Specify text to appear before each warning [default:
               "'  \item '"]

          '--itemend=STRING'
               Specify text to appear after each warning [default:
               "'\\n'"]

   The following represent additional clarification for some of the
above:

   * If '--indent' is specified without an argument, the argument
     defaults to '2'.

   * If '--wrap' is specified without an argument, the argument defaults
     to '72'.

   * The following are examples of the different arguments to the
     '--columns' option:

     '--columns=1 (default)'
                 coNCePTuaL version: 1.0
                 coNCePTuaL backend: c_mpi
                 Average timer overhead [gettimeofday()]: <1 microsecond
                 Log creation time: Thu Mar 27 19:22:48 2003
                 Log completion time: Thu Mar 27 19:22:48 2003

     '--columns=2'
                 coNCePTuaL version:                      1.0
                 coNCePTuaL backend:                      c_mpi
                 Average timer overhead [gettimeofday()]: <1 microsecond
                 Log creation time:                       Thu Mar 27 19:22:48 2003
                 Log completion time:                     Thu Mar 27 19:22:48 2003

     '--columns=3'
                 coNCePTuaL version                     : 1.0
                 coNCePTuaL backend                     : c_mpi
                 Average timer overhead [gettimeofday()]: <1 microsecond
                 Log creation time                      : Thu Mar 27 19:22:48 2003
                 Log completion time                    : Thu Mar 27 19:22:48 2003

   * '--dumpkeys' produces suitable input for the '--include' option.

   * '--exclude' can be specified repeatedly on the command line.

   * '--keep-columns' accepts a list of comma-separated column ranges.
     For example, '--keep-columns=1,3-6,8' tells 'ncptl-logextract' to
     ignore all but the first, third through sixth, and eighth columns
     of data.

   * '--merge' takes one of 'mean' (arithmetic mean), 'hmean' (harmonic
     mean), 'min' (minimum), 'max' (maximum), 'median' (median), 'sum'
     (sum), 'all' (all values from each column), or 'concat' (horizontal
     concatenation of all data), and applies the function to
     corresponding data values across all of the input files.  '--merge'
     can also accept a comma-separated list of the above functions, one
     per data column.  This enables a different merge operation to be
     used for each column.  For example, '--merge=min,min,mean' will
     take the minimum value across all files of each element in the
     first and second columns and the arithmetic mean across all files
     of each element in the third column.  If the number of
     comma-separated values differs from the number of columns and
     '--force-merge' is specified, 'ncptl-logextract' will cycle over
     the given values until all columns are accounted for.  The 'concat'
     merge type applies to all columns and therefore cannot be combined
     with any other merge type.  The difference between '--merge=all'
     and '--merge=concat' is that the former merges three files each
     with columns A and B as {A, A, A, B, B, B} while the latter merges
     the same files as {A, B, A, B, A, B}.

     Note that '--merge' is applied AFTER '--keep-columns'.  Hence, if
     '--keep-columns' specifies that only three columns be kept,
     '--merge' should list exactly three operations (or a single
     operation that applies to all three columns).

   * '--showfnames' prepends to each data table in the input file an
     extra header line indicating the log file the data was extracted
     from.  This option makes sense only when data is being extracted
     and primarily when '--merge=all' is specified.  '--showfnames'
     takes one of 'none', 'all', or 'first'.  The default is 'none',
     which doesn't add an extra header row.  'all' repeats the filename
     in each column of the extra header row.  'first' outputs the
     filename in only the first column, leaving the remaining columns
     with an empty string.  The following examples show how a sample
     data table is formatted with '--showfnames' set in turn to each of
     'none', 'all', and 'first':

        * Set to 'none' (the default):

                   "Size","Value"
                   1,2
                   2,4
                   3,6

        * Set to 'all' (filename repeated in each column of the first
          row):

                   "mydata.log","mydata.log"
                   "Size","Value"
                   1,2
                   2,4
                   3,6

        * Set to 'first' (filename shown only in the first column of the
          first row):

                   "mydata.log",""
                   "Size","Value"
                   1,2
                   2,4
                   3,6

   * If '--format=params' is used with both '--longtable' and
     '--tabularx', the generated table will be formatted for use with
     the 'ltxtable' LaTeX package.  See the 'ltxtable' documentation for
     more information.

NOTES
.....

If no filenames are given, 'ncptl-logextract' will read from the
standard input device.  If multiple log files are specified, coNCePTuaL
will merge the data values and take all other information from the first
file specified.  Note, however, that all of the log files must have been
produced by the same coNCePTuaL program and that that program must have
been run in the same environment.  In other words, only the data values
may change across log files; everything else must be invariant.  See the
description of '--merge' in the Additional Options section for more
information about merging data values from multiple log files.

   'ncptl-logextract' treats certain files specially:

   * If 'ncptl-logextract' is given a filename ending in '.gz', '.bz2',
     or '.Z' it automatically decompresses the file to a temporary
     location using 'gunzip', 'bunzip2', or 'uncompress', as
     appropriate, then recursively processes the decompressed file.

   * If 'ncptl-logextract' is given a filename ending in '.tar' or
     '.zip' it automatically extracts the file's contents to a temporary
     directory using 'tar' or 'unzip', as appropriate, then recursively
     processes the temporary directory.

   * If 'ncptl-logextract' is given the name of a directory it processes
     all of the plain files found (recursively) beneath that directory.

   * If an input file is a merged coNCePTuaL log file (i.e., produced by
     'ncptl-logmerge'), 'ncptl-logextract' automatically invokes
     'ncptl-logunmerge' to split the file into its constituent, ordinary
     log files then recursively processes those.

   'ncptl-logmerge' treats filenames ending in '.tgz' as if they ended
in '.tar.gz' and filenames ending in '.taz' as if they ended in
'.tar.Z'.

   If the argument provided to any 'ncptl-logextract' option begins with
an at sign ("'@'"), the value is treated as a filename and is replaced
by the file's contents.  To specify an non-filename argument that begins
with an at sign, merely prepend an additional "'@'":

'--this=that'
     The option 'this' is given the value "'that'".

'--this=@that'
     The option 'this' is set to the contents of the file called 'that'.

'--this=@@that'
     The option 'this' is given the value "'@that'".

EXAMPLES
........

For the following examples, we assume that 'results.log' is the name of
a log file produced by a coNCePTuaL program.

   Extract the data in CSV format and write it to 'results.csv':

         ncptl-logextract --extract=data results.log --output=results.csv

   Note that '--extract=data' is the default and therefore optional:

         ncptl-logextract results.log --output=results.csv

   'ncptl-logextract' can combine data from multiple log files (using an
arithmetic mean by default):

         ncptl-logextract results-*.log --output=results.csv

   Put the data from all of the log files side-by-side and produce a CSV
file that Microsoft Excel can read directly:

         ncptl-logextract results-*.log --output=results.csv --merge=all \
            --showfnames=first --excel

   Output the data from 'result.log' in tab-separated-value format:

         ncptl-logextract --format=tsv results.log

   Output the data in space-separated-value format:

         ncptl-logextract --colsep=" " results.log

   Use 'gnuplot' to draw a PostScript graph of the data:

         ncptl-logextract results.log --format=gnuplot \
            --before=@params.gp | gnuplot > results.eps

   In the above, the 'params.gp' file might contain 'gnuplot' commands
such as the following:

         set terminal postscript eps enhanced color "Times-Roman" 30
         set output
         set logscale xy
         set data style linespoints
         set pointsize 3
         plot "-" title "Latency"

   (There should be an extra blank line at the end of the file because
'ncptl-logextract' strips off a trailing newline character whenever it
reads a file using "'@'".)

   Produce a complete HTML file of the data (noting that '--format=html'
produces only tables, not complete documents):

         ncptl-logextract --format=html
            --before='<html>\n<head>\n<title>Data</title>\n</head>\n<body>\n' \
            --after='</body>\n</html>\n' results.log

   Output the data as a LaTeX 'tabular', relying on both the (standard)
'dcolumn' and (non-standard) 'booktabs' packages for more attractive
formatting:

         ncptl-logextract --format=latex --dcolumn --booktabs \
           --output=results.tex results.log

   Output the run-time parameters in the form "KEY '--->' VALUE" with
all of the arrows aligned:

         ncptl-logextract results.log --extract=params --columns=3 --colsep=" --> "

   Output the run-time parameters as an HTML description list:

         ncptl-logextract results.log --extract=params --before='<dl>' \
           --rowbegin='<dt>' --colsep='</dt><dd>' --rowend='</dd>\n' \
           --after='</dl>\n'

   Restore the exact execution environment that was used to produce
'results.log', including the current working directory (assuming that
'bash' is the current command shell):

         eval `ncptl-logextract --extract=env --format=bash \
           --unset --chdir results.log`

   Set all of the environment variables that were used to produce
'results.log', overwriting--but not removing--whatever environment
variables are currently set (assuming that 'tcsh' is the current command
shell):

         eval `ncptl-logextract --extract=env --format=tcsh results.log`

   Extract the source code that produced 'results.log':

         ncptl-logextract --extract=source results.log

   Do the same, but indent the code by four spaces then re-wrap it into
a 60-column paragraph:

         ncptl-logextract --extract=source --indent=4 --wrap=60 results.log

   Here are a variety of ways to express the same thing:

         ncptl-logextract -e source --indent=4 --wrap=60 results.log

         ncptl-logextract -e source --indent=4 results.log --wrap=60

         cat results.log | ncptl-logextract --wrap=60 --indent=4 -e source

   Output the source code wrapped to 72 columns, with no indentation,
and formatted within an HTML preformatted-text block:

         ncptl-logextract --extract=source --wrap --before="<PRE>\n" \
           after="</PRE>\n" results.log

   List all of the warning messages which occur in 'results.log':

         ncptl-logextract --extract=warnings results.log

SEE ALSO
........

ncptl-logmerge(1), ncptl-logunmerge(1), the coNCePTuaL User's Guide

AUTHOR
......

Scott Pakin, <pakin@lanl.gov>


File: conceptual.info,  Node: ncptl-logmerge,  Next: ncptl-logunmerge,  Prev: ncptl-logextract,  Up: Interpreting coNCePTuaL log files

3.5.3 'ncptl-logmerge'
----------------------

coNCePTuaL programs produce one log file per process.  An unwieldy
number of files can therefore be generated on large-scale computer
systems.  For the case in which only a single log file contains
measurement data, 'ncptl-logmerge' can merge a number of log files into
a single file.  Only lines that differ across log files are repeated,
making the result fairly space-efficient.  The primary advantage of
'ncptl-logmerge' over an archiving program such as 'tar' or 'zip' is
that the output of 'ncptl-logmerge' is designed to be human-readable--in
fact, easily readable.

   'ncptl-logmerge' can also be used to highlight differences in log
files.  It is therefore an important diagnostic tool for unearthing
subtle configuration discrepancies across nodes in a large-scale
computer system.

   Running 'ncptl-logmerge --usage' causes 'ncptl-logmerge' to list a
synopsis of its core command-line options to the standard output device;
running 'ncptl-logmerge --help' produces basic usage information; and,
running 'ncptl-logmerge --man' outputs a complete manual page.  *Note
ncptl-logmerge manual page::, shows the 'ncptl-logmerge' documentation
as produced by 'ncptl-logmerge --man'.

* Menu:

* ncptl-logmerge manual page::     The result of running "ncptl-logmerge -man"


File: conceptual.info,  Node: ncptl-logmerge manual page,  Prev: ncptl-logmerge,  Up: ncptl-logmerge

NAME
....

ncptl-logmerge - Merge coNCePTuaL log files

SYNOPSIS
........

ncptl-logmerge '--usage' | '--help' | '--man'


ncptl-logmerge ['--output=FILENAME'] ['--simplify'] FILENAME...

DESCRIPTION
...........

A coNCePTuaL program produces one log file per process.  For large
numbers of processes the result can be unwieldy.  'ncptl-logmerge'
combines a large set of log files into a single, merged file which can
later be expanded back into its constituent log files.  There are a
number of restrictions on the input to 'ncptl-logmerge'; see the
Restrictions section for details.

   The merged output file does not modify lines which are identical in
all of the input files.  Lines which do differ across input files are
prefixed with the processors and processor ranges in which they
appeared.

   As an example, the following text was extracted from a set of 186
coNCePTuaL log files (from a 186-processor run):

         # Microsecond timer type: PAPI_get_real_usec()
         # Average microsecond timer overhead: <1 microsecond
         #[0-4,6-12,14-16,18-52,54-78,80-94,96-101,103-121,123-140,142-169,
           171-185]# Microsecond timer increment: 1 +/- 0 microseconds
           (ideal: 1 +/- 0)
         #[5]# Microsecond timer increment: 1.00229 +/- 0.15854
           microseconds (ideal: 1 +/- 0)
         #[13]# Microsecond timer increment: 1.00228 +/- 0.158442
           microseconds (ideal: 1 +/- 0)
         #[17,79]# Microsecond timer increment: 1.00228 +/- 0.158392
           microseconds (ideal: 1 +/- 0)
         #[53]# Microsecond timer increment: 1.00228 +/- 0.158409
           microseconds (ideal: 1 +/- 0)
         #[102]# Microsecond timer increment: 1.00228 +/- 0.158458
           microseconds (ideal: 1 +/- 0)
         #[95,122]# Microsecond timer increment: 1.00228 +/- 0.158474
           microseconds (ideal: 1 +/- 0)
         #[141]# Microsecond timer increment: 1.00228 +/- 0.158491
           microseconds (ideal: 1 +/- 0)
         #[170]# Microsecond timer increment: 1.00228 +/- 0.158524
           microseconds (ideal: 1 +/- 0)

   All of the input files contained the same 'Microsecond timer type'
and 'Average microsecond timer overhead' lines.  However, the measured
'Microsecond timer increment' varied across input files.  While many of
the processors observed an increment of '1 +/- 0', processor 5 was alone
in observing '1.00229 +/- 0.15854'; processor 13 was alone in observing
'1.00228 +/- 0.158442'; and, both processor 17 and processor 79 observed
'1.00228 +/- 0.158392' as the timer increment.

   'ncptl-logmerge' can also be instructed to output only the lines
which differ across files.  Common lines are not output.  This feature
is useful for discovering misconfigured nodes in a large computer
system.  For example, on one computer system on which coNCePTuaL was
run, five processors were running at a higher clock rate than the
remainder which naturally affected performance.  'ncptl-logmerge' can be
used to help identify such outliers.

OPTIONS
.......

'ncptl-logmerge' accepts the following command-line options:

'-u'
     Output the Synopsis section then exit the program.

'-h'
     Output the Synopsis section and the Options section then exit the
     program.

'-m'
     Output a complete Unix man ("manual") page for 'ncptl-logmerge'
     then exit the program.

'-o'
     'ncptl-logmerge' normally writes to the standard output device.
     The '--output' option redirects 'ncptl-logmerge''s output to a
     file.

'-s'
     Simplify the output by including only lines which differ across
     input files.  No data is output, only prologue and epilogue
     comments. '--simplify' can be specified up to four times on the
     command line:

     once
          Omit all comments and all lines which are identical across all
          input files.

     twice
          Lines which differ across ALL output files (e.g., 'Processor
          (0<=P<tasks)') are also omitted.

     three times
          The amount of output is further reduced by rounding to two
          significant digits all numbers appearing in all input files.
          Doing so makes '1.10644 +/- 0.593714' match '1.12511 +/-
          0.58829', for example.  (Both are converted to '1.1 +/-
          0.59'.)

     four times
          Lists of processors are replaced by the list size.  For
          example, '#[22,67,86,430]' becomes '#[4]'.

     Note that '--simplify' is intended as a diagnostic tool; files
     output using '--simplify' cannot be un-merged to recover the
     original input files.

   In addition to the preceding options 'ncptl-logmerge' requires a list
of log files to merge.  If a directory is specified, all of the files
immediately under that directory are used.  (Note that 'ncptl-logmerge'
does not descend into subdirectories, however.)  Files containing lists
of filenames can be specified with a leading at sign ("'@'").  For
example, '@filelist.txt' means to read a list of filenames from
'@filelist.txt'.  Filenames beginning with an at sign can be specified
by doubling the at sign on the command line.

DIAGNOSTICS
...........

FILENAME 'does not look like an unmerged coNCePTuaL log file'
     'ncptl-logmerge' accepts as input only log files produced directly
     by a coNCePTuaL program.  It is not a general-purpose file combiner
     nor does it accept its own output as input.  Unrecognized input
     files cause 'ncptl-logmerge' to abort with the preceding error
     message.

'No process rank found in' FILENAME
     'ncptl-logmerge' needs to map filenames to process ranks to
     indicate which ranks produced which lines of output.  If an input
     file does not contain a 'Rank (0<=P<tasks)' comment,
     'ncptl-logmerge' aborts with the preceding error message.

EXAMPLES
........

Merge a set of coNCePTuaL log files:

         ncptl-logmerge mybenchmark-[0-9]*.log > mybenchmark-all.log

   The following command is equivalent to the preceding one:

         ncptl-logmerge mybenchmark-[0-9]*.log --output=mybenchmark-all.log

   Show only "interesting" differences among the input files:

         ncptl-logmerge --simplify --simplify mybenchmark-[0-9]*.log

   For convenience, one can abbreviate '--simplify' '--simplify'
'--simplify' '--simplify' to '-s' '-s' '-s' '-s' or even '-ssss':

         ncptl-logmerge -ssss mybenchmark-[0-9]*.log

RESTRICTIONS
............

The log files passed to 'ncptl-logmerge' are subject to the following
restrictions:

   * All files must be produced by the same run of the same coNCePTuaL
     program.

   * None of the files can have been previously merged by
     'ncptl-logmerge' (i.e., 'ncptl-logmerge' can't read its own
     output).

   * Only the first filename passed to 'ncptl-logmerge' is allowed to
     contain data.  Data from all other files is discarded with a
     warning message.

BUGS
....

'ncptl-logmerge' is not a particularly robust script.  Specifically, it
is confused when input files contain different numbers of comment lines.
For example, if one input file includes more environment variables than
another or issued a warning about a timer where another input file
didn't, 'ncptl-logmerge' will erroneously report all subsequent lines as
being mismatched across input files.

SEE ALSO
........

ncptl-logunmerge(1), ncptl-logextract(1), the coNCePTuaL User's Guide

AUTHOR
......

Scott Pakin, <pakin@lanl.gov>


File: conceptual.info,  Node: ncptl-logunmerge,  Prev: ncptl-logmerge,  Up: Interpreting coNCePTuaL log files

3.5.4 'ncptl-logunmerge'
------------------------

The primary capability of 'ncptl-logmerge' (*note ncptl-logmerge::) is
to merge multiple coNCePTuaL log files into a more maintainable single
file.  'ncptl-logunmerge' performs the complementary operation of
splitting that merged file back into the original set of coNCePTuaL log
files.

   Running 'ncptl-logunmerge --usage' causes 'ncptl-logunmerge' to list
a synopsis of its core command-line options to the standard output
device; running 'ncptl-logunmerge --help' produces basic usage
information; and, running 'ncptl-logunmerge --man' outputs a complete
manual page.  *Note ncptl-logunmerge manual page::, shows the
'ncptl-logunmerge' documentation as produced by
'ncptl-logunmerge --man'.

* Menu:

* ncptl-logunmerge manual page::   The result of running "ncptl-logunmerge -man"


File: conceptual.info,  Node: ncptl-logunmerge manual page,  Prev: ncptl-logunmerge,  Up: ncptl-logunmerge

NAME
....

ncptl-logunmerge - Recover individual coNCePTuaL log files from
ncptl-logmerge output

SYNOPSIS
........

ncptl-logunmerge '--usage' | '--help' | '--man'


ncptl-logunmerge ['--logfile=TEMPLATE'] ['--procs=PROCESS_LIST']
['--quiet'] ['--memcache=MEGABYTES'] FILENAME

DESCRIPTION
...........

While 'ncptl-logmerge' merges a set of coNCePTuaL log files into a more
convenient, single file, 'ncptl-logunmerge' performs the inverse
operation, splitting a merged file into separate coNCePTuaL log files.
Specifically, unadorned comment lines such as the following are written
to all log files:

         # Executable name: /home/me/mybenchmark

   Comment lines which specify processor ranges are written to the
appropriate log files.  For example, the following line--with the
leading '#[35,43,89]' stripped--is written only to the log files
corresponding to processes 35, 43, and 89:

         #[35,43,89]# Minimum sleep time: 9.68 +/- 0.556776
           microseconds (ideal: 1 +/- 0)

   Non-comment lines (i.e., measurement data) such as the following are
written only to process 0's log file:

         "Contention factor","Msg. size (B)","1/2 RTT (us)","MB/s"
         "(all data)","(all data)","(all data)","(all data)"
         0,1048576,1368.0295,730.978389
         0,524288,691.9115,722.6357706

OPTIONS
.......

'ncptl-logunmerge' accepts the following command-line options:

'-u'
     Output the Synopsis section then exit the program.

'-h'
     Output the Synopsis section and the Options section then exit the
     program.

'-m'
     Output a complete Unix man ("manual") page for 'ncptl-logunmerge'
     then exit the program.

'-L'
     Specify a template for the names of the generated log files.  The
     template must contain the literal string '%p' which will be
     replaced by the appropriate processor number.  The template may
     contain the literal string '%r' (run number) which will be replaced
     by the smallest integer which produces a filename that does not
     already exist.  In addition, 'printf()'-style field widths can be
     used with '%p' and '%r'.  For example, '%04p' outputs the processor
     number as a four-digit number padded on the left with zeroes.

     If '--logfile' is not specified, 'ncptl-logunmerge' takes the
     default template from the merged log file's 'Log-file template'
     line, discards the directory component of the filename, and uses
     the result as the log-file template.

'-p'
     Identify a subset of log files to extract from the merged log file.
     By default, 'ncptl-logunmerge' extracts all of the constituent log
     files.  PROCESS_LIST is a comma-separated list of process number or
     process ranges.

'-q'
     Suppress progress output.  Normally, 'ncptl-logunmerge' outputs
     status information regarding its operation.  The '--quiet' option
     instruct 'ncptl-logunmerge' to output only warning and error
     messages.

'-M'
     Specify the size of the in-memory file cache.  By default the
     program keeps up to 8 MB of extracted file data resident in memory
     to improve performance.  The '--memcache' option enables more or
     less data to be cached in memory.  For example, '--memcache=512'
     specifies that 512 MB of memory should be reserved for the file
     cache.

   In addition to the preceding options 'ncptl-logunmerge' requires the
name of a merged coNCePTuaL log file.  If not provided,
'ncptl-logunmerge' reads the contents of the merged coNCePTuaL log file
from standard input.

DIAGNOSTICS
...........

'The input file does not look like a merged coNCePTuaL log file; assuming simple concatenation'
     'ncptl-logunmerge' expects its input file to contain the output
     from 'ncptl-logmerge'.  However, 'ncptl-logunmerge' can also accept
     an input file produced by concatenating a collection of coNCePTuaL
     log files end-to-end (e.g., by using the 'cat' command).  The
     preceding warning message serves merely to alert the user in case
     the wrong input file was provided to 'ncptl-logunmerge'.

'Unable to find a unique number of tasks in the input file'
     'ncptl-logunmerge' determines the number of files to generate from
     the 'Number of tasks' prologue comment.  If that comment does not
     appear or takes on different values, 'ncptl-logunmerge' rejects the
     input file.

EXAMPLES
........

Extract a set of coNCePTuaL log files from a merged log file and name
the extracted files 'happy-0.log', 'happy-1.log', 'happy-2.log', etc.:

         ncptl-logunmerge --logfile=happy-%p.log mybenchmark-all.log

   Extract only 'mybenchmark-0.log', 'mybenchmark-50.log',
'mybenchmark-51.log', 'mybenchmark-52.log', and 'mybenchmark-100.log'
from 'mybenchmark-all.log' (assuming that 'mybenchmark-all.log' contains
the line '# Log-file template: mybenchmark-%p.log'):

         ncptl-logunmerge --procs=0,50-52,100 mybenchmark-all.log

SEE ALSO
........

ncptl-logmerge(1), ncptl-logextract(1), printf(3), the coNCePTuaL User's
Guide

AUTHOR
......

Scott Pakin, <pakin@lanl.gov>


File: conceptual.info,  Node: Grammar,  Next: Examples,  Prev: Usage,  Up: Top

4 Grammar
*********

The coNCePTuaL language was designed to produce precise specifications
of network correctness and performance tests yet read like an
English-language document that contains a hint of mathematical notation.
Unlike more traditional programming languages, coNCePTuaL is more
descriptive than imperative.  There are no classes, functions, arrays,
pointers, or even variable assignments (although expressions can be
let-bound to identifiers).(1)  The language operates primarily on
integers, with support for string constants and floating-point numbers
in only a few constructs.  A coNCePTuaL program merely describes a
communication pattern and the coNCePTuaL compiler generates code to
implement that pattern.

   As a domain-specific language, coNCePTuaL contains primitives to send
and receive messages.  It is capable of measuring time, computing
statistics, and logging results.  It knows that it will be run in a
shared-nothing SPMD(2) style with explicit message-passing.  As a result
of its special-purpose design coNCePTuaL can express communication
patterns in a clearer and terser style than is possible using a
general-purpose programming language.

   The coNCePTuaL language is case-insensitive.  'Hello' is the same as
'HELLO' or 'hello'.  Furthermore, whitespace is insignificant; one space
has the same meaning as multiple spaces.  Comments are designated with a
'#' character and extend to the end of the line.

   We now describe the coNCePTuaL grammar in a bottom-up manner, i.e.,
starting from primitives and working up to complete programs.  Note that
many of the sections in this chapter use the following syntax to
formally describe language elements:

     <NONTERMINAL> a placeholder for a list of language primitives and
     additional placeholders

::=
     "is defined as"

     'KEYWORD' a primitive with special meaning to the language

[...]
     optional items

(...)
     grouping of multiple items into one

*
     zero or more occurrences of the preceding item

+
     one or more occurrences of the preceding item

|
     either the item to the left or the item to the right but not both

* Menu:

* Primitives::                  Identifiers, strings, and integers
* Expressions::                 Ways to combine primitives
* Task descriptions::           Selecting groups of tasks at once
* Communication statements::    Sending and receiving messages
* I/O statements::              Relaying status and logging results
* Counter and timer statements::  Measuring how long an operation takes
* Complex statements::          Combining statements into larger entities
* Other statements::            Statements for neither communication nor I/O
* Header declarations::         Language versioning and command-line parsing
* Complete programs::           Arguments + complex statements = programs
* Summary of the grammar::      Repeat of the EBNF rules that appeared above

   ---------- Footnotes ----------

   (1) coNCePTuaL is not even Turing-complete.  That is, it cannot
perform arbitrary computations.

   (2) Single Program, Multiple Data


File: conceptual.info,  Node: Primitives,  Next: Expressions,  Prev: Grammar,  Up: Grammar

4.1 Primitives
==============

At the lowest level, coNCePTuaL programs are composed of identifiers,
strings, and integers (and a modicum of punctuation).  Identifiers
consist of a letter followed by zero or more alphanumerics or
underscores.  'potato', 'x', and 'This_is_program_123' are all examples
of valid identifiers.  Identifiers are used for two purposes: variables
and keywords.  Variables--referred to in the formal grammar as
<IDENT>s--can be bound but not assigned.  That is, once a variable is
given a value it retains that value for the entire scope although it may
be given a different value within a subordinate scope for the duration
of that scope.  All variables are of integer type.  There are a number
of variables that are predeclared and maintained automatically by
coNCePTuaL.  These are listed and described in *note Predeclared
variables::.  Predeclared variables can be used by coNCePTuaL programs
but cannot be redeclared; an attempt to do so will result in a
compile-time error message.

   Keywords introduce actions.  For example, 'SEND' and 'RECEIVE' are
keywords.  (A complete list of coNCePTuaL keywords is presented in *note
Keywords::.)  Most keywords can appear in multiple forms.  For example,
'OUTPUT' and 'OUTPUTS' are synonymous, as are 'COMPUTE' and 'COMPUTES',
'A' and 'AN', and 'TASK' and 'TASKS'.  The intention is for programs to
use whichever sounds better in an English-language sentence.  Keywords
may not be used as variable names; an attempt to do so will cause the
compiler to output a parse error.

   As a special case to increase program readability, a single '-'
preceding a keyword is treated as a whitespace character.  Hence,
'INTEGER-SIZED PAGE-ALIGNED MESSAGE' is equivalent to 'INTEGER SIZED
PAGE ALIGNED MESSAGE' and '10 64-BYTE MESSAGES' is equivalent to '10 64
BYTE MESSAGES'.  However, 'x-3' and '3-x' still represent subtraction
operations.

   Although identifiers are case insensitive--'SEND' is the same as
'send' is the same as 'sENd'--to increase clarity, this manual presents
keywords in uppercase and variables in lowercase.

   Strings consist of double-quoted text.  Within a string--and only
within a string--whitespace and case are significant.  In particular, a
literal newline is honored but can be suppressed by preceding it with a
backslash as in the following example:

     "This string\
     contains some
     newline characters."
   => This string contains some
newline characters.

   Use '\"' for a double-quote character, '\\' for a backslash, '\t' for
a tab character, '\r' for a carriage-return character, and '\n' for a
newline character.  All other escape sequences produce a warning message
and are discarded.  As examples of valid escape-sequence usage, the
string '"March 2019"' represents the text "March 2019" and '"I store
\"stuff\" in C:\\MyStuff."' represents the text "I store "stuff" in
C:\MyStuff."

   Integers consist of an optional '+' or '-'(1) followed by one or more
digits followed by an optional multiplier.  This multiplier is unique to
coNCePTuaL and consists of one of the following four letters:

'K' (kilo)
     multiplies the integer by 1,024

'M' (mega)
     multiplies the integer by 1,048,576

'G' (giga)
     multiplies the integer by 1,073,741,824

'T' (tera)
     multiplies the integer by 1,099,511,627,776

   A multiplier can also be 'E' (exponent) followed by a positive
integer.  An 'E' multiplier multiplies the base integer by 10 raised to
the power of the positive integer following the 'E'.

   Integers can also be written as ordinals, with an 'ST', 'ND', 'RD',
or 'TH' suffix.  These suffixes are ignored by the lexer but can make
the 'PERCENTILE' aggregate function (*note Aggregate functions::) look
more English-like (as in, 'THE 95TH PERCENTILE').

   Some examples of valid integers include '2016', '-42', '64K'
(= 65,536), '8E3' (= 8,000), and '38TH'.

   ---------- Footnotes ----------

   (1) From the lexer's perspective, integers are always unsigned and
'+' or '-' are merely operators (*note Arithmetic expressions::).  The
parser, however, applies unary operators to integer literals.  This
alteration is evident in the output of the 'dot_ast' backend (*note The
dot_ast backend::).


File: conceptual.info,  Node: Expressions,  Next: Task descriptions,  Prev: Primitives,  Up: Grammar

4.2 Expressions
===============

Expressions, as in any language, are a combination of primitives and
other expressions in a semantically meaningful juxtaposition.
coNCePTuaL provides arithmetic expressions, which evaluate to a number,
and relational expressions, which evaluate to either TRUE or FALSE.  In
addition, coNCePTuaL provides the notion of an "aggregate expression",
which represents a function (e.g., statistical mean) applied to every
value taken on by an arithmetic expression during the run of a program.

* Menu:

* Arithmetic expressions::      Arithmetic expressions
* Built-in functions::          List of additional arithmetics
* Aggregate expressions::       Expressions with a function applied
                                to all instances
* Aggregate functions::         List of functions allowed in the above
* Relational expressions::      Relating one expression to another
* Range expressions::           Expression lists


File: conceptual.info,  Node: Arithmetic expressions,  Next: Built-in functions,  Prev: Expressions,  Up: Expressions

4.2.1 Arithmetic expressions
----------------------------

coNCePTuaL supports a variety of arithmetic expressions.  The following
is the language's order of operations from highest to lowest precedence:

unary            '+', '-', 'NOT', '<FUNCTION>(<EXPR>, ...)', 'REAL(<EXPR>)'
                 
power            '**'
                 
multiplicative   '*', '/', 'MOD', '<<', '>>', '&'
                 
additive         '+', '-', '|', 'XOR'
                 
conditional      '<EXPR> 'IF' <REL_EXPR> 'OTHERWISE' <EXPR>'

In addition, as in most programming languages, parentheses can be used
to group subexpressions.

   The '&' ("and"), '|' ("or"), 'XOR', and 'NOT' operators perform
bitwise, not logical, operations.  That is, they accept numerical
arguments, not truth-value arguments.  Hence, for example, '3 | 5' is
equal to '7'.

   '<<' and '>>' are bit-shift operators.  That is, 'a << b' is the
coNCePTuaL equivalent of the mathematical expression a * 2^b and 'a >>
b' is the coNCePTuaL equivalent of the mathematical expression a / 2^b.
Consequently, negative values of b are valid and correspond to a shift
in the opposite direction.  (In contrast, C and Perl treat a negative
shift amount as a--usually large--unsigned number and Python raises a
'ValueError' exception on negative shifts.)

   'MOD' is a modulo (i.e., remainder) operator: '10 MOD 3' returns '1'.
'MOD' is guaranteed to return a nonnegative remainder.  Hence, '16 MOD
7' and '16 MOD -7' both return '2' even though '-5' is also
mathematically valid.  Similarly, '-16 MOD 7' and '-16 MOD -7' both
return '5' even though '-2' is also mathematically valid.

   The function calls allowed in '<FUNCTION>(<EXPR>, ...)' are listed
and described in *note Built-in functions::.  All functions take one or
more arithmetic expressions as an argument.  The operator '*' represents
multiplication; '/' represents division; and '**' represents
exponentiation (i.e., 'x ** y' == x^y, rounded towards zero).  Note that
0^y generates a run-time error for y <= 0.

   A conditional expression '<EXPR1> 'IF' <REL_EXPR> 'OTHERWISE'
<EXPR2>' evaluates to <EXPR1> if the relational expression <REL_EXPR>
evaluates to TRUE and <EXPR2> if <REL_EXPR> evaluates to FALSE.(1)
Relational expressions are described in *note Relational expressions::.
As some examples of conditional expressions, '666 IF 2+2=5 OTHERWISE
777' returns '777' while '666 IF 2+2=4 OTHERWISE 777' returns '666'.

   All operations proceed left-to-right except power and conditional
expressions, which proceed right-to-left.  That is, '4-3-2' means
(4-3)-2 but '4**3**2' means 4^(3^2).  Similarly, '2 IF p=0 OTHERWISE 1
IF p=1 OTHERWISE 0' associates like '2 IF p=0 OTHERWISE (1 IF p=1
OTHERWISE 0)', not like '(2 IF p=0 OTHERWISE 1) IF p=1 OTHERWISE 0'.

* Menu:

* Evaluation contexts::         Integer context vs. floating-point context
* Formal grammar for arithmetic expressions::  EBNF version of the preceding
                                               prose

   ---------- Footnotes ----------

   (1) It is therefore analogous to '<REL_EXPR> ? <EXPR1> : <EXPR2>' in
the C programming language.


File: conceptual.info,  Node: Evaluation contexts,  Next: Formal grammar for arithmetic expressions,  Prev: Arithmetic expressions,  Up: Arithmetic expressions

Evaluation contexts
...................

coNCePTuaL normally evaluates arithmetic expressions in "integer
context", meaning that each subexpression is truncated to the nearest
integer after being evaluated.  Hence, '24/5*5' is '20', not '24',
because '24/5*5' = '(24/5)*5' = '4*5' = '20'.  There are a few
situations, however, in which coNCePTuaL evaluates expressions in
"floating-point context", meaning that no truncation occurs:

   * within an 'OUTPUTS' statement (*note Writing to standard output::)

   * within a 'LOGS' statement (*note Writing to a log file::)

   * within a 'BACKEND EXECUTES' statement (*note Injecting arbitrary
     code::)

   * within a range in a 'FOR EACH' statement (*note Range loops::) when
     coNCePTuaL is unable to find an arithmetic or geometric progression
     by evaluating the component <EXPR>s in integer context

Within any of the preceding statements, the expression '24/5*5'
evaluates to 24.  Furthermore, the expression '24/5' evaluates to 4.8,
which is a number that can't be entered directly in a coNCePTuaL
program.  (The language supports only integral constants, as mentioned
in *note Primitives::.)

   The coNCePTuaL language provides a special form called 'REAL', which
resembles a single-argument function.  When evaluated in floating-point
context, 'REAL' returns its argument evaluated normally, as if 'REAL'
were absent.  When evaluated in integer context, however, 'REAL'
evalutes its argument in floating-point context and then rounds the
result to the nearest integer.  For example, in integer context, '9/2 +
1/2' is '4' while 'REAL(9/2 + 1/2)' is '5'.


File: conceptual.info,  Node: Formal grammar for arithmetic expressions,  Prev: Evaluation contexts,  Up: Arithmetic expressions

Formal grammar for arithmetic expressions
.........................................

For completeness, the following productions formalize the process by
which coNCePTuaL parses arithmetic expressions:

<EXPR>   ::=   <COND_EXPR>

<COND_EXPR>   ::=   <ADD_EXPR> 'IF' <REL_EXPR> 'OTHERWISE' <ADD_EXPR>

<ADD_EXPR>   ::=   <MULT_EXPR>
             |     <ADD_EXPR> '+' <MULT_EXPR>
             |     <ADD_EXPR> '-' <MULT_EXPR>
             |     <ADD_EXPR> '|' <MULT_EXPR>
             |     <ADD_EXPR> 'XOR' <MULT_EXPR>

<MULT_EXPR>   ::=   <UNARY_EXPR>
              |     <MULT_EXPR> '*' <UNARY_EXPR>
              |     <MULT_EXPR> '/' <UNARY_EXPR>
              |     <MULT_EXPR> 'MOD' <UNARY_EXPR>
              |     <MULT_EXPR> '>>' <UNARY_EXPR>
              |     <MULT_EXPR> '<<' <UNARY_EXPR>
              |     <MULT_EXPR> '&' <UNARY_EXPR>

<POWER_EXPR>   ::=   <PRIMARY_EXPR> ['**' <UNARY_EXPR>]

<UNARY_EXPR>   ::=   <POWER_EXPR>
               |     <UNARY_OPERATOR> <UNARY_EXPR>

<UNARY_OPERATOR>   ::=   '+' | '-' | 'NOT'

<PRIMARY_EXPR>   ::=   '(' <EXPR> ')'
                 |     <IDENT>
                 |     <INTEGER>
                 |     <FUNC_NAME> '(' <ENUMERATED_EXPRS> ')'
                 |     'REAL' '(' <EXPR> ')'

<ENUMERATED_EXPRS>   ::=   <EXPR> [',' <EXPR>]*


File: conceptual.info,  Node: Built-in functions,  Next: Aggregate expressions,  Prev: Arithmetic expressions,  Up: Expressions

4.2.2 Built-in functions
------------------------

In addition to the operators described in *note Arithmetic
expressions::, coNCePTuaL contains a number of built-in functions that
perform a variety of arithmetic operations that are often found to be
useful in network correctness and performance testing codes.  These
include simple functions that map one number to another as well as a set
of topology-specific functions that help implement communication across
various topologies, specifically N-ary trees, meshes, tori, and K-nomial
trees.  coNCePTuaL currently supports the following functions:

<FUNC_NAME>   ::=   'ABS' | 'BITS' | 'CBRT' | 'FACTOR10' | 'LOG10' | 'MAX' | 'MIN' | 'ROOT' | 'SQRT'
              |     'CEILING' | 'FLOOR' | 'ROUND'
              |     'TREE_PARENT' | 'TREE_CHILD'
              |     'KNOMIAL_PARENT' | 'KNOMIAL_CHILD' | 'KNOMIAL_CHILDREN'
              |     'MESH_NEIGHBOR' | 'MESH_COORDINATE' | 'MESH_DISTANCE'
              |     'RANDOM_UNIFORM' | 'RANDOM_GAUSSIAN'
              |     'RANDOM_POISSON' | 'RANDOM_PARETO'
              |     'PROCESSOR_OF' | 'TASK_OF'
              |     'FILE_DATA' | 'STATIC_FILE_DATA'

   With a few exceptions, all of the above take as an argument one or
more numeric values (which may be the result of an arithmetic
expression).  The following sections describe each function in turn.

* Menu:

* Integer functions::           Map one integer to another
* Floating-point functions::    Map one floating-point value to another
* n-ary tree functions::        Find parents and children in n-ary trees
* k-nomial tree functions::     Find parents and children in k-nomial trees
* Mesh/torus functions::        Find neighbors in 1-D, 2-D, and 3-D meshes/tori
* Random-number functions::     Generate unsynchronized pseudorandom numbers
* Processor/task mapping functions::  Map between physical and virtual task IDs
* File-reading functions::      Extract numbers from file data


File: conceptual.info,  Node: Integer functions,  Next: Floating-point functions,  Prev: Built-in functions,  Up: Built-in functions

Integer functions
.................

'ABS' returns the absolute value of its argument.  For example,
'ABS(99)' and 'ABS(-99)' are both '99'.

   'BITS' returns the minimum number of bits needed to store its
argument.  For example, 'BITS(12345)' is '14' because 2^14 is 16,384,
which is larger than 12,345, while 2^13 is 8,192, which is too small.
'BITS(0)' is defined to be '0'.  Essentially, 'BITS(x)' represents the
ceiling of the base-2 logarithm of x.  Negative numbers are treated as
their two's-complement equivalent.  For example, 'BITS(-1)' returns '32'
on a 32-bit system and '64' on a 64-bit system.

   'CBRT' is an integer cube root function.  It is essentially just
syntactic sugar for the more general 'ROOT' function: 'CBRT(X)' =
'ROOT(3, X)'.

   'FACTOR10' rounds its argument down (more precisely, towards zero) to
the largest single-digit factor of an integral power of 10.
'FACTOR10(4975)' is therefore '4000'.  Similarly, 'FACTOR10(-4975)'
is '-4000'.

   'LOG10(x)' is the floor of the base-10 logarithm of x.  For instance,
'LOG10(12345)' is '4' because 10^4 is the largest integral power of 10
that does not exceed 12,345.

   'MIN' and 'MAX' return, respectively, the minimum and maximum value
in a list of numbers.  Unlike the other built-in functions, 'MIN' and
'MAX' accept an arbitrary number of arguments (but at least one).  For
example, 'MIN(8,6,7,5,3,0,9)' is '0' and 'MAX(8,6,7,5,3,0,9)' is '9'.

   'ROOT(n, x)' returns the nth root of x.  More precisely, it returns
the largest integer r such that r^n <= x.  'ROOT' is not currently
defined on negative values of x.  As an example of 'ROOT' usage,
'ROOT(5, 245)' is '3' because 3^5 = 243 <= 245 while 4^5 = 1024 > 245.
Similarly, 'ROOT(2, 16)' = '4'; 'ROOT(3, 27)' = '3'; 'ROOT(0, 0)' and
'ROOT(4, -245)' each return a run-time error; and, 'ROOT(-3, 8)' = '0'
(because 'ROOT(-3, 8)' = '1/ROOT(3, 8)' = '1/2' = '0').

   'SQRT' is an integer square root function.  It is essentially just
syntactic sugar for the more general 'ROOT' function: 'SQRT(X)' =
'ROOT(2, X)'.


File: conceptual.info,  Node: Floating-point functions,  Next: n-ary tree functions,  Prev: Integer functions,  Up: Built-in functions

Floating-point functions
........................

As stated in *note Arithmetic expressions::, there are certain
constructs in which expressions are evaluated in floating-point context
instead of integer context.  In such constructs, all of coNCePTuaL's
built-in functions accept and return floating-point values.
Furthermore, the 'CBRT', 'LOG10', 'ROOT', and 'SQRT' functions (*note
Integer functions::) compute floating-point results, not integer results
that are coerced into floating-point format.

   The following functions are not meaningful in integer context but are
in floating-point context:

   * 'CEILING'

   * 'FLOOR'

   * 'ROUND'

   'CEILING' returns the smallest integer not less than its argument.
For example, 'CEILING(-7777/10)' is '-777'.  (-778 is less than -777.7
while -777 is not less than -777.7.)

   'FLOOR' returns the largest integer not greater than its argument.
For example, 'FLOOR(-7777/10)' is '-778'.  (-778 is not greater than
-777.7 while -777 is greater than -777.7.)

   'ROUND' rounds its argument to the nearest integer.  For example,
'ROUND(-7777/10)' is '-778'.

   It is not an error to use 'CEILING', 'FLOOR', and 'ROUND' in an
integer context; each function merely return its argument unmodified.


File: conceptual.info,  Node: n-ary tree functions,  Next: k-nomial tree functions,  Prev: Floating-point functions,  Up: Built-in functions

n-ary tree functions
....................

N-ary trees are used quite frequently in communication patterns because
they require only logarithmic time (in the number of tasks) for a
message to propagate from the root to a leaf.  coNCePTuaL supports N-ary
trees in the form of the 'TREE_PARENT' and 'TREE_CHILD' functions.

 -- Function: TREE_PARENT (TASK_ID [, FAN-OUT])
     'TREE_PARENT' takes a task number and an optional tree fan-out (n)
     and returns the task's parent in an N-ary tree.  n defaults to '2',
     i.e., a binary tree.  Taking the 'TREE_PARENT' of any task less
     than 1 returns the value '-1'.

 -- Function: TREE_CHILD (TASK_ID, CHILD [, FAN-OUT])
     'TREE_CHILD' takes a task number, a child number (0 <= i < N), and
     an optional tree fan-out (n), which again defaults to '2'.  It
     returns the task number corresponding to the given task's childth
     child.

   The following illustrations show how tasks are numbered in,
respectively, a 2-ary and a 3-ary tree:


                                              0
                                          +--/ \--+
                                         /         \
                                        1           2
                                      /   \       /   \
                                     3     4     5     6
                                    / \   / \   / \   / \
                                   7   8 9  10 11 12 13 14

                                             0
                                            /|\
                                      +----/ | \----+
                                     /       |       \
                                    1        2        3
                                  / | \    / | \    / | \
                                 4  5  6  7  8  9 10 11 12

   As shown by the 2-ary tree, task 1's children are task 3 and task 4.
Therefore, 'TREE_PARENT(3)' and 'TREE_PARENT(4)' are both '1';
'TREE_CHILD(1, 0)' is '3'; and, 'TREE_CHILD(1, 1)' is '4'.  In a 3-ary
tree, each task has three children.  Hence, the following expressions
hold:

   * 'TREE_PARENT(7, 3)' => '2'
   * 'TREE_PARENT(8, 3)' => '2'
   * 'TREE_PARENT(9, 3)' => '2'
   * 'TREE_CHILD(2, 0, 3)' => '7'
   * 'TREE_CHILD(2, 1, 3)' => '8'
   * 'TREE_CHILD(2, 2, 3)' => '9'


File: conceptual.info,  Node: k-nomial tree functions,  Next: Mesh/torus functions,  Prev: n-ary tree functions,  Up: Built-in functions

K-nomial tree functions
.......................

K-nomial trees are an efficient way to implement
collective-communication operations in software.  Unlike in an N-ary
tree, the number of children in a K-nomial tree decreases with
increasing task depth (i.e., no task has more children than the root).
The advantage is that the tasks that start communicating earlier perform
more work, which reduces the total latency of the collective operation.
In contrast, in an N-ary tree, the tasks that start communicating
earlier finish earlier, at the expense of increased total latency.
coNCePTuaL supports K-nomial trees via the 'KNOMIAL_PARENT',
'KNOMIAL_CHILDREN', and 'KNOMIAL_CHILD' functions, as described below.

 -- Function: KNOMIAL_PARENT (TASK_ID [, FAN_OUT [, NUM_TASKS]])
     'KNOMIAL_PARENT' takes a task number, the tree fan-out factor (the
     "K" in "K-ary"), and the number of tasks in the tree.  It returns
     the task ID of the given task's parent.  FAN_OUT defaults to '2'
     and the number of tasks defaults to 'num_tasks' (*note Predeclared
     variables::).

 -- Function: KNOMIAL_CHILDREN (TASK_ID [, FAN_OUT [, NUM_TASKS]])
     'KNOMIAL_CHILDREN' takes the same arguments as 'KNOMIAL_PARENT' but
     returns the number of immediate descendents the given task has.

 -- Function: KNOMIAL_CHILD (TASK_ID, CHILD [, FAN_OUT [, NUM_TASKS]])
     'KNOMIAL_CHILD' takes a task number, a child number (0 <= i <
     'KNOMIAL_CHILDREN(...)'), the tree fan-out factor, and the number
     of tasks in the tree.  It returns the task number corresponding to
     the given task's ith child.  As in 'KNOMIAL_PARENT' and
     'KNOMIAL_CHILDREN', FAN_OUT defaults to '2' and the number of tasks
     defaults to 'num_tasks' (*note Predeclared variables::).

   The following figure shows how coNCePTuaL numbers tasks in a K-nomial
tree with k=2 (a.k.a.  a 2-nomial or binomial tree).


                                                   0
                                                  /|\
                                                 1 | |
                                                /| | |
                                               3 | 2 |
                                               | | | |
                                               7 5 6 4

The figure is structured with time flowing downwards.  That is, for a
multicast operation expressed over a 2-nomial tree, task 0 sends a
message to task 1 in the first time step.  Then, task 0 sends to task 2
while task 1 sends to task 3.  In the final step, task 0 sends to
task 4, task 1 sends to task 5, task 2 sends to task 6, and task 3 sends
to task 7--all concurrently.  The following expressions also hold,
assuming there are a total of eight tasks in the computation:

   * 'KNOMIAL_PARENT(0)' => '-1'
   * 'KNOMIAL_PARENT(1)' => '0'
   * 'KNOMIAL_CHILDREN(1)' => '2'
   * 'KNOMIAL_CHILD(1, 0)' => '3'
   * 'KNOMIAL_CHILD(1, 1)' => '5'
   * 'KNOMIAL_CHILDREN(7)' => '0'
   * 'KNOMIAL_CHILD(7, 0)' => '-1'

   K-nomial trees for k>2 are much less common in practice than 2-nomial
trees.  However, they may perform well when a task has sufficient
bandwidth to support multiple, simultaneous, outgoing messages.  For
example, a trinomial tree (i.e., a K-nomial tree with k=3) should
exhibit good performance if there is enough bandwidth to send two
messages simultaneously.  The following illustration shows how
coNCePTuaL constructs a 27-task trinomial tree:


                                         0
                                         |
                +--------------------+---+-------+------+----+---+
                |                    |           |      |    |   |
                1                    2           |      |    |   |
                |                    |           |      |    |   |
       +------+-+--+---+    +------+-+--+---+    |      |    |   |
       |      |    |   |    |      |    |   |    |      |    |   |
       4      7    |   |    5      8    |   |    3      6    |   |
       |      |    |   |    |      |    |   |    |      |    |   |
     +-+-+  +-+-+  |   |  +-+-+  +-+-+  |   |  +-+-+  +-+-+  |   |
     |   |  |   |  |   |  |   |  |   |  |   |  |   |  |   |  |   |
    13  22 16  25 10  19 14  23 17  26 11  20 12  21 15  24  9  18

As before, time flows downward (assuming a multicast operation) and
tasks are expected to communicate with their children in order.  The
following are some coNCePTuaL K-nomial tree expressions and their
evaluations, assuming 'num_tasks' is '27':

   * 'KNOMIAL_PARENT(0, 3)' => '-1'
   * 'KNOMIAL_PARENT(2, 3)' => '0'
   * 'KNOMIAL_CHILDREN(2, 3)' => '4'
   * 'KNOMIAL_CHILD(2, 0, 3)' => '5'
   * 'KNOMIAL_CHILD(2, 1, 3)' => '8'
   * 'KNOMIAL_CHILD(2, 2, 3)' => '11'
   * 'KNOMIAL_CHILD(2, 3, 3)' => '20'
   * 'KNOMIAL_CHILD(2, 4, 3)' => '-1'
   * 'KNOMIAL_CHILDREN(8, 3)' => '2'
   * 'KNOMIAL_CHILDREN(8, 3, 26)' => '1'
   * 'KNOMIAL_CHILDREN(8, 3, 10)' => '0'


File: conceptual.info,  Node: Mesh/torus functions,  Next: Random-number functions,  Prev: k-nomial tree functions,  Up: Built-in functions

Mesh/torus functions
....................

coNCePTuaL provides three functions--'MESH_NEIGHBOR', 'MESH_COORDINATE',
and 'MESH_DISTANCE'--that help treat (linear) task IDs as positions on a
multidimensional mesh or torus.  Each of these functions takes a
variable number of arguments, determined by the dimensionality of the
mesh (1-D, 2-D, or 3-D).

     _Terminology note_: In the context of network topologies in general
     and 'MESH_NEIGHBOR', 'MESH_COORDINATE', and 'MESH_DISTANCE' in
     particular, "torus" refers to a mesh topology, of any number of
     dimensions, that contains wraparound links.  That is, nodes on the
     right side of the mesh are directly connected to nodes on the left
     side of the mesh, nodes on the top of the mesh are directly
     connected to nodes on the bottom of the mesh, and so forth.  A
     "partial torus" refers to a mesh topology of two or more dimensions
     in which at least one dimension contains wraparound links and at
     least one dimension does not.

 -- Function: MESH_NEIGHBOR ('(' WIDTH '*'? [, HEIGHT '*'?
          [, DEPTH '*'?]] ')', TASK_ID, '(' X_OFFSET [, Y_OFFSET
          [, Z_OFFSET]] ')')
     'MESH_NEIGHBOR' returns a task's neighbor on a 1-D, 2-D, or 3-D
     mesh or torus.  It takes exactly three arguments: a list of the
     mesh/torus's dimensions, a task number, and a list of the
     neighbor's offset in each dimension from the given task.  The two
     list arguments must be parenthesized, even if they contain only a
     single element.  Each dimension in the dimension list may be
     followed by an asterisk to indicate that the mesh wraps around in
     that dimension.  If not specified, HEIGHT and DEPTH default to '1',
     and Y_OFFSET and Z_OFFSET default to '0'.  In the absence of
     wraparound links, offsets that move off the mesh cause
     'MESH_NEIGHBOR' to return the value '-1'.

 -- Function: MESH_COORDINATE ('(' WIDTH '*'? [, HEIGHT '*'?
          [, DEPTH '*'?]] ')', TASK_ID, COORDINATE)
     'MESH_COORDINATE' returns a task's X, Y, or Z coordinate on a 1-D,
     2-D, or 3-D mesh/torus.  The first argument to 'MESH_COORDINATE' is
     a list of the mesh/torus's dimensions.  The second argument is a
     task number.  The third argument should be '0' to calculate an X
     coordinate, '1' to calculate a Y coordinate, or '2' to calculate a
     Z coordinate.  Coordinates are zero-origined.  Each dimension in
     the dimension list may be followed by an asterisk to indicate that
     the mesh wraps around in that dimension, but this has no impact on
     the result.  (Asterisks are allowed solely for consistency with the
     other mesh functions.)

 -- Function: MESH_DISTANCE ('(' WIDTH '*'? [, HEIGHT '*'?
          [, DEPTH '*'?]] ')', TASK_ID_1, TASK_ID_2)
     'MESH_DISTANCE' returns the shortest Manhattan distance between two
     tasks on a 1-D, 2-D, or 3-D mesh or torus.  It takes exactly three
     arguments: a list of the mesh/torus's dimensions and two task
     numbers.  The list argument must be parenthesized, even if it
     contains only a single element.  Each dimension in the dimension
     list may be followed by an asterisk to indicate that the mesh wraps
     around in that dimension.  If not specified, HEIGHT and DEPTH
     default to '1'.

   'MESH_NEIGHBOR', 'MESH_COORDINATE', and 'MESH_DISTANCE' number tasks
following the right-hand rule: left-to-right, then top-to-bottom, and
finally back-to-front, as shown in the following illustrations of a
4-element (1-D) mesh, a 4x3 (2-D) mesh, and a 4x3x2 (3-D) mesh.
Examples of 'MESH_NEIGHBOR', 'MESH_COORDINATE', and 'MESH_DISTANCE' for
1-D, 2-D, and 3-D meshes follow the corresponding illustration.


             
                                        0 -- 1 -- 2 -- 3

   The following examples show how to use 'MESH_NEIGHBOR' and
'MESH_COORDINATE' to calculate neighbors and coordinates on the 1-D mesh
shown above:

   * 'MESH_NEIGHBOR((4), 0, (-1))' => '-1'
   * 'MESH_NEIGHBOR((4), 0, (+1))' => '1'
   * 'MESH_NEIGHBOR((4), 1, (-1))' => '0'
   * 'MESH_NEIGHBOR((4), 1, (+1))' => '2'
   * 'MESH_NEIGHBOR((4), 2, (-1))' => '1'
   * 'MESH_NEIGHBOR((4), 2, (+1))' => '3'
   * 'MESH_NEIGHBOR((4), 3, (-1))' => '2'
   * 'MESH_NEIGHBOR((4), 3, (+1))' => '-1'


   * 'MESH_COORDINATE((4), -1, 0)' => '-1'
   * 'MESH_COORDINATE((4), 0, 0)' => '0'
   * 'MESH_COORDINATE((4), 1, 0)' => '1'
   * 'MESH_COORDINATE((4), 2, 0)' => '2'
   * 'MESH_COORDINATE((4), 3, 0)' => '3'
   * 'MESH_COORDINATE((4), 4, 0)' => '-1'
   * 'MESH_COORDINATE((4), 2, 1)' => '0'
   * 'MESH_COORDINATE((4), 2, 2)' => '0'


   * 'MESH_DISTANCE((4), -1, 0)' => '-1'
   * 'MESH_DISTANCE((4), 1, 2)' => '1'
   * 'MESH_DISTANCE((4), 0, 3)' => '3'

   We can treat the 1-D mesh as a 1-D torus (a ring) by putting a '*'
after the length of the x dimension:

   * 'MESH_NEIGHBOR((4*), 0, (-1))' => '3'
   * 'MESH_NEIGHBOR((4*), 3, (+1))' => '0'

   * 'MESH_DISTANCE((4*), -1, 0)' => '-1'
   * 'MESH_DISTANCE((4*), 1, 2)' => '1'
   * 'MESH_DISTANCE((4*), 0, 3)' => '1'

The remaining 'MESH_NEIGHBOR' examples return the same value as before.
'MESH_COORDINATE' _always_ returns the same value regardless of the
presence or absence of wraparound links.


                                        0 -- 1 -- 2 -- 3
                                        |    |    |    |
                                        |    |    |    |
                                        |    |    |    |
                                        4 -- 5 -- 6 -- 7
                                        |    |    |    |
                                        |    |    |    |
                                        |    |    |    |
                                        8 -- 9 - 10 - 11

   The next set of examples shows how to use 'MESH_NEIGHBOR',
'MESH_COORDINATE', and 'MESH_DISTANCE' to calculate neighbors,
coordinates, and distances on the 2-D mesh shown above:

   * 'MESH_NEIGHBOR((4, 3), 5, (-1, -1))' => '0'
   * 'MESH_NEIGHBOR((4, 3), 5, ( 0, -1))' => '1'
   * 'MESH_NEIGHBOR((4, 3), 5, (+1, -1))' => '2'
   * 'MESH_NEIGHBOR((4, 3), 5, (-1, 0))' => '4'
   * 'MESH_NEIGHBOR((4, 3), 5, ( 0, 0))' => '5'
   * 'MESH_NEIGHBOR((4, 3), 5, (+1, 0))' => '6'
   * 'MESH_NEIGHBOR((4, 3), 5, (-1, +1))' => '8'
   * 'MESH_NEIGHBOR((4, 3), 5, ( 0, +1))' => '9'
   * 'MESH_NEIGHBOR((4, 3), 5, (+1, +1))' => '10'


   * 'MESH_COORDINATE((4, 3), 1, 0)' => '1'
   * 'MESH_COORDINATE((4, 3), 6, 0)' => '2'
   * 'MESH_COORDINATE((4, 3), 6, 1)' => '1'
   * 'MESH_COORDINATE((4, 3), 6, 2)' => '0'
   * 'MESH_COORDINATE((4, 3), 8, 0)' => '0'
   * 'MESH_COORDINATE((4, 3), 8, 1)' => '2'
   * 'MESH_COORDINATE((4, 3), 12, 0)' => '-1'


   * 'MESH_DISTANCE((4, 3), 1, 2)' => '1'
   * 'MESH_DISTANCE((4, 3), 2, 6)' => '1'
   * 'MESH_DISTANCE((4, 3), 0, 5)' => '2'
   * 'MESH_DISTANCE((4, 3), 3, 9)' => '4'
   * 'MESH_DISTANCE((4, 3), 11, 0)' => '5'

   Wraparound links turn some out-of-bounds ('-1') neighbor values into
in-bounds values and reduce some of the shortest-path distances between
tasks:

   * 'MESH_NEIGHBOR((4, 3), 5, (-2, 0))' => '-1'
   * 'MESH_NEIGHBOR((4, 3), 5, (-2, -2))' => '-1'
   * 'MESH_NEIGHBOR((4, 3*), 5, (-2, 0))' => '-1'
   * 'MESH_NEIGHBOR((4, 3*), 5, (-2, -2))' => '-1'
   * 'MESH_NEIGHBOR((4*, 3), 5, (-2, 0))' => '7'
   * 'MESH_NEIGHBOR((4*, 3), 5, (-2, -2))' => '-1'
   * 'MESH_NEIGHBOR((4*, 3*), 5, (-2, 0))' => '7'
   * 'MESH_NEIGHBOR((4*, 3*), 5, (-2, -2))' => '11'


   * 'MESH_DISTANCE((4*, 3*), 1, 2)' => '1'
   * 'MESH_DISTANCE((4*, 3*), 2, 6)' => '1'
   * 'MESH_DISTANCE((4*, 3*), 0, 5)' => '2'
   * 'MESH_DISTANCE((4*, 3*), 3, 9)' => '3'
   * 'MESH_DISTANCE((4*, 3*), 11, 0)' => '2'


                      			   0 -- 1 -- 2 -- 3
                      			   |\   |\   |\   |\
                      			   | 12 + 13 + 14 + 15
                      			   |  | |  | |  | |  |
                      			   4 -+ 5 -+ 6 -+ 7  |
                      			   |\ | |\ | |\ | |\ |
                      			   | 16 + 17 + 18 + 19
                      			   |  | |  | |  | |  |
                      			   8 -+ 9 -+10 -+11  |
                      			    \ |  \ |  \ |  \ |
                      			     20 - 21 - 22 - 23

   The final set of examples in this section shows how to use
'MESH_NEIGHBOR', 'MESH_COORDINATE', and 'MESH_DISTANCE' to calculate
neighbors, coordinates, and distances on the 3-D mesh shown above:

   * 'MESH_NEIGHBOR((4, 3, 2), 0, (0, 0, +1))' => '12'
   * 'MESH_NEIGHBOR((4, 3, 2), 0, (0, +1, 0))' => '4'
   * 'MESH_NEIGHBOR((4, 3, 2), 0, (+1, 0, 0))' => '1'
   * 'MESH_NEIGHBOR((4, 3, 2), 0, (+1, +1, +1))' => '17'
   * 'MESH_NEIGHBOR((4, 3, 2), 17, (+2, -1, -1))' => '3'
   * 'MESH_NEIGHBOR((4, 3, 2), 23, (+1, +1, +1))' => '-1'
   * 'MESH_NEIGHBOR((4, 3, 2), 7, (+100, -200, +300))' => '-1'


   * 'MESH_COORDINATE((4, 3, 2), -5, 0)' => '-1'
   * 'MESH_COORDINATE((4, 3, 2), 1, 0)' => '1'
   * 'MESH_COORDINATE((4, 3, 2), 6, 0)' => '2'
   * 'MESH_COORDINATE((4, 3, 2), 6, 1)' => '1'
   * 'MESH_COORDINATE((4, 3, 2), 6, 2)' => '0'
   * 'MESH_COORDINATE((4, 3, 2), 18, 0)' => '2'
   * 'MESH_COORDINATE((4, 3, 2), 18, 1)' => '1'
   * 'MESH_COORDINATE((4, 3, 2), 18, 2)' => '1'
   * 'MESH_COORDINATE((4, 3, 2), 18, 3)' => error-> Invalid coordinate


   * 'MESH_DISTANCE((4, 3, 2), 23, 24)' => '-1'
   * 'MESH_DISTANCE((4, 3, 2), 5, 17)' => '1'
   * 'MESH_DISTANCE((4, 3, 2), 1, 16)' => '3'
   * 'MESH_DISTANCE((4, 3, 2), 14, 8)' => '5'
   * 'MESH_DISTANCE((4, 3, 2), 0, 23)' => '6'

   As before, wraparound links affect some of the return values:

   * 'MESH_NEIGHBOR((4*, 3*, 2*), 23, (+1, +1, +1))' => '0'
   * 'MESH_NEIGHBOR((4*, 3*, 2*), 7, (+100, -200, +300))' => '11'


   * 'MESH_DISTANCE((4*, 3*, 2*), 23, 24)' => '-1'
   * 'MESH_DISTANCE((4*, 3*, 2*), 5, 17)' => '1'
   * 'MESH_DISTANCE((4*, 3*, 2*), 1, 16)' => '3'
   * 'MESH_DISTANCE((4*, 3*, 2*), 14, 8)' => '4'
   * 'MESH_DISTANCE((4*, 3*, 2*), 0, 23)' => '3'


File: conceptual.info,  Node: Random-number functions,  Next: Processor/task mapping functions,  Prev: Mesh/torus functions,  Up: Built-in functions

Random-number functions
.......................

coNCePTuaL programs can utilize randomness in one of two ways.  The
functions described below are _unsynchronized_ across tasks.  That is,
they can--and usually do--return a different value to each task on each
invocation.  One consequence is that these functions are not permitted
within a task expression (*note Task descriptions::) because randomness
would cause the tasks to disagree about who the sources and targets of
an operation are.  In contrast, the 'A RANDOM TASK' construct described
in *note Binding variables:: returns a value guaranteed to be
synchronized across tasks and thereby enables random-task selection.

 -- Function: RANDOM_UNIFORM (LOWER_BOUND, UPPER_BOUND)
     Return a number selected at random from a uniform distribution over
     the range [LOWER_BOUND, UPPER_BOUND).

 -- Function: RANDOM_GAUSSIAN (MEAN, STDDEV)
     Return a number selected at random from a Gaussian distribution
     with mean MEAN and standard deviation STDDEV.

 -- Function: RANDOM_POISSON (MEAN)
     Return an integer selected at random from a Poisson distribution
     with mean MEAN and standard deviation sqrt(MEAN).

 -- Function: RANDOM_PARETO (SHAPE, SCALE)
 -- Function: RANDOM_PARETO (SHAPE, LOWER_BOUND, UPPER_BOUND)
     With the two-argument form, return an integer selected at random
     from a Pareto distribution with shape SHAPE and scale SCALE.  With
     the three-argument form, return an integer selected at random from
     a bounded Pareto distribution with shape SHAPE and bounded by the
     range [LOWER_BOUND, UPPER_BOUND].


File: conceptual.info,  Node: Processor/task mapping functions,  Next: File-reading functions,  Prev: Random-number functions,  Up: Built-in functions

Processor/task mapping functions
................................

coNCePTuaL supports a level of indirection in task numbering.  The
language defines a "processor" as a value that does not change for the
task's entire lifetime and a "task" as a value that can be remapped at
will.  By default, task numbers match processor numbers, but if task
numbers are remapped (using the 'IS ASSIGNED TO' construct described in
*note Reordering task IDs::), the following functions can be used to
query the current mapping:

   'TASK_OF' returns the task number associated with a given processor
number.

   'PROCESSOR_OF' returns the processor number associated with a given
task number.

   These functions are especially useful when a task A RANDOM PROCESSOR
'IS ASSIGNED TO A RANDOM PROCESSOR', because there is no other mechanism
for determining the resulting task mapping.


File: conceptual.info,  Node: File-reading functions,  Prev: Processor/task mapping functions,  Up: Built-in functions

File-reading functions
......................

'FILE_DATA' interacts with the surrounding system by parsing a named
file as a table and returning the contents of a specified row and
column.

 -- Function: FILE_DATA ('(' FILENAME [, COLUMN [, ROW [, COLUMN-SEPS [,
          ROW-SEPS]]]] ')')
     Read the contents of file FILENAME and parse the data read into
     rows and columns.  Rows are separated by one or more characters
     appearing in the string ROW-SEPS (default: '\n', i.e., a newline
     character).  Columns are separated by one or more characters
     appearing in the string COL-SEPS (default: ' \t', i.e., a space and
     a tab).  Once the data are parsed in this manner, the cell at
     column COLUMN (default: '1') and row ROW (default: '1') is
     converted to a number and returned.

     Columns and rows are each numbered starting from 1.  Negative
     numbers represent offsets from the _last_ column or row.  Zero
     values cause the program to abort with an error message.

   Consider a data file, 'example.dat', with the following contents:

     Eir    231  58 490 703  19 644 967
     Gunnr  901 875 141 372 374 618  77
     Herja   17 979 363 930 977
     Hrist  100 132 981 246  93 614
     Svipul 688 536 965 746 209

Then, the following uses of 'FILE_DATA' return the results shown:

   * 'FILE_DATA("example.dat")' => '0'
     (The default cell is (1, 1), which contains 'Eir', and this is
     converted to 0.)

   * 'FILE_DATA("example.dat", 3)' => '58'

   * 'FILE_DATA("example.dat", 3, 2)' => '875'

   * 'FILE_DATA("example.dat", 3, -4)' => '875'

   * 'FILE_DATA("example.dat", 3, -6)' => error-> Too few rows

   * 'FILE_DATA("example.dat", -3, -2)' => '246'
     (The function first finds the row, then the column within the row.)

   * 'FILE_DATA("example.dat", 0)' => error-> Column number is zero

   The use of 'FILE_DATA' is discouraged in coNCePTuaL programs because
of its reliance on external files, whose contents are not automatically
preserved in any coNCePTuaL log files (*note Interpreting coNCePTuaL log
files::) and which may exhibit system-specific behavior (e.g., if the
file is in fact a named pipe or a file-like interface to a kernel data
structure).  However, 'FILE_DATA' can be useful in certain circumstances
for logging changes in system state of which coNCePTuaL would otherwise
be unaware.  For example, one might log values from various pseudo-files
appearing in Linux's '/proc' filesystem or from system log files (e.g.,
those within Linux's '/var/log' directory).

   Because coNCePTuaL cannot determine a priori if multiple reads of the
same row and column from the same file will produce the same value it
pessimistically assumes that each read produces a different value.
(Consider even the simple case of 'FILE_DATA' reading the last row of a
system log file to which another process is asynchronously appending.)
Consequently, 'FILE_DATA' cannot be used in any context that requires
multiple tasks to agree on a value, such as within message
specifications (*note Message specifications::) or let bindings (*note
Binding variables::).  For cases where the programmer can assert that
reads from a particular row and column will always return the same value
(on penalty of undefined behavior, including hangs and crashes),
coNCePTuaL provides the following function:

 -- Function: STATIC_FILE_DATA ('(' FILENAME [, COLUMN [, ROW [,
          COLUMN-SEPS [, ROW-SEPS]]]] ')')
     Perform exactly the same operation as 'FILE_DATA' but with the
     programmer's guarantee that the file contents will not change from
     invocation to invocation.  'STATIC_FILE_DATA' can therefore be used
     in places where 'FILE_DATA' is disallowed.

   Given the 'example.dat' file shown previously, the following let
binding is legitimate:

     LET msg_size BE STATIC_FILE_DATA("example.dat", 2, iter) AND rank_ofs
     BE STATIC_FILE_DATA("example.dat", 3, iter) MOD num_tasks WHILE ...

However, the following, which uses 'FILE_DATA' instead of
'STATIC_FILE_DATA', is not:

     LET msg_size BE FILE_DATA("example.dat", 2, iter) AND rank_ofs BE
     FILE_DATA("example.dat", 3, iter) MOD num_tasks WHILE ...

   'STATIC_FILE_DATA' can be used as above to implement complex,
irregular communication patterns that vary across runs of the program.
That is, each iteration, a different value read from the file can be
used to specify the message size and the distance between senders and
receivers.

   The use of 'STATIC_FILE_DATA' is even more discouraged than the use
of 'FILE_DATA' because an incorrect claim that a file's contents are
unvarying could lead to abnormal program behavior--and not necessarily
easily detectable.  It is best to avoid both 'FILE_DATA' and
'STATIC_FILE_DATA' if possible.  If not, use 'FILE_DATA' unless (a) the
compiler rejects the program on the grounds that 'FILE_DATA' is being
used in an invalid location and (b) the data being read is known to be
invariant throughout the lifetime of the program.


File: conceptual.info,  Node: Aggregate expressions,  Next: Aggregate functions,  Prev: Built-in functions,  Up: Expressions

4.2.3 Aggregate expressions
---------------------------

Aggregate expressions (<AGGR_EXPR>s) are currently used exclusively by
the 'LOGS' statement.  They represent an expression with a given
function applied to the aggregate of all (dynamic) instances of that
expression.  <AGGR_EXPR>s take one of four forms:

<AGGR_EXPR>   ::=   ['EACH'] <EXPR>
              |     'THE' <EXPR>
              |     'THE' <AGGR_FUNC> ['AND' 'THE' <AGGR_FUNC>]* ['OF' ['THE']] <EXPR>
              |     'A HISTOGRAM OF' ['THE'] <EXPR>

(In the above, <EXPR> refers to an arithmetic expression defined in
*note Arithmetic expressions:: and <AGGR_FUNC> refers to one of the
functions defined in *note Aggregate functions::.)

   The first form does not summarize <EXPR>; every individual instance
of <EXPR> is utilized.  The second form asserts that <EXPR> is a
constant (i.e., all values are identical) and utilizes that constant.(1)
The third form applies each <AGGR_FUNC> to the set of all values of
<EXPR> and utilizes the result of that function.  The fourth form
produces a histogram of all values of <EXPR>, i.e., a list of {UNIQUE
VALUE, TALLY} pairs, sorted by UNIQUE VALUE.

   ---------- Footnotes ----------

   (1) The program aborts with a run-time error if <EXPR> is not a
constant.


File: conceptual.info,  Node: Aggregate functions,  Next: Relational expressions,  Prev: Aggregate expressions,  Up: Expressions

4.2.4 Aggregate functions
-------------------------

The following functions, referred to collectively as <AGGR_FUNC>s, may
be used in an aggregate expression (*note Aggregate expressions::):

<AGGR_FUNC>   ::=   ['ARITHMETIC'] 'MEAN' | 'HARMONIC MEAN' | 'GEOMETRIC MEAN' | 'MEDIAN' |
                    'STANDARD DEVIATION' | 'VARIANCE' | 'MEDIAN ABSOLUTE DEVIATION' | 'SUM'
                    | 'MINIMUM' | 'MAXIMUM' | 'FINAL' | <EXPR> 'PERCENTILE'

   'MEAN' and 'ARITHMETIC MEAN' are equivalent.  'MEDIAN' is the value
such that there are as many larger as smaller values.  If there are an
even number of values, 'MEDIAN' is the arithmetic mean of the two
medians.  'FINAL' returns only the final value measured.  'PERCENTILE'
returns a given percentile, <EXPR>, of the values.  <EXPR> must lie in
the range [0, 100].  Percentile values are computed as x_g + (h - g)(x_g
- x_h), where x is the data in sorted order and h is (|x| - 1) * p/100 +
1 when computing the value at the pth percentile.  (See Wikipedia's
entry on _quantile_ (http://en.wikipedia.org/wiki/Quantile) for more
information.)  The interpretation of the remaining aggregate functions
should be unambiguous.


File: conceptual.info,  Node: Relational expressions,  Next: Range expressions,  Prev: Aggregate functions,  Up: Expressions

4.2.5 Relational expressions
----------------------------

Relational expressions (<REL_EXPR>s) compare two arithmetic expressions
(*note Arithmetic expressions::) or test an arithmetic expression for a
property.  A relational expression can be either TRUE or FALSE.

   coNCePTuaL supports a variety of relational expressions.  The
following is the language's order of operations from highest to lowest
precedence:

unary/        'IS EVEN', 'IS ODD'
binary/       '=', '<', '>', '<=', '>=', '<>', 'DIVIDES', 'IS IN', 'IS NOT IN'
              
conjunctive   '/\'
              
disjunctive   '\/'

In addition, as in most programming languages, parentheses can be used
to group subexpressions.

   The unary relation 'IS EVEN' is TRUE if a given arithmetic expression
represents an even number and the unary relation 'IS ODD' is TRUE if a
given arithmetic expression represents an odd number.  For example,
'456 IS EVEN' is TRUE and '64 MOD 6 IS ODD' is FALSE.

   The coNCePTuaL operators '=', '<', '>', '<=', '>=', and '<>'
represent, respectively, the mathematical relations =, <, >, <=, >=, and
<> (i.e., not equal).  These are all binary relations that operate on
arithmetic expressions (*note Arithmetic expressions::).  For example,
'2+2 = 4' is TRUE and '2**3 > 2**4' is FALSE.  The 'DIVIDES' relation is
TRUE if the first expression evenly divides the second, i.e., that e2 =
0 (mod e1).  Hence, '2 DIVIDES 1234' (equivalent to '1234 MOD 2 = 0') is
TRUE while '2 DIVIDES 4321' (equivalent to '4321 MOD 2 = 0') is FALSE.

   The binary relation 'IS IN' has the form

        <EXPR> 'IS IN' <RANGE> [',' <RANGE>]*

   A <RANGE> represents a range expression.  Range expressions are
described in *note Range expressions::.  In short, a range expression
specifies a list of values by explicit enumeration, numeric progression,
or predicated combinations of other range expressions.  As an example,
the relational expression 'x 'IS IN' {1, ..., 5}' is TRUE if and only if
x is one of 1, 2, 3, 4, or 5.  As a more complex example, 'p*2 'IS IN'
{0}, {1, 2, 4, ..., num_tasks*2}' is TRUE if and only if twice p is
either zero or a power of two less than or equal to twice the number of
tasks being used.

   The complementary operation to 'IS IN' is the binary relation 'IS NOT
IN'.  Hence, '4 IS NOT IN {3, ..., 5}' is FALSE while '6 IS NOT IN
{3, ..., 5}' is TRUE.

   Conjunction (``and'') and disjunction (``or'') combine multiple
relational expressions. <REL_EXPR> '/\' <REL_EXPR> is TRUE if and only
if both <REL_EXPR>s are TRUE, and <REL_EXPR> '\/' <REL_EXPR> is TRUE if
and only if either <REL_EXPR> is TRUE.  For example, '456 IS EVEN \/
2**3 > 2**4' is TRUE and '456 IS EVEN /\ 2**3 > 2**4' is FALSE.
Conjunction and disjunction are both short-circuiting operations.
Evaluation proceeds left-to-right.  Expressions such as 'x<>0 /\ 1/x=1'
will therefore not result in a divide-by-zero error.

   coNCePTuaL does not currently have a logical negation operator.

* Menu:

* Formal grammar for relational expressions::  EBNF version of the preceding
                                               prose


File: conceptual.info,  Node: Formal grammar for relational expressions,  Prev: Relational expressions,  Up: Relational expressions

Formal grammar for relational expressions
.........................................

For completeness, the following productions formalize the process by
which coNCePTuaL parses relational expressions:

<REL_EXPR>   ::=   <REL_DISJ_EXPR>

<REL_DISJ_EXPR>   ::=   [<REL_DISJ_EXPR> '\/'] <REL_CONJ_EXPR>

<REL_CONJ_EXPR>   ::=   [<REL_CONJ_EXPR> '/\'] <REL_PRIMARY_EXPR>

<REL_PRIMARY_EXPR>   ::=   <EQ_EXPR>
                     |     '(' <REL_EXPR> ')'

<EQ_EXPR>   ::=   <EXPR> '=' <EXPR>
            |     <EXPR> '<' <EXPR>
            |     <EXPR> '>' <EXPR>
            |     <EXPR> '<=' <EXPR>
            |     <EXPR> '>=' <EXPR>
            |     <EXPR> '<>' <EXPR>
            |     <EXPR> 'DIVIDES' <EXPR>
            |     <EXPR> 'IS EVEN'
            |     <EXPR> 'IS ODD'
            |     <EXPR> 'IS IN' <RANGE> [',' <RANGE>]*
            |     <EXPR> 'IS NOT IN' <RANGE> [',' <RANGE>]*


File: conceptual.info,  Node: Range expressions,  Prev: Relational expressions,  Up: Expressions

4.2.6 Range expressions
-----------------------

Ranges are a powerful way of describing an ordered list of tasks.
Ranges come in three forms:

  1. Enumerated lists

  2. Arithmetic and geometric sequences

  3. List comprehensions

These are described with the following syntax:

<RANGE>   ::=   '{' <EXPR> [',' <EXPR>]* [', ... ,' <EXPR>] '}'
          |     '{' <EXPR> ['FOR EACH' <IDENT> 'IN' <RANGE> [',' <RANGE>]* ]+
                    ['WHERE' <REL_EXPR>] '}'

   Enumerated lists are the simplest type of range.  They represent a
list of explicitly specified values.  For example, the range '{2**3,
2+4, 14/2, 8-3, 1+1+1, 0, 5*2-1}' represents each of the seven numbers
8, 6, 7, 5, 3, 0, and 9 in turn.  Duplicate values are allowed in
enumerated lists so '{9, 3, 9, 5, 5, 5, 0, 1, 1, 3}' represents ten
numbers even though not all of them are unique.

   Arithmetic and geometric progressions are specified by including the
first few values of the progression, followed by an ellipsis, followed
by the final value of the progression.  A single initial value implies
an arithmetic progression with increment of +/- 1, depending on whether
the final value is greater or less than the initial value.  Two initial
values imply an arithmetic progression with an increment of
SECOND-FIRST.  If three or more initial values are provided, coNCePTuaL
first looks for an arithmetic progression, then a geometric progression.
If coNCePTuaL finds neither an arithmetic nor a geometric progression,
it re-evaluates all of the <EXPR>s in floating-point context (*note
Arithmetic expressions::) and tries once again to find a geometric
progression.  If a pattern is still not found, a run-time error message
is generated.  As some examples of arithmetic and geometric range
expressions, the range '{10, ..., 1E6}' represents the values 10, 11,
12, 13, 14, 15, and so forth by ones up to 1,000,000; the range '{10,
12, ..., 1E6}' represents the values 10, 12, 14, 16, and so forth by
twos up to 1,000,000; and the range '{10, 100, 1000, ..., 1E6}'
represents the values 10, 100, 1000, 10000, 100000, and 1000000.

   Arithmetic and geometric progressions do not necessarily include the
final value.  For example, the range '{1, 4, ..., 15}' represents the
values 1, 4, 7, 10, and 13 but not 15, even though 15 is specified as
the final value of the range.  Similarly, '{15, 12, ..., 1}' represents
the values 15, 12, 9, 6, and 3 but not 1, even though 1 is specified as
the final value of the range.  Progressions stop at or before the final
value, never after.  If the number following the ellipsis is less than
(respectively, greater than) the first number in an increasing
(respectively, decreasing) range (as in '{15, 25, ..., 5}'), then the
range represents an empty list of values.

   List comprehensions provide a way to combine and filter ranges to
describe complex sequences of values with comparatively little code.(1)
A simple example is '{n FOR EACH n IN {1, ..., 10}}', but this is not
particularly useful, as the range '{1, ..., 10}' represents the same
list of values.  However, replacing the expression 'n' with 'n/2' to get
'{n/2 FOR EACH n IN {1, ..., 10}}' returns the values 0, 1, 1, 2, 2, 3,
3, 4, 4, and 5, which would be more difficult to express without a list
comprehension.  We can even utilize only a subset of those values by
applying a filter.  For example, '{n/2 FOR EACH n IN {1, ..., 10} WHERE
n/2 IS ODD}' represents the values 1, 1, 3, 3, and 5.  List
comprehensions can be multivariate, as in the following example:

     {diag+ofs
       FOR EACH diag IN {0, 11, ..., 99}
         FOR EACH ofs IN {-1, 0, 1}
           WHERE diag+ofs IS IN {0, ..., 99}}

   That single range expression represents all cells on the tridiagonal
of a 10x10 matrix, with cell 0 in the upper left and cell 99 in the
lower right.  The first 'FOR EACH' generator binds 'diag' to each cell
on the diagonal: 0, 11, 22, 33, and so forth.  The second 'FOR EACH'
generator binds 'ofs' to each of -1, 0, and 1.  The 'WHERE' predicate,
which itself uses a range expression, selects only those values of
'diag' and 'ofs' which which 0 <= diag+ofs <= 99.  The value 'diag+ofs'
is returned for all values for which the predicate is true.  The
following figure illustrates the values described by the preceding range
expression:


        	 +----+----+----+----+----+----+----+----+----+----+
        	 |  0 |  1 |    |    |    |    |    |    |    |    |
        	 +----+----+----+----+----+----+----+----+----+----+
        	 | 10 | 11 | 12 |    |    |    |    |    |    |    |
        	 +----+----+----+----+----+----+----+----+----+----+
        	 |    | 21 | 22 | 23 |    |    |    |    |    |    |
        	 +----+----+----+----+----+----+----+----+----+----+
        	 |    |    | 32 | 33 | 34 |    |    |    |    |    |
        	 +----+----+----+----+----+----+----+----+----+----+
        	 |    |    |    | 43 | 44 | 45 |    |    |    |    |
        	 +----+----+----+----+----+----+----+----+----+----+
        	 |    |    |    |    | 54 | 55 | 56 |    |    |    |
        	 +----+----+----+----+----+----+----+----+----+----+
        	 |    |    |    |    |    | 65 | 66 | 67 |    |    |
        	 +----+----+----+----+----+----+----+----+----+----+
        	 |    |    |    |    |    |    | 76 | 77 | 78 |    |
        	 +----+----+----+----+----+----+----+----+----+----+
        	 |    |    |    |    |    |    |    | 87 | 88 | 89 |
        	 +----+----+----+----+----+----+----+----+----+----+
        	 |    |    |    |    |    |    |    |    | 98 | 99 |
        	 +----+----+----+----+----+----+----+----+----+----+

   Here are a number of additional examples of range expressions and the
values they represent:

'{2, 2, 2, 2, 2, 2}'
     => 2, 2, 2, 2, 2, 2

'{2, 2, ..., 2}'
     => 2

'{2, 2, ..., 1000}'
     => 2

'{20, 30, 40, ..., 55}'
     => 20, 30, 40, 50

'{20, 30, 40, ..., 30}'
     => 20, 30

'{20, 30, 40, ..., 20}'
     => 20

'{20, 30, 40, ..., 10}'
     => [empty]

'{2, ..., 50}'
     => 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,
     20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,
     37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50

'{2, 4, ..., 50}'
     => 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,
     36, 38, 40, 42, 44, 46, 48, 50

'{2, 4, 4, ..., 50}'
     => error->

'{2, 4, 6, ..., 50}'
     => 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,
     36, 38, 40, 42, 44, 46, 48, 50

'{2, 4, 8, ..., 50}'
     => 2, 4, 8, 16, 32

'{1, 3, ..., 25}'
     => 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25

'{1, 3, 5, 7, 9, 11, 13, ..., 25}'
     => 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25

'{6561, 2187, 729, ..., 1}'
     => 6561, 2187, 729, 243, 81, 27, 9, 3, 1

'{100, 150, 225, ..., 10000}'
     => 100, 150, 225, 337, 506, 759, 1139, 1708, 2562, 3844, 5766, 8649

'{1, 4, 9, ..., 81}'
     => error->

'{sqrt(s)**2 FOR EACH s IN {1, ..., 16}}'
     => 1, 1, 1, 4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 9, 9, 16

'{y*10+x
  FOR EACH y IN {0, ..., 6}
    FOR EACH x IN {0, ..., 6}
      WHERE (x IS EVEN /\ y IS ODD) \/ (y IS EVEN /\ x IS ODD)}'
     => 1, 3, 5, 10, 12, 14, 16, 21, 23, 25, 30, 32, 34, 36, 41, 43, 45,
     50, 52, 54, 56, 61, 63, 65

   The preceding examples used exclusively constant expressions.
However, as indicated by the definition of <RANGE> above, any arbitrary
arithmetic expression (*note Arithmetic expressions::) is valid.
Assuming that 'x' is currently bound to 123, the following expansion
holds:

'{x*10, x*9, x*8, ..., x*3}'
     => 1230, 1107, 984, 861, 738, 615, 492

   ---------- Footnotes ----------

   (1) Readers unfamilier with the concept of a list comprehension may
want to consult the Wikipedia article on list comprehensions
(http://en.wikipedia.org/wiki/List_comprehension) for more information.


File: conceptual.info,  Node: Task descriptions,  Next: Communication statements,  Prev: Expressions,  Up: Grammar

4.3 Task descriptions
=====================

"Task descriptions" are a powerful way of tersely describing the sources
and targets of coNCePTuaL operations.  Task IDs range from 0 to
'num_tasks-1' (*note Predeclared variables::).  Operations involving
out-of-bound task IDs are silently ignored.

   As a side effect, a task description can declare a variable that can
be used in subsequent expressions.  (*Note Expressions::.)  There are
two types of task descriptions: one for "source" tasks and one for
"target" tasks.  The two are syntactically similar but semantically
different.  Specifically, the scope of a variable declared in a
<TARGET_TASKS> specification is more limited than one declared in a
<SOURCE_TASK> specification.

   Before introducing <SOURCE_TASK> and <TARGET_TASKS> specifications we
first introduce the notion of a <RESTRICTED_IDENT>, which is a variable
declaration that can be used to define a set of tasks.  We then present
coNCePTuaL's complete set of mechanisms for describing sets of source
and target tasks.

* Menu:

* Restricted identifiers::      Task specifications with constraints
* Source tasks::                Who performs an operation
* Target tasks::                Whom an operation is performed upon


File: conceptual.info,  Node: Restricted identifiers,  Next: Source tasks,  Prev: Task descriptions,  Up: Task descriptions

4.3.1 Restricted identifiers
----------------------------

A "restricted identifier" declares a variable, restricting it to the set
of tasks that satisfy a given relational expression (*note Relational
expressions::).  The syntax, shown below, represents the mathematical
notion of "for all <IDENT> such that <REL_EXPR> is TRUE and <IDENT> is
between zero and the number of tasks...".

<RESTRICTED_IDENT>   ::=   <IDENT> 'SUCH THAT' <REL_EXPR>

   As an example, 'evno SUCH THAT evno IS EVEN' describes all
even-numbered tasks.  On each such task, the variable 'evno' takes on
that task's ID.  Similarly, 'thr SUCH THAT 3 DIVIDES thr-1' describes
tasks 1, 4, 7, 10, 13....  On each of those tasks, 'thr' will be bound
to the task ID.  On all other tasks, 'thr' will be undefined.  When
order matters (as in the cases described in *note Sending:: and *note
Reordering task IDs::), <IDENT> takes on task IDs in increasing order.


File: conceptual.info,  Node: Source tasks,  Next: Target tasks,  Prev: Restricted identifiers,  Up: Task descriptions

4.3.2 Source tasks
------------------

A <SOURCE_TASK> specification takes one of six forms:

<SOURCE_TASK>   ::=   'ALL TASKS'
                |     'ALL TASKS' <IDENT>
                |     'TASK' <EXPR>
                |     'TASKS' <RESTRICTED_IDENT>
                |     'TASK' 'GROUP' <IDENT>
                |     'TASKS' <RANGE> [',' <RANGE>]*

   'ALL TASKS' specifies that each task will perform a given operation.
If followed by a variable name (<IDENT>), each task will individually
bind <IDENT> to its task ID--a number from zero to one less than the
total number of tasks.  That is, ''ALL TASKS' me' will bind 'me' to '0'
on task 0, '1' on task 1, and so forth.

   ''TASK' <EXPR>' specifies that only the task described by arithmetic
expression <EXPR> will perform the given operation.  For example, 'TASK
2*3+1' says that only task 7 will act; the other tasks will do nothing.

   ''TASKS' <RESTRICTED_IDENT>' describes a set of tasks that will
perform a given operation.  For instance, 'TASKS x SUCH THAT x>0 /\
x<num_tasks-1'--read as "tasks x such that x is greater than zero and x
is less than num_tasks minus one"--expresses that a given operation
should be performed on all tasks except the first and last in the
computation.  On each task that satisfies the relational expression, 'x'
will be bound to the task ID as in 'ALL TASKS' above.  Hence, 'x' will
be undefined on task 0, '1' on task 1, '2' on task 2, and so forth up to
task 'num_tasks-1', on which 'x' will again be undefined.

   ''TASK GROUP' <IDENT>' specifies that a previously defined group of
tasks will perform a given operation.  This form of <SOURCE_TASK> is
described further in *note Binding variables::.

   ''TASKS' <RANGE>' is syntactic sugar for the <RESTRICTED_IDENT> case
with an anonymous <IDENT> and an 'IS IN' relation.  For example, ''TASKS
{3, 5, 8}'' is equivalent to ''TASKS' var 'SUCH THAT' var 'IS IN' {3, 5,
8}' except that it does not bind variable 'var'.

   As per the definitions in *note Primitives:: and *note Restricted
identifiers::, respectively, <IDENT>s and <RESTRICTED_IDENT>s do not
accept parentheses.  Hence, 'TASKS (bad SUCH THAT bad IS EVEN)' and 'ALL
TASKS (no_good)' result in parse errors while 'TASKS fine SUCH THAT fine
IS EVEN' and 'ALL TASKS dandy' are acceptable constructs.  As an
analogy, 'x = 3' is valid in many general-purpose programming languages
while '(x) = 3' is not.

   Variables declared in a 'source_task' specification are limited in
scope to the surrounding statement.


File: conceptual.info,  Node: Target tasks,  Prev: Source tasks,  Up: Task descriptions

4.3.3 Target tasks
------------------

A <TARGET_TASKS> specification takes one of six forms:

<TARGET_TASKS>   ::=   'ALL OTHER TASKS'
                 |     'TASK' <EXPR>
                 |     'TASKS' <RESTRICTED_IDENT>
                 |     'TASK' 'GROUP' <IDENT>
                 |     'TASKS' <RANGE> [',' <RANGE>]*

   'ALL OTHER TASKS' is just like 'ALL TASKS' in a <SOURCE_TASK>
specification (*note Source tasks::) but applies to all tasks _except_
the source task.  Also, unlike 'ALL TASKS', 'ALL OTHER TASKS' does not
accept an <IDENT> term.

   The remaining <TARGET_TASKS> variants behave like their <SOURCE_TASK>
counterparts (*note Source tasks::), but their variables are evaluated
in the scope of the corresponding <SOURCE_TASK>.  For example, in the
<SOURCE_TASK> 'TASKS src SUCH THAT 3 DIVIDES src', the variable 'src'
can be used in a <TARGET_TASKS> such as 'TASKS dst SUCH THAT dst>src'.


File: conceptual.info,  Node: Communication statements,  Next: I/O statements,  Prev: Task descriptions,  Up: Grammar

4.4 Communication statements
============================

Communication statements are the core of any coNCePTuaL program.  The
coNCePTuaL language makes it easy to express a variety of communication
features:

   * synchronous or asynchronous communication

   * unaligned, aligned (to arbitrary byte boundaries), or misaligned
     (from a page boundary) message buffers

   * ignored, touched, or verified message contents

   * unique or recycled message buffers

   * point-to-point or collective operations

   Communication statements are performed by an arbitrary <SOURCE_TASK>
(*note Source tasks::) and may involve arbitrary <TARGET_TASKS> (*note
Target tasks::).  After explaining how to describe a message to
coNCePTuaL (*note Message specifications::) this section presents each
communication statement in turn and explains its purpose, syntax, and
semantics.

* Menu:

* Message specifications::      Describing message parameters
* Sending::                     Sending and implicitly receiving messages
* Receiving::                   Explicitly receiving messages
* Awaiting completion::         Completing asynchronous sends/receives
* Multicasting::                One-to-many communication
* Reducing::                    Many-to-many communication
* Synchronizing::               Barrier synchronization


File: conceptual.info,  Node: Message specifications,  Next: Sending,  Prev: Communication statements,  Up: Communication statements

4.4.1 Message specifications
----------------------------

A "message specification" describes a set of messages.  The following is
a formal definition:

<MESSAGE_SPEC>        ::=   <ITEM_COUNT>
                            ['NONUNIQUE' | 'UNIQUE']
                            <ITEM_SIZE>
                            ['UNALIGNED' |
                             <MESSAGE_ALIGNMENT> 'ALIGNED' |
                             <MESSAGE_ALIGNMENT> 'MISALIGNED']
                            'MESSAGES'
                            ['WITH VERIFICATION' | 'WITH DATA TOUCHING' |
                             'WITHOUT VERIFICATION' | 'WITHOUT DATA TOUCHING']
                            ['USING TAG'
                             <EXPR> | <STRING>]
                            ['FROM' [<EXPR> <DATA_MULTIPLIER> 'INTO']
                             'BUFFER' <EXPR> | 'THE DEFAULT BUFFER']

   Within a 'RECEIVE' statement (*note Receiving::), a <MESSAGE_SPEC>'s
'FROM' keyword must be replaced with 'INTO'.

   A 'SEND' statement's 'WHO RECEIVES IT' clause (*note Sending::)
utilizes a slightly different message specification, which is referred
to here as a <RECV_MESSAGE_SPEC>:

<RECV_MESSAGE_SPEC>   ::=   ['SYNCHRONOUSLY' | 'ASYNCHRONOUSLY']
                            ['AS' ['A'|'AN']
                             ['NONUNIQUE' | 'UNIQUE']
                             ['UNALIGNED' |
                              <MESSAGE_ALIGNMENT> 'ALIGNED' |
                              <MESSAGE_ALIGNMENT> 'MISALIGNED']
                             'MESSAGES']
                            ['WITH VERIFICATION' | 'WITH DATA TOUCHING' |
                             'WITHOUT VERIFICATION' | 'WITHOUT DATA TOUCHING']
                            ['USING TAG'
                             <EXPR> | <STRING>]
                            ['INTO' [<EXPR> <DATA_MULTIPLIER> 'INTO']
                             'BUFFER' <EXPR> | 'THE DEFAULT BUFFER']

   Although not indicated by the preceding grammatical rule, a
<RECV_MESSAGE_SPEC> is not allowed to be empty.  That is, at least one
of the optional clauses must be specified.

   A 'REDUCE' statement (*note Reducing::) utilizes the following
variations of <MESSAGE_SPEC> and <RECV_MESSAGE_SPEC>, respectively:

<REDUCE_MESSAGE_SPEC>   ::=   <ITEM_COUNT>
                              ['NONUNIQUE' | 'UNIQUE']
                              ['UNALIGNED' |
                               <MESSAGE_ALIGNMENT> 'ALIGNED' |
                               <MESSAGE_ALIGNMENT> 'MISALIGNED']
                              'INTEGERS' | 'DOUBLEWORDS'
                              ['WITH DATA TOUCHING' | 'WITHOUT DATA TOUCHING']
                              ['USING TAG'
                               <EXPR> | <STRING>]
                              ['FROM' [<EXPR> <DATA_MULTIPLIER> 'INTO']
                               'BUFFER' <EXPR> | 'THE DEFAULT BUFFER']

<REDUCE_TARGET_MESSAGE_SPEC>   ::=   ['AS' <ITEM_COUNT>
                                      ['NONUNIQUE' | 'UNIQUE']
                                      [<MESSAGE_ALIGNMENT> 'ALIGNED' |
                                       <MESSAGE_ALIGNMENT> 'MISALIGNED']
                                      'INTEGERS' | 'DOUBLEWORDS']
                                     ['WITH DATA TOUCHING' | 'WITHOUT DATA TOUCHING']
                                     ['USING TAG'
                                      <EXPR> | <STRING>]
                                     ['INTO' [<EXPR> <DATA_MULTIPLIER> 'INTO']
                                      'BUFFER' <EXPR> | 'THE DEFAULT BUFFER']


   We now describe in turn each component of a <MESSAGE_SPEC>,
<RECV_MESSAGE_SPEC>, <REDUCE_MESSAGE_SPEC>, and
<REDUCE_TARGET_MESSAGE_SPEC>.

* Menu:

* Item count::                  How many messages should be sent?
* Unique messages::             Should messages recycle memory or not?
* Item size::                   How big is each message?
* Message alignment::           How should messages be aligned in memory?
* Data touching::               Should message contents be accessed explcitly?
* Tag matching::                In what order should messages be received?
* Buffer control::              What buffer should be used for each message?
* Blocking semantics::          Should the sender/receiver wait before proceeding?


File: conceptual.info,  Node: Item count,  Next: Unique messages,  Prev: Message specifications,  Up: Message specifications

Item count
..........

The <ITEM_COUNT> says how many messages the <MESSAGE_SPEC> represents:

<ITEM_COUNT>   ::=   'A' | 'AN' | <EXPR>

'A' and 'AN' are synonyms for the value '1'.


File: conceptual.info,  Node: Unique messages,  Next: Item size,  Prev: Item count,  Up: Message specifications

Unique messages
...............

Normally, the coNCePTuaL backends recycle message memory to reduce the
program's memory requirements and improve performance.  By adding the
keyword 'UNIQUE', every message buffer will reside in a unique memory
region.  'NONUNIQUE' explicitly specifies the default, buffer-recycling
behavior.


File: conceptual.info,  Node: Item size,  Next: Message alignment,  Prev: Unique messages,  Up: Message specifications

Item size
.........

The message size is represented by the <ITEM_SIZE> nonterminal.  It can
be empty or expressed in one of two other ways:

<ITEM_SIZE>   ::=   <empty>
              |     <EXPR> <DATA_MULTIPLIER>
              |     <DATA_TYPE> 'SIZED'

   A <DATA_MULTIPLIER> is a scaling factor that converts a unitless
number into a number of bytes.  The following are the valid
possibilities for <DATA_MULTIPLIER> and the number of bytes by which
they multiply <EXPR>:

<DATA_MULTIPLIER>   ::=   'BIT' | 'BYTE' | 'HALFWORD' | 'WORD' | 'INTEGER' | 'DOUBLEWORD' |
                          'QUADWORD' | 'PAGE' | 'KILOBYTE' | 'MEGABYTE' | 'GIGABYTE'

     'BIT' 1/8 bytes, rounded up to the nearest integral number of bytes

     'BYTE' 1 byte

     'HALFWORD' 2 bytes

     'WORD' 4 bytes

     'INTEGER' the number of bytes in the backend's fundamental integer
     type

     'DOUBLEWORD' 8 bytes

     'QUADWORD' 16 bytes

     'PAGE' the number of bytes in an operating-system page

     'KILOBYTE' 1,024 bytes

     'MEGABYTE' 1,048,576 bytes

     'GIGABYTE' 1,073,741,824 bytes


   A <DATA_TYPE> is an "atomic" unit of data.  It can be any of the
following:

<DATA_TYPE>   ::=   'BYTE' | 'HALFWORD' | 'WORD' | 'INTEGER' | 'DOUBLEWORD' |
                    'QUADWORD' | 'PAGE'

     'BYTE' 1 byte

     'HALFWORD' 2 bytes

     'WORD' 4 bytes

     'INTEGER' the number of bytes in the backend's fundamental integer
     type

     'DOUBLEWORD' 8 bytes

     'QUADWORD' 16 bytes

     'PAGE' the number of bytes in an operating-system page

   Hence, valid <ITEM_SIZE>s include, for example, '16 MEGABYTE' or
'PAGE SIZED'.  Empty <ITEM_SIZE>s are equivalent to '0 BYTE'.  Note that
'INTEGER' varies in size based on the backend, backend compiler, and CPU
architecture but is commonly either 4 or 8 bytes; 'PAGE' varies in size
from operating system to operating system; each of the other
<DATA_TYPE>s has a fixed size, as indicated above.


File: conceptual.info,  Node: Message alignment,  Next: Data touching,  Prev: Item size,  Up: Message specifications

Message alignment
.................

Messages are normally allocated with arbitrary alignment in memory.
However, coNCePTuaL can force a specific alignment relative to the
operating-system page size (commonly 4KB or 8KB, but significantly
larger sizes are gaining popularity).  A <MESSAGE_ALIGNMENT> is
represented as follows:

<MESSAGE_ALIGNMENT>   ::=   <DATA_TYPE>
                      |     <EXPR> <DATA_MULTIPLIER>

   '64 BYTE', '3 MEGABYTE', and 'QUADWORD' are therefore all valid
examples of <MESSAGE_ALIGNMENT>s.  Bit counts are rounded up to the
nearest byte count, so '27 BITS' is in fact equivalent to '4 BYTES'.

   The 'ALIGNED' keyword forces coNCePTuaL to align messages on
_exactly_ the specified alignment.  Hence, a 'HALFWORD ALIGNED' message
can begin at memory locations 0, 2, 4, 6, 8, ..., 2k (where k is a
positive integer).  In contrast, the 'MISALIGNED' keyword forces
coNCePTuaL to align messages the given number of bytes (positive or
negative) past a page boundary.  For example, if pages are 8192 bytes in
size then a message described as 'HALFWORD MISALIGNED' can begin at
memory locations 2, 8194, 16386, 24578, ..., 8192k+2 (where k is a
positive integer).  Unlike 'ALIGNED', 'MISALIGNED' supports negative
alignments.  If the page size is 4096 bytes, then '-10 BYTE MISALIGNED'
enables a message to begin at memory locations 4086, 8182, 12278, etc.
The 'MISALIGNED' alignment is taken modulo the page size.  Therefore,
with a 4096-byte page size, '10000 BYTE MISALIGNED' is the same as '1808
BYTE MISALIGNED'.

   The 'UNALIGNED' keyword explicitly specifies the default behavior,
with messages aligned on arbitrary boundaries.


File: conceptual.info,  Node: Data touching,  Next: Tag matching,  Prev: Message alignment,  Up: Message specifications

Data touching
.............

A <MESSAGE_SPEC> described as being 'WITH DATA TOUCHING' will force
every word in a message to be both read and written ("touched").  When
<MESSAGE_SPEC> describes an outgoing message, the data will be touched
before transmission.  When <MESSAGE_SPEC> describes an incoming message,
the data will be touched after reception.  In a sense, 'WITH DATA
TOUCHING' presents a more realistic assessment of network performance,
as real applications almost always access the data they send or receive.
It also distinguishes between messaging layers that implicitly touch
data and those that can transmit data without having to touch it.  One
would expect the latter to perform better when the data is not touched,
as the former may be paying a penalty for touching the data.  However,
either could perform better when messages are sent 'WITH DATA TOUCHING',
because the latter now has to pay the penalty that the former has
already paid.

   Another form of data-touching supported by coNCePTuaL is 'WITH
VERIFICATION'.  This causes the source task to write known, but randomly
generated, data into the message before transmission and the target task
to verify that every bit was correctly received.  When a message is
received 'WITH VERIFICATION', the 'bit_errors' variable (*note
Predeclared variables::) is updated appropriately.

   'WITHOUT DATA TOUCHING' and 'WITHOUT VERIFICATION' are synonymous.
Both explicitly specify the default behavior of neither touching nor
verifying message contents.

